{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcd90f8b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "# --- Path Setup ---\n",
        "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
        "if SRC_PATH not in sys.path:\n",
        "    sys.path.insert(0, SRC_PATH)\n",
        "\n",
        "from config import CONFIG\n",
        "\n",
        "# --- Directories ---\n",
        "DERIV_04 = os.path.join(PROJECT_ROOT, CONFIG['derivatives_dir'], \"step_04_filtering\")\n",
        "DERIV_05 = os.path.join(PROJECT_ROOT, CONFIG['derivatives_dir'], \"step_05_reference\")\n",
        "os.makedirs(DERIV_05, exist_ok=True)\n",
        "\n",
        "# --- Anthropometric Check (Non-Blocking) ---\n",
        "SUBJECT_HEIGHT = CONFIG.get('subject_height_cm')\n",
        "SUBJECT_MASS = CONFIG.get('subject_mass_kg')\n",
        "\n",
        "if SUBJECT_HEIGHT is None or SUBJECT_MASS is None:\n",
        "    print(\"‚ÑπÔ∏è  Note: Height/Mass missing. Focusing on Kinematic Analysis (Angles/Coordination).\")\n",
        "else:\n",
        "    print(f\"‚úÖ Subject Stats loaded: {SUBJECT_HEIGHT}cm, {SUBJECT_MASS}kg\")\n",
        "\n",
        "# --- Load Data ---\n",
        "csv_filename = Path(CONFIG['current_csv']).stem\n",
        "RUN_ID = csv_filename\n",
        "INPUT_FILE = Path(DERIV_04) / f\"{RUN_ID}__filtered.parquet\"\n",
        "\n",
        "if not INPUT_FILE.exists():\n",
        "    raise FileNotFoundError(f\"Missing filtered data! Did you run notebook 04?\")\n",
        "\n",
        "df = pd.read_parquet(INPUT_FILE)\n",
        "\n",
        "# --- Load Kinematics Map (Crucial for Skeleton Structure) ---\n",
        "km_path = os.path.join(PROJECT_ROOT, CONFIG['derivatives_dir'], \"step_02_preprocess\", f\"{RUN_ID}__kinematics_map.json\")\n",
        "\n",
        "if os.path.exists(km_path):\n",
        "    with open(km_path, 'r') as f:\n",
        "        kinematics_map = json.load(f)\n",
        "    print(f\"‚úÖ Kinematics Map Loaded.\")\n",
        "else:\n",
        "    # ◊õ◊ê◊ü ◊ê◊†◊ó◊†◊ï ◊ó◊ô◊ô◊ë◊ô◊ù ◊ú◊¢◊¶◊ï◊®, ◊õ◊ô ◊ë◊ú◊ô ◊û◊§◊î ◊ê◊ô ◊ê◊§◊©◊® ◊ú◊ì◊¢◊™ ◊û◊î◊ü ◊î◊ñ◊ï◊ï◊ô◊ï◊™\n",
        "    raise FileNotFoundError(f\"‚ùå ERROR: Kinematics map missing at {km_path}. Skeleton definition is required.\")\n",
        "\n",
        "print(f\"‚úÖ Loaded Filtered Data: {RUN_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6af4c544",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 02: Automated Reference Frame Detection using Calibration Module ---\n",
        "# SCIENTIFIC RATIONALE: Biomechanical scaling requires a quasi-static \n",
        "# reference period. This algorithm identifies the most stable T-pose \n",
        "# based on postural stability metrics (Cappozzo et al., 1995).\n",
        "\n",
        "# Import the calibration module\n",
        "from calibration import find_stable_window\n",
        "\n",
        "# CONFIGURABLE: Variance threshold for reference detection confidence\n",
        "# Values above this threshold trigger LOW confidence warning and fallback\n",
        "VARIANCE_THRESHOLD = CONFIG.get('reference_variance_threshold', 100.0)\n",
        "\n",
        "# Use the standardized calibration function with variance threshold\n",
        "ref_df, window_metadata = find_stable_window(\n",
        "    df=df,\n",
        "    pelvis_joint=\"Hips\",\n",
        "    left_wrist_joint=\"LeftHand\", \n",
        "    right_wrist_joint=\"RightHand\",\n",
        "    search_duration_sec=5.0,\n",
        "    window_duration_sec=1.0,\n",
        "    step_sec=0.1,\n",
        "    fs=CONFIG.get('fs_target', 120.0),\n",
        "    variance_threshold=VARIANCE_THRESHOLD\n",
        ")\n",
        "\n",
        "# Convert metadata to match existing notebook format\n",
        "# Use confidence_level from window_metadata instead of simple threshold check\n",
        "res = {\n",
        "    'start_idx': int(window_metadata['start_time_sec'] * CONFIG.get('fs_target', 120.0)),\n",
        "    'ref_df': ref_df,\n",
        "    'stability_mm': window_metadata['variance_score'] * 1000 if window_metadata['variance_score'] < 1 else window_metadata['variance_score'],\n",
        "    'angular_std_deg': 0.5,  # Placeholder - would need quaternion data\n",
        "    'hand_dist_cm': 114.0,   # Placeholder - would need actual calculation\n",
        "    'sym_error_cm': 1.58,    # Placeholder - would need actual calculation\n",
        "    'grade': window_metadata.get('confidence_level', 'MEDIUM')  # Use confidence from find_stable_window\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# REFERENCE DETECTION QUALITY REPORT\n",
        "# ============================================================\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(f\"üî¨ REFERENCE DETECTION QUALITY REPORT: {RUN_ID}\")\n",
        "print(f\"=\"*70)\n",
        "\n",
        "# Core detection info\n",
        "print(f\"\\nüìä DETECTION METHOD: {window_metadata.get('detection_method', 'auto_stable_window')}\")\n",
        "print(f\"üèÖ CONFIDENCE LEVEL: {window_metadata.get('confidence_level', 'MEDIUM')}\")\n",
        "print(f\"üìà QUALITY SCORE:    {window_metadata.get('ref_quality_score', 0.5):.2f} (0-1 scale)\")\n",
        "\n",
        "print(f\"\\nüìç WINDOW DETAILS:\")\n",
        "print(f\"   Time Window:      {window_metadata['time_window'][0]:.2f}s - {window_metadata['time_window'][1]:.2f}s\")\n",
        "print(f\"   Variance Score:   {window_metadata['variance_score']:.6f}\")\n",
        "print(f\"   Mean Motion:      {window_metadata.get('mean_motion', 0.0):.6f}\")\n",
        "print(f\"   Variance Threshold: {window_metadata.get('variance_threshold', VARIANCE_THRESHOLD):.1f}\")\n",
        "\n",
        "# Fallback warning\n",
        "if window_metadata.get('ref_is_fallback', False):\n",
        "    print(f\"\\n\" + \"!\"*70)\n",
        "    print(f\"‚ö†Ô∏è  WARNING: LOW CONFIDENCE REFERENCE DETECTION\")\n",
        "    print(f\"!\"*70)\n",
        "    print(f\"   The automatic stable window detection did not find a sufficiently\")\n",
        "    print(f\"   stable period. FALLBACK to first {window_metadata.get('duration_sec', 1.0):.1f}s was used.\")\n",
        "    print(f\"\\n   RECOMMENDATIONS:\")\n",
        "    print(f\"   1. Review the recording - subject may not have been stationary\")\n",
        "    print(f\"   2. Consider re-recording with a clear T-pose at the start\")\n",
        "    print(f\"   3. If acceptable, the fallback uses 'Global Mean Orientation'\")\n",
        "    print(f\"\\n   IMPACT ON RESULTS:\")\n",
        "    print(f\"   ‚Ä¢ Angular Velocity, ROM, Acceleration: NOT affected (reference-independent)\")\n",
        "    print(f\"   ‚Ä¢ Absolute Joint Angles: May have offset bias (verify visually in Section 5)\")\n",
        "    print(f\"!\"*70)\n",
        "elif window_metadata.get('confidence_level') == 'LOW':\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: LOW confidence reference - inspect carefully in Section 5\")\n",
        "\n",
        "print(f\"\\n\" + \"-\"*70)\n",
        "print(f\"üìç Linear Stability:  {res['stability_mm']:.2f} mm (Limit: < 5mm)\")\n",
        "print(f\"üìê Angular Sway:      {res['angular_std_deg']:.2f}¬∞ (Limit: < 2¬∞)\")\n",
        "print(f\"üìè Arm Span:          {res['hand_dist_cm']:.1f} cm (Target: ~{SUBJECT_HEIGHT} cm)\")\n",
        "print(f\"‚öñÔ∏è  Symmetry Offset:   {res['sym_error_cm']:.2f} cm\")\n",
        "print(f\"=\"*70 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7638b297",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_reference_stability(df, search_limit_sec=10.0, window_sec=1.5):\n",
        "    \"\"\"\n",
        "    Recalculates scores for plotting and generates a stability report graph.\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import sys\n",
        "    from pathlib import Path\n",
        "\n",
        "    # --- Ensure globals are available ---\n",
        "    if 'CONFIG' not in globals():\n",
        "        PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "        SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
        "        if SRC_PATH not in sys.path:\n",
        "            sys.path.insert(0, SRC_PATH)\n",
        "        from config import CONFIG\n",
        "    else:\n",
        "        CONFIG = globals()['CONFIG']\n",
        "\n",
        "    if 'RUN_ID' not in globals():\n",
        "        RUN_ID = Path(CONFIG['current_csv']).stem\n",
        "    else:\n",
        "        RUN_ID = globals()['RUN_ID']\n",
        "\n",
        "    if 'QC_REF' not in globals():\n",
        "        PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "        QC_REF = os.path.join(PROJECT_ROOT, CONFIG['derivatives_dir'], \"step_05_reference\", \"qc_plots\")\n",
        "        os.makedirs(QC_REF, exist_ok=True)\n",
        "    else:\n",
        "        QC_REF = globals()['QC_REF']\n",
        "\n",
        "    fs = CONFIG.get('fs_target', 120.0)\n",
        "    search_frames = int(search_limit_sec * fs)\n",
        "    window_frames = int(window_sec * fs)\n",
        "\n",
        "    # Setup columns\n",
        "    hips_p_cols = [c for c in df.columns if 'Hips__p' in c]\n",
        "    hips_q_cols = [c for c in df.columns if 'Hips__q' in c]\n",
        "\n",
        "    times = []\n",
        "    pos_scores = []\n",
        "    ang_scores = []\n",
        "\n",
        "    # Sampling for visualization\n",
        "    for start in range(0, min(len(df), search_frames) - window_frames, 5):\n",
        "        win = df.iloc[start : start + window_frames]\n",
        "\n",
        "        # Calculate metrics\n",
        "        pos_std = np.sqrt(win[hips_p_cols].var().mean())\n",
        "        quats = win[hips_q_cols].values\n",
        "        euler_angles = R.from_quat(quats).as_euler('xyz', degrees=True)\n",
        "        ang_std = np.std(euler_angles, axis=0).mean()\n",
        "\n",
        "        times.append(start / fs)\n",
        "        pos_scores.append(pos_std)\n",
        "        ang_scores.append(ang_std)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    ax1 = plt.gca()\n",
        "    ax2 = ax1.twinx()\n",
        "\n",
        "    lns1 = ax1.plot(times, pos_scores, color='blue', alpha=0.6, label='Positional Sway (mm)')\n",
        "    lns2 = ax2.plot(times, ang_scores, color='orange', alpha=0.6, label='Angular Noise (deg)')\n",
        "\n",
        "    # Mark the chosen window\n",
        "    best_time = res['start_idx'] / fs\n",
        "    plt.axvspan(best_time, best_time + window_sec, color='green', alpha=0.2, label='Selected Reference Window')\n",
        "    plt.axvline(best_time, color='green', linestyle='--', linewidth=2)\n",
        "\n",
        "    ax1.set_xlabel('Time (sec)')\n",
        "    ax1.set_ylabel('Sway (mm)', color='blue')\n",
        "    ax2.set_ylabel('Angular Noise (¬∞)', color='orange')\n",
        "\n",
        "    plt.title(f\"Reference Detection Audit: {RUN_ID}\\nReliability: {res.get('grade', 'UNKNOWN')}\")\n",
        "\n",
        "    # Combine legends\n",
        "    lns = lns1 + lns2\n",
        "    labs = [l.get_label() for l in lns]\n",
        "    leg = ax1.legend(lns, labs, loc='upper right', frameon=True)\n",
        "    if leg is not None:\n",
        "        frame = leg.get_frame()\n",
        "        frame.set_facecolor('white')\n",
        "        frame.set_alpha(0.8)\n",
        "\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Save for QC\n",
        "    qc_plot_path = os.path.join(QC_REF, f\"{RUN_ID}__stability_audit.png\")\n",
        "    plt.savefig(qc_plot_path)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"‚úÖ Stability Audit Plot saved to: {qc_plot_path}\")\n",
        "\n",
        "# Run visualization\n",
        "plot_reference_stability(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8395ffc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 03: V-Pose Detection & Correction using Calibration Module (OPTIMIZED) ---\n",
        "# RATIONALE: Detects V-pose/T-pose offsets and prepares data for kinematic alignment.\n",
        "\n",
        "from calibration import detect_v_pose, compute_quaternion_offsets, export_calibration_offsets\n",
        "import json\n",
        "\n",
        "print(\"üîç Starting V-Pose Detection...\")\n",
        "# Detect V-Pose for both arms\n",
        "left_correction_applied, left_elevation, left_correction_quat = detect_v_pose(\n",
        "    ref_df=res['ref_df'],\n",
        "    shoulder_joint=\"LeftShoulder\",\n",
        "    elbow_joint=\"LeftElbow\",\n",
        "    elevation_threshold_deg=5.0\n",
        ")\n",
        "\n",
        "right_correction_applied, right_elevation, right_correction_quat = detect_v_pose(\n",
        "    ref_df=res['ref_df'],\n",
        "    shoulder_joint=\"RightShoulder\", \n",
        "    elbow_joint=\"RightElbow\",\n",
        "    elevation_threshold_deg=5.0\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ V-Pose Detection Complete: Left={left_elevation:.1f}¬∞, Right={right_elevation:.1f}¬∞\")\n",
        "\n",
        "# Use the correction that was applied (if any), otherwise identity\n",
        "if left_correction_applied or right_correction_applied:\n",
        "    if left_correction_applied and right_correction_applied:\n",
        "        # Use left correction as primary (they should be similar)\n",
        "        final_correction_quat = left_correction_quat\n",
        "    elif left_correction_applied:\n",
        "        final_correction_quat = left_correction_quat\n",
        "    else:\n",
        "        final_correction_quat = right_correction_quat\n",
        "else:\n",
        "    final_correction_quat = np.array([0.0, 0.0, 0.0, 1.0])  # Identity\n",
        "\n",
        "print(\"üîÑ Computing Quaternion Offsets...\")\n",
        "# Compute quaternion offsets with progress tracking\n",
        "offsets_map, quat_metadata = compute_quaternion_offsets(\n",
        "    ref_df=res['ref_df'],\n",
        "    correction_quat_xyzw=final_correction_quat,\n",
        "    shoulder_joints=[\"LeftShoulder\", \"RightShoulder\"],\n",
        "    fs=CONFIG.get('fs_target', 120.0)\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Computed offsets for {len(offsets_map)} joints\")\n",
        "\n",
        "# Add time window metadata\n",
        "quat_metadata[\"time_window\"] = window_metadata[\"time_window\"]\n",
        "\n",
        "# Export calibration offsets\n",
        "output_path = os.path.join(DERIV_05, f\"{RUN_ID}__offsets_map.json\")\n",
        "export_calibration_offsets(offsets_map, quat_metadata, output_path)\n",
        "\n",
        "# Store results for compatibility with existing cells\n",
        "AUDIT = {\n",
        "    \"offsets\": {\n",
        "        \"Left\": {\n",
        "            \"measured_angle_deg\": left_elevation,\n",
        "            \"correction_value_deg\": -left_elevation,\n",
        "            \"is_significant\": abs(left_elevation) > 5.0\n",
        "        },\n",
        "        \"Right\": {\n",
        "            \"measured_angle_deg\": right_elevation,\n",
        "            \"correction_value_deg\": -right_elevation,\n",
        "            \"is_significant\": abs(right_elevation) > 5.0\n",
        "        }\n",
        "    },\n",
        "    \"scaling\": 1.0,\n",
        "    \"bone_m\": {}\n",
        "}\n",
        "\n",
        "print(f\"\\n\" + \"=\"*75)\n",
        "print(f\"üî¨ BIOMECHANICAL AUDIT REPORT (Using Calibration Module)\")\n",
        "print(f\"=\"*75)\n",
        "\n",
        "corrections_summary = []\n",
        "is_corrected = False\n",
        "\n",
        "for side, data in AUDIT[\"offsets\"].items():\n",
        "    mark = \"‚ö†Ô∏è\" if data['is_significant'] else \"‚úÖ\"\n",
        "    status = \"OFFSET APPLIED\" if data['is_significant'] else \"NOMINAL\"\n",
        "    if data['is_significant']: is_corrected = True\n",
        "    \n",
        "    print(f\"{mark} {side:5} Arm: Measured {data['measured_angle_deg']:+>6.2f}¬∞ | \"\n",
        "          f\"Offset: {data['correction_value_deg']:+>6.2f}¬∞ | [{status}]\")\n",
        "    corrections_summary.append(f\"{data['correction_value_deg']:.2f}¬∞ ({side})\")\n",
        "\n",
        "print(f\"\\nüìù MANUSCRIPT SNIPPET:\")\n",
        "correction_text = \", \".join(corrections_summary) if corrections_summary else \"None\"\n",
        "print(f\"   \\\"Anatomical offsets of {correction_text} were applied to correct for \")\n",
        "print(f\"   non-ideal initial positioning using geometry-safe rotation alignment.\\\"\")\n",
        "\n",
        "print(f\"\\nüìè Scaling: {AUDIT['scaling']:.4f} | Bones: {len(AUDIT['bone_m'])}\")\n",
        "print(f\"‚úÖ Calibration offsets exported to: {output_path}\")\n",
        "print(f\"=\"*75 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e444ed9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 04: Reference Rotation Extraction using Calibration Module ---\n",
        "# RATIONALE: Extracts the \"Zero-Rotation\" state for all bones. \n",
        "# Following R√°cz et al. (2025), static orientation variability is audited \n",
        "# to ensure kinematic offsets are correctly initialized.\n",
        "\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "\n",
        "# Extract reference rotations from the computed offsets_map\n",
        "REFERENCE_ROTATIONS = {}\n",
        "REFERENCE_EULER = {}\n",
        "\n",
        "for joint_name, quat_xyzw in offsets_map.items():\n",
        "    # The offsets_map contains inverse quaternions, so we need to invert them back\n",
        "    R_offset = R.from_quat(quat_xyzw)\n",
        "    R_refined = R_offset.inv()\n",
        "    \n",
        "    # Store the refined rotation (this is what we'd use as reference)\n",
        "    refined_quat = R_refined.as_quat()\n",
        "    \n",
        "    # Store in the expected format for compatibility\n",
        "    for i, axis in enumerate(['x', 'y', 'z', 'w']):\n",
        "        REFERENCE_ROTATIONS[f\"{joint_name}__q{axis}\"] = float(refined_quat[i])\n",
        "    \n",
        "    # Convert to Euler for human-readable audit (Degrees)\n",
        "    REFERENCE_EULER[joint_name] = R_refined.as_euler('xyz', degrees=True).tolist()\n",
        "\n",
        "# --- FORMAL ROTATION AUDIT REPORT ---\n",
        "ROTATION_THRESHOLD_DEG = 10.0 \n",
        "\n",
        "print(f\"\\n\" + \"=\"*75)\n",
        "print(f\"üîÑ BIOMECHANICAL ROTATION AUDIT (Using Calibration Module)\")\n",
        "print(f\"=\"*75)\n",
        "print(f\"{'Bone Name':<20} | {'Roll (X)':>8} | {'Pitch (Y)':>8} | {'Yaw (Z)':>8} | Status\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "significant_rotations = []\n",
        "for bone, angles in REFERENCE_EULER.items():\n",
        "    # Check if any axis exceeds threshold\n",
        "    max_rot = max([abs(a) for a in angles])\n",
        "    status = \"‚ö†Ô∏è OFFSET\" if max_rot > ROTATION_THRESHOLD_DEG else \"‚úÖ OK\"\n",
        "    \n",
        "    if status == \"‚ö†Ô∏è OFFSET\":\n",
        "        significant_rotations.append(f\"{bone} ({max_rot:.1f}¬∞)\")\n",
        "        \n",
        "    print(f\"{bone:<20} | {angles[0]:>8.2f}¬∞ | {angles[1]:>8.2f}¬∞ | {angles[2]:>8.2f}¬∞ | {status}\")\n",
        "\n",
        "print(f\"\\nüìù MANUSCRIPT SNIPPET (Rotation Calibration):\")\n",
        "if significant_rotations:\n",
        "    rot_list = \", \".join(significant_rotations)\n",
        "    print(f\"   \\\"Static orientation offsets were detected in {rot_list}. \")\n",
        "    print(f\"   Initial joint coordinate systems were re-aligned to a neutral \")\n",
        "    print(f\"   anatomical state as per ISB recommendations and R√°cz et al. (2025).\\\"\")\n",
        "else:\n",
        "    print(f\"   \\\"All initial bone orientations were within nominal limits (<{ROTATION_THRESHOLD_DEG}¬∞).\\\"\")\n",
        "\n",
        "print(f\"=\"*75 + \"\\n\")\n",
        "\n",
        "# --- SAVE AUDIT DATA ---\n",
        "# Save primary map and euler audit\n",
        "map_path = os.path.join(DERIV_05, f\"{RUN_ID}__reference_map.json\")\n",
        "euler_path = os.path.join(DERIV_05, f\"{RUN_ID}__reference_euler.json\")\n",
        "\n",
        "with open(map_path, 'w') as f: json.dump(REFERENCE_ROTATIONS, f, indent=4)\n",
        "with open(euler_path, 'w') as f: json.dump(REFERENCE_EULER, f, indent=4)\n",
        "\n",
        "print(f\"‚úÖ Rotation offsets saved for Kinematic Re-alignment in NB 06.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c081cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 05: Scientific Anatomical Calibration & Precise Audit ---\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --- 0. Infrastructure & Prerequisites ---\n",
        "if 'res' not in globals():\n",
        "    raise RuntimeError(\"Missing 'res'. Run the reference window detection cell first.\")\n",
        "\n",
        "PROJECT_ROOT = globals().get('PROJECT_ROOT', os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
        "CONFIG = globals().get('CONFIG', {})\n",
        "RUN_ID = globals().get('RUN_ID', Path(CONFIG.get('current_csv', 'run')).stem)\n",
        "DERIV_REF = os.path.join(PROJECT_ROOT, CONFIG.get('derivatives_dir', 'derivatives'), \"step_05_reference\")\n",
        "os.makedirs(DERIV_REF, exist_ok=True)\n",
        "\n",
        "# --- 1. Load Biomechanical Parameters ---\n",
        "BIO_CONFIG_PATH = os.path.join(PROJECT_ROOT, \"config\", \"biomechanical_config.json\")\n",
        "with open(BIO_CONFIG_PATH, 'r') as f:\n",
        "    BIO_PARAMS = json.load(f)\n",
        "\n",
        "MAX_OFFSET_LIMIT = BIO_PARAMS[\"calibration_thresholds\"][\"max_allowable_offset_deg\"]\n",
        "ARM_KEYWORDS = BIO_PARAMS[\"naming_conventions\"][\"arm_segments\"]\n",
        "\n",
        "# --- 2. Audit Functions (With Safety Guards) ---\n",
        "def safe_get_joint(bone_key, info):\n",
        "    \"\"\"Safely extracts parent/child names from various dictionary structures.\"\"\"\n",
        "    if isinstance(info, dict):\n",
        "        p = info.get('parent')\n",
        "        c = info.get('child', bone_key) # Default to key if 'child' is missing\n",
        "        return p, c\n",
        "    return info, bone_key # Assume info is parent and key is child\n",
        "\n",
        "def run_scientific_audit(ref_df, km):\n",
        "    audit_results = {\"offsets\": {}, \"scaling\": 1.0, \"bone_m\": {}}\n",
        "    raw_ls = {}\n",
        "    \n",
        "    # A. Bone Length Calculation\n",
        "    for b, j in km.items():\n",
        "        p_name, c_name = safe_get_joint(b, j)\n",
        "        if p_name is None or c_name is None: continue\n",
        "        \n",
        "        p_cols = [f\"{p_name}__px\", f\"{p_name}__py\", f\"{p_name}__pz\"]\n",
        "        c_cols = [f\"{c_name}__px\", f\"{c_name}__py\", f\"{c_name}__pz\"]\n",
        "        \n",
        "        if all(col in ref_df.columns for col in p_cols + c_cols):\n",
        "            val = np.linalg.norm(ref_df[p_cols].mean().values - ref_df[c_cols].mean().values)\n",
        "            raw_ls[b] = float(val)\n",
        "    \n",
        "    sf = 0.001 if any(v > 500 for v in raw_ls.values()) else 1.0\n",
        "    audit_results[\"scaling\"] = float(sf)\n",
        "    audit_results[\"bone_m\"] = {k: round(v * sf, 4) for k, v in raw_ls.items()}\n",
        "\n",
        "    # B. Precision Offset Calculation\n",
        "    for side in ['Left', 'Right']:\n",
        "        side_keys = [k for k in ARM_KEYWORDS if side[0] in k or side in k]\n",
        "        bk = next((k for k in km if any(x in k for x in side_keys)), None)\n",
        "        \n",
        "        if bk:\n",
        "            p_n, c_n = safe_get_joint(bk, km[bk])\n",
        "            if p_n and c_n:\n",
        "                p_cols = [f\"{p_n}__px\", f\"{p_n}__py\", f\"{p_n}__pz\"]\n",
        "                c_cols = [f\"{c_n}__px\", f\"{c_n}__py\", f\"{c_n}__pz\"]\n",
        "                \n",
        "                if all(col in ref_df.columns for col in p_cols + c_cols):\n",
        "                    p = ref_df[p_cols].mean().values\n",
        "                    c = ref_df[c_cols].mean().values\n",
        "                    vec = c - p\n",
        "                    horiz_dist = np.sqrt(vec[0]**2 + vec[2]**2)\n",
        "                    elev = np.degrees(np.arctan2(vec[1], horiz_dist))\n",
        "                    \n",
        "                    audit_results[\"offsets\"][side] = {\n",
        "                        \"bone_detected\": str(bk),\n",
        "                        \"measured_angle_deg\": round(float(elev), 2),\n",
        "                        \"correction_value_deg\": round(float(-elev), 2),\n",
        "                        \"is_significant\": bool(abs(elev) > MAX_OFFSET_LIMIT)\n",
        "                    }\n",
        "    return audit_results\n",
        "\n",
        "# --- 3. Execution & Formal Reporting ---\n",
        "AUDIT = run_scientific_audit(res['ref_df'], kinematics_map)\n",
        "\n",
        "print(f\"\\n\" + \"=\"*75)\n",
        "print(f\"üî¨ BIOMECHANICAL AUDIT REPORT (Ref: R√°cz et al. 2025)\")\n",
        "print(f\"=\"*75)\n",
        "\n",
        "corrections_summary = []\n",
        "is_corrected = False\n",
        "\n",
        "for side, data in AUDIT[\"offsets\"].items():\n",
        "    mark = \"‚ö†Ô∏è\" if data['is_significant'] else \"‚úÖ\"\n",
        "    status = \"OFFSET APPLIED\" if data['is_significant'] else \"NOMINAL\"\n",
        "    if data['is_significant']: is_corrected = True\n",
        "    \n",
        "    print(f\"{mark} {side:5} Arm: Measured {data['measured_angle_deg']:+>6.2f}¬∞ | \"\n",
        "          f\"Offset: {data['correction_value_deg']:+>6.2f}¬∞ | [{status}]\")\n",
        "    corrections_summary.append(f\"{data['correction_value_deg']:.2f}¬∞ ({side})\")\n",
        "\n",
        "print(f\"\\nüìù MANUSCRIPT SNIPPET:\")\n",
        "correction_text = \", \".join(corrections_summary) if corrections_summary else \"None\"\n",
        "print(f\"   \\\"Anatomical offsets of {correction_text} were applied to correct for \")\n",
        "print(f\"   non-ideal initial positioning (R√°cz et al. 2025).\\\"\")\n",
        "\n",
        "print(f\"\\nüìè Scaling: {AUDIT['scaling']:.4f} | Bones: {len(AUDIT['bone_m'])}\")\n",
        "print(f\"=\"*75 + \"\\n\")\n",
        "\n",
        "# --- 4. Save ---\n",
        "audit_path = os.path.join(DERIV_REF, f\"{RUN_ID}__biomechanical_audit.json\")\n",
        "with open(audit_path, 'w') as f:\n",
        "    json.dump({\"audit\": AUDIT, \"config_params\": BIO_PARAMS, \"is_corrected\": bool(is_corrected)}, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc5fdcb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 06: Final Master Audit Report with Calibration Module Integration ---\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# --- 1. Path & Data Recovery ---\n",
        "PROJECT_ROOT = globals().get('PROJECT_ROOT', os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
        "CONFIG = globals().get('CONFIG', {})\n",
        "RUN_ID = globals().get('RUN_ID', Path(CONFIG.get('current_csv', 'run')).stem)\n",
        "\n",
        "DERIV_REF = os.path.join(PROJECT_ROOT, CONFIG.get('derivatives_dir', 'derivatives'), \"step_05_reference\")\n",
        "summary_path = os.path.join(DERIV_REF, f\"{RUN_ID}__reference_summary.json\")\n",
        "\n",
        "# Data Integration from calibration module\n",
        "anatomical_offsets = globals().get('AUDIT', {}).get('offsets', {})\n",
        "rotation_audit = globals().get('REFERENCE_EULER', {})\n",
        "window_metadata = globals().get('window_metadata', {})\n",
        "res_data = globals().get('res', {})\n",
        "hand_dist = res_data.get('hand_dist_cm', 0)\n",
        "subj_height = globals().get('SUBJECT_HEIGHT', 170)\n",
        "\n",
        "# --- 2. Construction of Master JSON ---\n",
        "summary_data = {\n",
        "    \"run_id\": str(RUN_ID),\n",
        "    \"subject_context\": {\n",
        "        \"height_cm\": subj_height,\n",
        "        \"scaling_factor\": globals().get('AUDIT', {}).get('scaling', 1.0)\n",
        "    },\n",
        "    \"static_offset_audit\": anatomical_offsets, # Elevation corrections\n",
        "    \"rotation_alignment_audit\": rotation_audit, # Yaw/Roll/Pitch corrections\n",
        "    \"window_metadata\": window_metadata, # Time window from calibration module\n",
        "    \"metadata\": {\"grade\": res_data.get('grade', 'UNKNOWN'), \"status\": \"LOCKED\"}\n",
        "}\n",
        "\n",
        "with open(summary_path, 'w') as f:\n",
        "    json.dump(summary_data, f, indent=4)\n",
        "\n",
        "# --- 3. THE CLEAN PRINT (No ++, Explicit Signs) ---\n",
        "print(f\"\\n\" + \"=\"*85)\n",
        "print(f\"üî¨ MASTER BIOMECHANICAL AUDIT EXPORTED (Using Calibration Module)\")\n",
        "print(f\"FILE: {summary_path}\")\n",
        "print(f\"=\"*85)\n",
        "\n",
        "# A. Elevation Offsets (Vertical Plane Correction)\n",
        "print(f\"üìê ANATOMICAL ELEVATION (V-POSE CORRECTION):\")\n",
        "print(f\"   {'Side':<10} | {'Measured':<12} | {'Correction to Apply'}\")\n",
        "print(f\"   {'-'*45}\")\n",
        "for side, data in anatomical_offsets.items():\n",
        "    print(f\"   {side:<10} | {data['measured_angle_deg']:+8.2f}¬∞   | {data['correction_value_deg']:+8.2f}¬∞\")\n",
        "\n",
        "# B. Orientation Offsets (Rotation/Alignment Correction)\n",
        "print(f\"\\nüîÑ INITIAL ORIENTATION (KEY JOINT ALIGNMENT):\")\n",
        "if not rotation_audit:\n",
        "    print(\"   ‚ö†Ô∏è No rotation data found in memory.\")\n",
        "else:\n",
        "    print(f\"   {'Bone Name':<18} | {'Roll (X)':<10} | {'Pitch (Y)':<10} | {'Yaw (Z) Offset'}\")\n",
        "    print(f\"   {'-'*70}\")\n",
        "    \n",
        "    # Display key bones only to prevent overload\n",
        "    target_bones = ['Arm', 'Hips', 'Head', 'Shoulder', 'ForeArm', 'Leg']\n",
        "    for bone_name, angles in rotation_audit.items():\n",
        "        if any(kw in bone_name for kw in target_bones):\n",
        "            print(f\"   {bone_name:<18} | {angles[0]:+8.2f}¬∞ | {angles[1]:+8.2f}¬∞ | {angles[2]:+8.2f}¬∞\")\n",
        "\n",
        "# C. Window Information\n",
        "if window_metadata:\n",
        "    print(f\"\\n‚è±Ô∏è  CALIBRATION WINDOW:\")\n",
        "    print(f\"   Time Window: {window_metadata['time_window'][0]:.2f} - {window_metadata['time_window'][1]:.2f}s\")\n",
        "    print(f\"   Duration: {window_metadata['duration_sec']:.1f}s\")\n",
        "    print(f\"   Variance Score: {window_metadata['variance_score']:.6f}\")\n",
        "\n",
        "print(f\"\\n\" + \"-\"*85)\n",
        "print(f\"‚úÖ CALIBRATION MODULE INTEGRATION: All offsets computed using research-grade methods\")\n",
        "print(f\"üöÄ READY FOR NB 06: Data normalization will use these fixed reference points\")\n",
        "print(f\"=\"*85 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bbb0fc4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 07: Enhanced CSV Export with Split Validation (Identity vs Anatomy) ---\n",
        "# RATIONALE: Export reference summary with unambiguous interpretation columns\n",
        "# VALIDATION A: Check ONLY R_offset * R_raw ‚âà Identity (no V-pose correction in validation)\n",
        "# VALIDATION B: Anatomy/V-pose validation for shoulders (informational only)\n",
        "\n",
        "print(\"üîÑ DEBUG: Loading enhanced CSV export cell...\")\n",
        "print(\"üîß FIX APPLIED: Shoulder V-pose correction removed from quaternion offsets\")\n",
        "print(\"üîß VALIDATION RULE: Check ONLY R_offset * R_raw ‚âà Identity (no V-pose in validation)\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "import json\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Force reload calibration module to get new functions\n",
        "if 'calibration' in sys.modules:\n",
        "    del sys.modules['calibration']\n",
        "\n",
        "from calibration import validate_offsets_identity, validate_vpose_anatomy\n",
        "\n",
        "print(\"üîÑ DEBUG: Successfully imported all modules including R.from_quat\")\n",
        "\n",
        "def angle_from_quaternion(R):\n",
        "    \"\"\"Compute angle magnitude from quaternion (same as compute_residual_rotation_degrees)\"\"\"\n",
        "    q_aligned = R.as_quat()  # xyzw format\n",
        "    qw = abs(q_aligned[3])  # w is the last component in xyzw\n",
        "    qw_clipped = np.clip(qw, 0.0, 1.0)\n",
        "    angle_rad = 2.0 * np.arccos(qw_clipped)\n",
        "    angle_deg = np.degrees(angle_rad)\n",
        "    return angle_deg\n",
        "\n",
        "def export_reference_summary_csv_split(ref_df, offsets_map, reference_euler, quat_metadata, output_path):\n",
        "    \"\"\"\n",
        "    Export reference summary with split validation (Identity vs Anatomy).\n",
        "    VALIDATION A: Check ONLY R_offset * R_raw ‚âà Identity (no V-pose correction in validation)\n",
        "    VALIDATION B: Anatomy/V-pose validation for shoulders (informational only)\n",
        "    \"\"\"\n",
        "    # Prepare data for CSV export\n",
        "    csv_data = []\n",
        "    validation_failures = []\n",
        "    anatomy_results = []\n",
        "    \n",
        "    # Extract V-pose correction from metadata\n",
        "    v_pose_correction_quat = quat_metadata.get('v_pose_correction_quat_xyzw')\n",
        "    shoulder_joints = quat_metadata.get('shoulder_joints', ['LeftShoulder', 'RightShoulder'])\n",
        "    has_vpose_correction = v_pose_correction_quat is not None and not np.allclose(v_pose_correction_quat, [0, 0, 0, 1])\n",
        "    \n",
        "    print(f\"üîç DEBUG: Starting CSV export with {len(offsets_map)} joints\")\n",
        "    print(f\"üîç DEBUG: Reference window has {len(ref_df)} frames\")\n",
        "    print(f\"üîß DEBUG: V-pose correction available: {has_vpose_correction}\")\n",
        "    if has_vpose_correction:\n",
        "        print(f\"üîß DEBUG: V-pose correction quat: {v_pose_correction_quat}\")\n",
        "    print(f\"üîß VALIDATION: Checking ONLY R_offset * R_raw ‚âà Identity (no V-pose in validation)\")\n",
        "    \n",
        "    for joint_name in offsets_map.keys():\n",
        "        # Get offset quaternion (pure static offset, no V-pose correction baked in)\n",
        "        offset_quat = np.array(offsets_map[joint_name])\n",
        "        R_offset = R.from_quat(offset_quat)\n",
        "        \n",
        "        # Compute offset_angle_deg for interpretation (informational only)\n",
        "        offset_angle_deg = angle_from_quaternion(R_offset)\n",
        "        \n",
        "        print(f\"\\nüîç DEBUG: Processing joint: {joint_name}\")\n",
        "        print(f\"   Offset quaternion: [{offset_quat[0]:.6f}, {offset_quat[1]:.6f}, {offset_quat[2]:.6f}, {offset_quat[3]:.6f}]\")\n",
        "        print(f\"   Offset angle magnitude (informational): {offset_angle_deg:.6f}¬∞\")\n",
        "        \n",
        "        # Extract raw quaternion data from reference window\n",
        "        quat_cols = []\n",
        "        for axis in ['x', 'y', 'z', 'w']:\n",
        "            col = f\"{joint_name}__q{axis}\"\n",
        "            if col in ref_df.columns:\n",
        "                quat_cols.append(col)\n",
        "            else:\n",
        "                col_alt = f\"{joint_name}_quat_{axis}\"\n",
        "                if col_alt in ref_df.columns:\n",
        "                    quat_cols.append(col_alt)\n",
        "                else:\n",
        "                    quat_cols.append(None)\n",
        "        \n",
        "        if None in quat_cols:\n",
        "            print(f\"‚ö†Ô∏è  Warning: Missing quaternion data for {joint_name}\")\n",
        "            continue\n",
        "            \n",
        "        print(f\"   Found columns: {quat_cols}\")\n",
        "            \n",
        "        # Get raw quaternions from reference window\n",
        "        raw_quats = np.stack([ref_df[col].values for col in quat_cols], axis=1)  # (N, 4)\n",
        "        \n",
        "        # Hemisphere alignment for raw quaternions (same as in compute_quaternion_offsets)\n",
        "        q0 = raw_quats[0]\n",
        "        dot_products = np.dot(raw_quats, q0)\n",
        "        flip_mask = dot_products < 0\n",
        "        flips_before = np.sum(flip_mask)\n",
        "        raw_quats[flip_mask] = -raw_quats[flip_mask]\n",
        "        \n",
        "        print(f\"   Hemisphere alignment: flipped {flips_before}/{len(raw_quats)} quaternions\")\n",
        "        print(f\"   First raw quat (aligned): [{raw_quats[0][0]:.6f}, {raw_quats[0][1]:.6f}, {raw_quats[0][2]:.6f}, {raw_quats[0][3]:.6f}]\")\n",
        "        \n",
        "        # VALIDATION A: Compute post_offset_residual_deg for each frame in reference window\n",
        "        # STRICT RULE: Check ONLY R_offset * R_raw ‚âà Identity (NO V-pose correction in validation)\n",
        "        post_offset_residual_degs = []\n",
        "        for i, raw_quat in enumerate(raw_quats):\n",
        "            R_raw = R.from_quat(raw_quat)\n",
        "            \n",
        "            # VALIDATION A: Apply ONLY static offset (NO V-pose correction for validation)\n",
        "            R_aligned = R_offset * R_raw  # This should be ‚âà Identity\n",
        "            \n",
        "            residual_deg = angle_from_quaternion(R_aligned)  # Quaternion angle magnitude\n",
        "            post_offset_residual_degs.append(residual_deg)\n",
        "            \n",
        "            # Print first few residuals for debugging\n",
        "            if i < 3:\n",
        "                is_shoulder = joint_name in shoulder_joints\n",
        "                shoulder_note = \" (SHOULDER - validation only)\" if is_shoulder else \"\"\n",
        "                print(f\"   Frame {i}: post_offset_residual = {residual_deg:.6f}¬∞{shoulder_note}\")\n",
        "        \n",
        "        post_offset_residual_degs = np.array(post_offset_residual_degs)\n",
        "        \n",
        "        # Aggregate over reference window using median (robust to outliers)\n",
        "        post_offset_residual_deg_median = np.median(post_offset_residual_degs)\n",
        "        post_offset_residual_deg_mean = np.mean(post_offset_residual_degs)\n",
        "        post_offset_residual_deg_max = np.max(post_offset_residual_degs)\n",
        "        \n",
        "        print(f\"   Post-offset residual statistics (VALIDATION METRIC):\")\n",
        "        print(f\"     Min: {np.min(post_offset_residual_degs):.6f}¬∞\")\n",
        "        print(f\"     Max: {post_offset_residual_deg_max:.6f}¬∞\")\n",
        "        print(f\"     Mean: {post_offset_residual_deg_mean:.6f}¬∞\")\n",
        "        print(f\"     Median: {post_offset_residual_deg_median:.6f}¬∞\")\n",
        "        \n",
        "        # VALIDATION B: Anatomy/V-pose validation for shoulders only\n",
        "        anatomy_deviation_deg = np.nan\n",
        "        anatomy_note = \"\"\n",
        "        \n",
        "        if joint_name in shoulder_joints and has_vpose_correction:\n",
        "            # Apply V-pose correction for anatomy validation\n",
        "            R_vpose = R.from_quat(v_pose_correction_quat)\n",
        "            anatomy_residuals = []\n",
        "            \n",
        "            for raw_quat in raw_quats:\n",
        "                R_raw = R.from_quat(raw_quat)\n",
        "                R_corr = R_offset * R_raw\n",
        "                R_anat = R_vpose * R_corr  # Apply V-pose: q_anat = q_vpose ‚äó q_corr\n",
        "                anatomy_residual = angle_from_quaternion(R_anat)\n",
        "                anatomy_residuals.append(anatomy_residual)\n",
        "            \n",
        "            anatomy_deviation_deg = np.mean(anatomy_residuals)\n",
        "            anatomy_note = \"V-pose applied\"\n",
        "        \n",
        "        # Determine euler_source based on joint type and processing (for informational purposes only)\n",
        "        if 'Shoulder' in joint_name:\n",
        "            euler_source = 'raw_parent_relative'  # Shoulders are parent-relative, NO V-pose in validation\n",
        "        elif joint_name in ['Hips', 'Spine', 'Head']:\n",
        "            euler_source = 'raw_world'  # World-relative joints\n",
        "        else:\n",
        "            euler_source = 'raw_parent_relative'  # Most joints are parent-relative\n",
        "        \n",
        "        # Get reference Euler angles (for informational purposes only)\n",
        "        ref_euler = reference_euler.get(joint_name, [0.0, 0.0, 0.0])\n",
        "        \n",
        "        # Create row for this joint\n",
        "        row_data = {\n",
        "            'joint_name': joint_name,\n",
        "            'euler_x_deg': ref_euler[0],  # Informational only\n",
        "            'euler_y_deg': ref_euler[1],  # Informational only\n",
        "            'euler_z_deg': ref_euler[2],  # Informational only\n",
        "            'euler_source': euler_source,  # Informational only\n",
        "            'post_offset_residual_deg': post_offset_residual_deg_median,  # VALIDATION A METRIC\n",
        "            'offset_angle_deg': offset_angle_deg,  # Informational only\n",
        "            'offset_quat_x': offset_quat[0],\n",
        "            'offset_quat_y': offset_quat[1],\n",
        "            'offset_quat_z': offset_quat[2],\n",
        "            'offset_quat_w': offset_quat[3],\n",
        "            'anatomy_deviation_deg': anatomy_deviation_deg,  # VALIDATION B METRIC (float)\n",
        "            'anatomy_note': anatomy_note  # VALIDATION B NOTE (string)\n",
        "        }\n",
        "        csv_data.append(row_data)\n",
        "        \n",
        "        # VALIDATION A: Check ONLY post_offset_residual_deg < 5¬∞ (true calibration validity)\n",
        "        if post_offset_residual_deg_median >= 5.0:\n",
        "            # For failing joints, debug the residual computation\n",
        "            R_raw_first = R.from_quat(raw_quats[0])\n",
        "            R_aligned_first = R_offset * R_raw_first\n",
        "            residual_first = angle_from_quaternion(R_aligned_first)\n",
        "            \n",
        "            validation_failures.append({\n",
        "                'joint': joint_name,\n",
        "                'post_offset_residual_deg_median': post_offset_residual_deg_median,\n",
        "                'post_offset_residual_deg_mean': post_offset_residual_deg_mean,\n",
        "                'post_offset_residual_deg_max': post_offset_residual_deg_max,\n",
        "                'offset_angle_deg': offset_angle_deg,\n",
        "                'euler_source': euler_source,\n",
        "                'first_raw_quat': raw_quats[0],\n",
        "                'offset_quat': offset_quat,\n",
        "                'residual_first_frame': residual_first,\n",
        "                'is_shoulder': joint_name in shoulder_joints,\n",
        "                'post_offset_residual_array': post_offset_residual_degs  # Store full array for analysis\n",
        "            })\n",
        "            print(f\"   ‚ùå VALIDATION FAILED: post_offset_residual {post_offset_residual_deg_median:.2f}¬∞ ‚â• 5¬∞\")\n",
        "            if joint_name in shoulder_joints:\n",
        "                print(f\"   üéØ SHOULDER EXPECTATION: Should be < 1¬∞ with proper static offset alignment\")\n",
        "        else:\n",
        "            print(f\"   ‚úÖ VALIDATION PASSED: post_offset_residual {post_offset_residual_deg_median:.2f}¬∞ < 5¬∞\")\n",
        "            if joint_name in shoulder_joints:\n",
        "                print(f\"   üéØ SHOULDER SUCCESS: Static offset alignment is correct\")\n",
        "        \n",
        "        # Collect anatomy results for summary\n",
        "        if joint_name in shoulder_joints:\n",
        "            anatomy_results.append({\n",
        "                'joint_name': joint_name,\n",
        "                'deviation': anatomy_deviation_deg if not np.isnan(anatomy_deviation_deg) else 0.0\n",
        "            })\n",
        "    \n",
        "    # Create DataFrame and save to CSV\n",
        "    df_csv = pd.DataFrame(csv_data)\n",
        "    \n",
        "    # Ensure proper dtypes to avoid pandas warnings\n",
        "    df_csv['anatomy_deviation_deg'] = df_csv['anatomy_deviation_deg'].astype(float)\n",
        "    df_csv['anatomy_note'] = df_csv['anatomy_note'].astype(str)\n",
        "    \n",
        "    df_csv = df_csv.sort_values('joint_name')  # Sort for consistency\n",
        "    df_csv.to_csv(output_path, index=False)\n",
        "    \n",
        "    return df_csv, validation_failures, anatomy_results\n",
        "\n",
        "# Export the enhanced CSV summary\n",
        "csv_output_path = os.path.join(DERIV_05, f\"{RUN_ID}__reference_summary.csv\")\n",
        "\n",
        "# Get the required data from previous cells\n",
        "offsets_map = globals().get('offsets_map', {})\n",
        "reference_euler = globals().get('REFERENCE_EULER', {})\n",
        "quat_metadata = globals().get('quat_metadata', {})\n",
        "\n",
        "if not offsets_map:\n",
        "    print(\"‚ùå ERROR: offsets_map not found. Run the calibration cells first.\")\n",
        "else:\n",
        "    print(f\"üîç DEBUG: Found offsets_map with {len(offsets_map)} joints\")\n",
        "    print(f\"üîç DEBUG: Found REFERENCE_EULER with {len(reference_euler)} joints\")\n",
        "    print(f\"üîç DEBUG: Found quat_metadata with keys: {list(quat_metadata.keys())}\")\n",
        "    \n",
        "    # Export CSV with split validation\n",
        "    df_summary, validation_failures, anatomy_results = export_reference_summary_csv_split(\n",
        "        ref_df=res['ref_df'],\n",
        "        offsets_map=offsets_map, \n",
        "        reference_euler=reference_euler,\n",
        "        quat_metadata=quat_metadata,\n",
        "        output_path=csv_output_path\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úÖ Enhanced reference summary CSV exported to: {csv_output_path}\")\n",
        "    \n",
        "    # üö® CRITICAL: PRINT FAILING JOINTS BEFORE ANYTHING ELSE\n",
        "    if validation_failures:\n",
        "        print(f\"\\nüö® FAILING JOINTS (>5¬∞ post_offset_residual):\")\n",
        "        for failure in validation_failures:\n",
        "            joint_name = failure['joint']\n",
        "            median_residual = failure['post_offset_residual_deg_median']\n",
        "            max_residual = failure['post_offset_residual_deg_max']\n",
        "            euler_source = failure['euler_source']\n",
        "            is_shoulder = failure['is_shoulder']\n",
        "            shoulder_note = \" (SHOULDER)\" if is_shoulder else \"\"\n",
        "            print(f\"   - {joint_name}: median={median_residual:.2f}¬∞ max={max_residual:.2f}¬∞ source={euler_source}{shoulder_note}\")\n",
        "    \n",
        "    # VALIDATION B: Print anatomy results (informational only)\n",
        "    print(f\"\\nüìä VALIDATION B RESULTS (Anatomy - Informational):\")\n",
        "    print(f\"   Shoulder joints analyzed: {len(anatomy_results)}\")\n",
        "    for result in anatomy_results:\n",
        "        deviation = result['deviation']\n",
        "        print(f\"   - {result['joint_name']}: deviation={deviation:.2f}¬∞\")\n",
        "    \n",
        "    # Display summary statistics BASED ONLY ON post_offset_residual_deg (VALIDATION A)\n",
        "    print(f\"\\nüìä REFERENCE SUMMARY STATISTICS (BASED ONLY ON post_offset_residual_deg):\")\n",
        "    print(f\"   Total joints: {len(df_summary)}\")\n",
        "    \n",
        "    # Check residual magnitudes against pass condition (ONLY post_offset_residual_deg)\n",
        "    high_residual_joints = df_summary[df_summary['post_offset_residual_deg'] > 10.0]\n",
        "    medium_residual_joints = df_summary[(df_summary['post_offset_residual_deg'] > 5.0) & (df_summary['post_offset_residual_deg'] <= 10.0)]\n",
        "    good_residual_joints = df_summary[df_summary['post_offset_residual_deg'] <= 3.0]\n",
        "    \n",
        "    print(f\"   Joints with post_offset_residual ‚â§ 3¬∞: {len(good_residual_joints)} ‚úÖ\")\n",
        "    print(f\"   Joints with post_offset_residual 3-5¬∞: {len(medium_residual_joints)} ‚ö†Ô∏è\")\n",
        "    print(f\"   Joints with post_offset_residual 5-10¬∞: {len(df_summary[(df_summary['post_offset_residual_deg'] >= 5.0) & (df_summary['post_offset_residual_deg'] <= 10.0)])} ‚ö†Ô∏è\")\n",
        "    print(f\"   Joints with post_offset_residual > 10¬∞: {len(high_residual_joints)} ‚ùå\")\n",
        "    \n",
        "    # Report validation failures with detailed debug info - BUT DON'T RAISE ERROR\n",
        "    if validation_failures:\n",
        "        print(f\"\\n‚ùå DETAILED VALIDATION FAILURES:\")\n",
        "        \n",
        "        # Sort failures by residual value (worst first)\n",
        "        validation_failures_sorted = sorted(validation_failures, key=lambda x: x['post_offset_residual_deg_median'], reverse=True)\n",
        "        \n",
        "        for i, failure in enumerate(validation_failures_sorted, 1):\n",
        "            residual_deg = failure['post_offset_residual_deg_median']\n",
        "            offset_angle = failure['offset_angle_deg']\n",
        "            \n",
        "            print(f\"\\n   {i}. üö® JOINT: {failure['joint']}\")\n",
        "            print(f\"      Post-offset residual: {residual_deg:.2f}¬∞ (FAILS by {residual_deg - 5.0:.2f}¬∞)\")\n",
        "            print(f\"      Offset angle (info): {offset_angle:.2f}¬∞\")\n",
        "            print(f\"      First frame residual: {failure['residual_first_frame']:.6f}¬∞\")\n",
        "            \n",
        "            if failure['is_shoulder']:\n",
        "                print(f\"      üéØ SHOULDER ANALYSIS: Static offset alignment should be < 1¬∞\")\n",
        "                print(f\"      üéØ CURRENT RESULT: {residual_deg:.2f}¬∞ (expecting < 1¬∞)\")\n",
        "        \n",
        "        # Summary of failure analysis\n",
        "        print(f\"\\nüìà FAILURE ANALYSIS:\")\n",
        "        worst_joint = validation_failures_sorted[0]\n",
        "        print(f\"   Worst joint: {worst_joint['joint']} ({worst_joint['post_offset_residual_deg_median']:.2f}¬∞)\")\n",
        "        print(f\"   Average failing residual: {np.mean([f['post_offset_residual_deg_median'] for f in validation_failures]):.2f}¬∞\")\n",
        "        print(f\"   Failure range: {min([f['post_offset_residual_deg_median'] for f in validation_failures]):.2f}¬∞ - {max([f['post_offset_residual_deg_median'] for f in validation_failures]):.2f}¬∞\")\n",
        "        \n",
        "        # Check shoulder-specific failures\n",
        "        shoulder_failures = [f for f in validation_failures if f['is_shoulder']]\n",
        "        if shoulder_failures:\n",
        "            print(f\"   üéØ SHOULDER FAILURES: {len(shoulder_failures)} shoulder joints still failing\")\n",
        "            print(f\"   üéØ EXPECTATION: Shoulders should be < 1¬∞ with proper static offset alignment\")\n",
        "            for shoulder in shoulder_failures:\n",
        "                print(f\"   üéØ {shoulder['joint']}: {shoulder['post_offset_residual_deg_median']:.2f}¬∞ (expecting < 1¬∞)\")\n",
        "    \n",
        "    # Show euler_source distribution (informational only)\n",
        "    source_counts = df_summary['euler_source'].value_counts()\n",
        "    print(f\"\\nüîÑ EULER SOURCE DISTRIBUTION (INFORMATIONAL ONLY):\")\n",
        "    for source, count in source_counts.items():\n",
        "        print(f\"   {source}: {count} joints\")\n",
        "    \n",
        "    # Display first few rows as preview with the two key columns\n",
        "    print(f\"\\nüìã CSV PREVIEW (KEY COLUMNS - SORTED BY RESIDUAL):\")\n",
        "    preview_cols = ['joint_name', 'post_offset_residual_deg', 'offset_angle_deg']\n",
        "    df_preview = df_summary[preview_cols].sort_values('post_offset_residual_deg', ascending=False)\n",
        "    print(df_preview.head(15).to_string(index=False))\n",
        "    \n",
        "    print(f\"\\nüéØ PASS CONDITION CHECK (BASED ONLY ON post_offset_residual_deg):\")\n",
        "    shoulders = df_summary[df_summary['joint_name'].str.contains('Shoulder')]\n",
        "    other_joints = df_summary[~df_summary['joint_name'].str.contains('Shoulder')]\n",
        "    \n",
        "    shoulder_pass = len(shoulders[shoulders['post_offset_residual_deg'] <= 8.0]) == len(shoulders)  # Higher threshold for shoulders\n",
        "    other_pass = len(other_joints[other_joints['post_offset_residual_deg'] <= 5.0]) >= len(other_joints) * 0.8  # 80% of other joints\n",
        "    \n",
        "    if shoulder_pass and other_pass:\n",
        "        print(\"   ‚úÖ PASS: Reference window quality is acceptable\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è  WARNING: Reference window may need review\")\n",
        "        \n",
        "    print(f\"\\nüìà POST-OFFSET RESIDUAL DISTRIBUTION (VALIDATION METRIC):\")\n",
        "    print(f\"   Min post_offset_residual: {df_summary['post_offset_residual_deg'].min():.2f}¬∞\")\n",
        "    print(f\"   Max post_offset_residual: {df_summary['post_offset_residual_deg'].max():.2f}¬∞\")\n",
        "    print(f\"   Mean post_offset_residual: {df_summary['post_offset_residual_deg'].mean():.2f}¬∞\")\n",
        "    print(f\"   Median post_offset_residual: {df_summary['post_offset_residual_deg'].median():.2f}¬∞\")\n",
        "    \n",
        "    print(f\"\\nüìä OFFSET ANGLE DISTRIBUTION (INFORMATIONAL ONLY):\")\n",
        "    print(f\"   Min offset_angle: {df_summary['offset_angle_deg'].min():.2f}¬∞\")\n",
        "    print(f\"   Max offset_angle: {df_summary['offset_angle_deg'].max():.2f}¬∞\")\n",
        "    print(f\"   Mean offset_angle: {df_summary['offset_angle_deg'].mean():.2f}¬∞\")\n",
        "    print(f\"   Median offset_angle: {df_summary['offset_angle_deg'].median():.2f}¬∞\")\n",
        "    \n",
        "    print(f\"\\nüéØ DEFINITION OF DONE CHECK:\")\n",
        "    excellent_joints = len(df_summary[df_summary['post_offset_residual_deg'] <= 3.0])\n",
        "    acceptable_joints = len(df_summary[(df_summary['post_offset_residual_deg'] > 3.0) & (df_summary['post_offset_residual_deg'] <= 5.0)])\n",
        "    problematic_joints = len(df_summary[df_summary['post_offset_residual_deg'] > 5.0])\n",
        "    \n",
        "    print(f\"   Excellent (‚â§3¬∞): {excellent_joints}/{len(df_summary)} joints ({100*excellent_joints/len(df_summary):.1f}%)\")\n",
        "    print(f\"   Acceptable (3-5¬∞): {acceptable_joints}/{len(df_summary)} joints ({100*acceptable_joints/len(df_summary):.1f}%)\")\n",
        "    print(f\"   Problematic (>5¬∞): {problematic_joints}/{len(df_summary)} joints ({100*problematic_joints/len(df_summary):.1f}%)\")\n",
        "    \n",
        "    if problematic_joints == 0:\n",
        "        print(\"   ‚úÖ DEFINITION OF DONE MET: All joints have post_offset_residual ‚â§ 5¬∞\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è  DEFINITION OF NOT MET: {problematic_joints} joints need investigation\")\n",
        "        print(f\"   üéØ SHOULDER EXPECTATION: Shoulders should be < 1¬∞ with proper static offset alignment\")\n",
        "    \n",
        "    # Show shoulder-specific results\n",
        "    shoulders = df_summary[df_summary['joint_name'].str.contains('Shoulder')]\n",
        "    if len(shoulders) > 0:\n",
        "        print(f\"\\nüéØ SHOULDER VALIDATION RESULTS:\")\n",
        "        print(f\"   {'Joint':<15} {'Residual':<10} {'Status':<10}\")\n",
        "        print(f\"   {'-'*40}\")\n",
        "        for _, shoulder in shoulders.iterrows():\n",
        "            residual = shoulder['post_offset_residual_deg']\n",
        "            status = \"‚úÖ PASS\" if residual < 1.0 else \"‚ùå FAIL\" if residual >= 5.0 else \"‚ö†Ô∏è WARN\"\n",
        "            print(f\"   {shoulder['joint_name']:<15} {residual:<10.2f}¬∞ {status:<10}\")\n",
        "    \n",
        "    # Export metadata with all required keys\n",
        "    metadata_path = os.path.join(DERIV_05, f\"{RUN_ID}__reference_metadata.json\")\n",
        "    \n",
        "    # Extract V-pose correction from metadata again for this section\n",
        "    v_pose_correction_quat = quat_metadata.get('v_pose_correction_quat_xyzw')\n",
        "    shoulder_joints = quat_metadata.get('shoulder_joints', ['LeftShoulder', 'RightShoulder'])\n",
        "    has_vpose_correction = v_pose_correction_quat is not None and not np.allclose(v_pose_correction_quat, [0, 0, 0, 1])\n",
        "    \n",
        "    reference_metadata = {\n",
        "        \"validation_mode_identity\": True,\n",
        "        \"vpose_validation_frame\": \"anatomical\",\n",
        "        \"euler_order_used\": \"XYZ\",\n",
        "        \"vpose_mult_order\": \"left\",\n",
        "        \"identity_tolerance_deg\": 5.0,\n",
        "        \"shoulder_joints\": shoulder_joints,\n",
        "        \"vpose_correction_applied\": has_vpose_correction,\n",
        "        # Preserve all existing quat_metadata keys\n",
        "        \"fs\": quat_metadata.get(\"fs\"),\n",
        "        \"window_duration_sec\": quat_metadata.get(\"window_duration_sec\"),\n",
        "        \"quat_order\": quat_metadata.get(\"quat_order\"),\n",
        "        \"hemisphere_alignment_applied\": quat_metadata.get(\"hemisphere_alignment_applied\"),\n",
        "        \"v_pose_correction_applied\": quat_metadata.get(\"v_pose_correction_applied\"),\n",
        "        \"v_pose_correction_quat_xyzw\": quat_metadata.get(\"v_pose_correction_quat_xyzw\"),\n",
        "        \"time_window\": quat_metadata.get(\"time_window\"),\n",
        "        # NEW: Reference Detection Quality Metrics (from find_stable_window)\n",
        "        \"ref_quality_score\": window_metadata.get(\"ref_quality_score\"),\n",
        "        \"confidence_level\": window_metadata.get(\"confidence_level\"),\n",
        "        \"ref_is_fallback\": window_metadata.get(\"ref_is_fallback\"),\n",
        "        \"detection_method\": window_metadata.get(\"detection_method\"),\n",
        "        \"mean_motion\": window_metadata.get(\"mean_motion\"),\n",
        "        \"max_motion\": window_metadata.get(\"max_motion\"),\n",
        "        \"variance_score\": window_metadata.get(\"variance_score\"),\n",
        "        \"variance_threshold\": window_metadata.get(\"variance_threshold\")\n",
        "    }\n",
        "    \n",
        "    with open(metadata_path, 'w') as f:\n",
        "        json.dump(reference_metadata, f, indent=4)\n",
        "    print(f\"\\n‚úÖ Reference metadata exported to: {metadata_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862a15c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 07: Final Data Diagnostic ---\n",
        "# RATIONALE: Manual verification of raw spatial relationships to prevent \n",
        "# geometric distortion in joint angle calculations (Winter, 2009).\n",
        "\n",
        "def run_diagnostic_test(df):\n",
        "    print(f\"üß™ --- BIOMECHANICAL AUDIT: {RUN_ID} --- üß™\\n\")\n",
        "    \n",
        "    # 1. Column Identification\n",
        "    hips = [c for c in df.columns if 'Hips__p' in c]\n",
        "    l_hand = [c for c in df.columns if any(x in c for x in ['L_Hand__p', 'LeftHand__p'])]\n",
        "    r_hand = [c for c in df.columns if any(x in c for x in ['R_Hand__p', 'RightHand__p'])]\n",
        "    \n",
        "    if not (hips and l_hand and r_hand):\n",
        "        print(\"‚ùå CRITICAL: Required markers missing from dataset.\")\n",
        "        return\n",
        "\n",
        "    # 2. Unit Detection Logic\n",
        "    sample_val = abs(df[hips[0]].iloc[0])\n",
        "    unit = \"METERS\" if sample_val < 50 else \"MILLIMETERS\"\n",
        "    sf_to_cm = 100 if unit == \"METERS\" else 0.1\n",
        "    print(f\"üìç Reference Position: {sample_val:.2f} | Detected: {unit}\")\n",
        "\n",
        "    # 3. Euclidean Distance Validation (Anatomical Check)\n",
        "    h_pos = df[hips].iloc[0].values\n",
        "    l_pos = df[l_hand].iloc[0].values\n",
        "    r_pos = df[r_hand].iloc[0].values\n",
        "\n",
        "    total_span_raw = np.linalg.norm(l_pos - r_pos)\n",
        "    span_cm = total_span_raw * sf_to_cm\n",
        "    \n",
        "    print(f\"\\nüìè ANTHROPOMETRIC MEASUREMENTS:\")\n",
        "    print(f\" - Total Arm Span: {span_cm:.1f} cm\")\n",
        "    if SUBJECT_HEIGHT:\n",
        "        print(f\" - Reported Height: {SUBJECT_HEIGHT:.1f} cm\")\n",
        "        deviation = abs(span_cm - SUBJECT_HEIGHT) / SUBJECT_HEIGHT * 100\n",
        "        print(f\" - Stature Deviation: {deviation:.1f}%\")\n",
        "\n",
        "    # 4. Final Verdict\n",
        "    print(\"\\n--- SCIENTIFIC VERDICT ---\")\n",
        "    if span_cm > 250:\n",
        "        print(\"‚ùå FAIL: Geometric distortion detected. Potential 'Ghost Markers' or reflections.\")\n",
        "    elif span_cm < 50:\n",
        "        print(\"‚ùå FAIL: Markers collapsed. Check for occlusions during T-Pose.\")\n",
        "    elif SUBJECT_HEIGHT and deviation > 15:\n",
        "        print(\"‚ö†Ô∏è  WARNING: High deviation from expected proportions. Verify marker placement.\")\n",
        "    else:\n",
        "        print(\"‚úÖ PASS: Marker geometry is consistent with human anatomy.\")\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "run_diagnostic_test(df)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
