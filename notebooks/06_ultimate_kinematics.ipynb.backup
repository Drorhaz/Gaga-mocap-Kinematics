{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ultimate Kinematic Gold Standard Pipeline (Step 06)\n",
        "\n",
        "Unified, production-grade kinematics: root-relative positions, hierarchical dual-track (raw vs zeroed), Savitzky–Golay on quaternions, physiological audit, and hard-proof validation.\n",
        "\n",
        "**Outputs:** `derivatives/step_06_kinematics/ultimate/{RUN_ID}__kinematics_master.parquet`, `{RUN_ID}__validation_report.json`, and Plotly dashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RUN_ID: 734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002, FPS: 120.0, Root: Hips, Frames: 16503, SavGol window: 21\n",
            "ENFORCE_CLEANING: False\n",
            "OMEGA_METHOD: quat_log, OMEGA_FRAME: local\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy.spatial.transform import Rotation as R\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "if os.path.basename(os.getcwd()) == 'notebooks':\n",
        "    PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "else:\n",
        "    PROJECT_ROOT = os.path.abspath(os.getcwd())\n",
        "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
        "if SRC_PATH not in sys.path:\n",
        "    sys.path.insert(0, SRC_PATH)\n",
        "\n",
        "from pipeline_config import CONFIG\n",
        "from angular_velocity import compute_omega_and_alpha, compare_angular_velocity_methods\n",
        "from kinematic_repair import identify_critical_units, apply_surgical_repair\n",
        "\n",
        "ENFORCE_CLEANING = CONFIG.get(\"ENFORCE_CLEANING\", False)\n",
        "OMEGA_METHOD = CONFIG.get(\"OMEGA_METHOD\", \"quat_log\")\n",
        "OMEGA_FRAME = \"local\" if (CONFIG.get(\"OMEGA_FRAME\") or \"child_body\").lower() in (\"child_body\", \"local\") else \"global\"\n",
        "\n",
        "DERIV_FILTERED = os.path.join(PROJECT_ROOT, CONFIG['derivatives_dir'], \"step_04_filtering\")\n",
        "DERIV_REF = os.path.join(PROJECT_ROOT, CONFIG['derivatives_dir'], \"step_05_reference\")\n",
        "OUT_DIR = os.path.join(PROJECT_ROOT, CONFIG['derivatives_dir'], \"step_06_kinematics\", \"ultimate\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "RUN_ID = Path(CONFIG['current_csv']).stem\n",
        "FS = float(CONFIG.get('FS_TARGET', 120.0))\n",
        "SG_WINDOW_SEC = CONFIG.get('SG_WINDOW_SEC', 0.175)\n",
        "SG_POLYORDER = CONFIG.get('SG_POLYORDER', 3)\n",
        "dt = 1.0 / FS\n",
        "\n",
        "INPUT_PARQUET = Path(DERIV_FILTERED) / f\"{RUN_ID}__filtered.parquet\"\n",
        "if not INPUT_PARQUET.exists():\n",
        "    raise FileNotFoundError(f\"Step 04 output not found: {INPUT_PARQUET}\")\n",
        "\n",
        "df_in = pd.read_parquet(INPUT_PARQUET)\n",
        "n_frames = len(df_in)\n",
        "\n",
        "map_path = Path(DERIV_REF) / f\"{RUN_ID}__kinematics_map.json\"\n",
        "if not map_path.exists():\n",
        "    map_path = Path(PROJECT_ROOT) / CONFIG['derivatives_dir'] / \"step_03_resample\" / f\"{RUN_ID}__kinematics_map.json\"\n",
        "with open(map_path, 'r', encoding='utf-8') as f:\n",
        "    kinematics_map = json.load(f)\n",
        "\n",
        "ref_path = Path(DERIV_REF) / f\"{RUN_ID}__reference_map.json\"\n",
        "if not ref_path.exists():\n",
        "    raise FileNotFoundError(f\"Reference map not found: {ref_path}\")\n",
        "with open(ref_path, 'r', encoding='utf-8') as f:\n",
        "    ref_pose = json.load(f)\n",
        "\n",
        "ROOT_SEGMENT = 'Pelvis' if 'Pelvis' in kinematics_map else 'Hips'\n",
        "\n",
        "def savgol_window_len(fs, w_sec, polyorder):\n",
        "    w_len = int(round(w_sec * fs))\n",
        "    if w_len % 2 == 0:\n",
        "        w_len += 1\n",
        "    w_len = max(5, w_len, polyorder + 2)\n",
        "    if w_len % 2 == 0:\n",
        "        w_len += 1\n",
        "    return w_len\n",
        "\n",
        "W_LEN = savgol_window_len(FS, SG_WINDOW_SEC, SG_POLYORDER)\n",
        "print(f\"RUN_ID: {RUN_ID}, FPS: {FS}, Root: {ROOT_SEGMENT}, Frames: {n_frames}, SavGol window: {W_LEN}\")\n",
        "print(f\"ENFORCE_CLEANING: {ENFORCE_CLEANING}\")\n",
        "print(f\"OMEGA_METHOD: {OMEGA_METHOD}, OMEGA_FRAME: {OMEGA_FRAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helpers: Quaternion unrolling and renormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def unroll_quat(q):\n",
        "    \"\"\"Ensure temporal continuity (shortest path); q shape (T, 4).\"\"\"\n",
        "    q = np.asarray(q, dtype=float)\n",
        "    if q.ndim == 1:\n",
        "        q = q.reshape(1, -1)\n",
        "    out = q.copy()\n",
        "    for i in range(1, len(out)):\n",
        "        if np.dot(out[i], out[i - 1]) < 0:\n",
        "            out[i] *= -1\n",
        "    return out\n",
        "\n",
        "def renormalize_quat(q):\n",
        "    \"\"\"Unit norm per row; q shape (T, 4).\"\"\"\n",
        "    n = np.linalg.norm(q, axis=1, keepdims=True)\n",
        "    n = np.where(n < 1e-12, 1.0, n)\n",
        "    return q / n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Root-relative positions and dual-track quaternion processing\n",
        "\n",
        "For each joint: hierarchical q_rel = inv(parent)*child → unroll → SavGol smooth → renormalize (Track A). Track B: q_zeroed = inv(q_ref_rel)*q_raw_smooth. Then ω from quat_log, α from SavGol derivative on ω. Linear v,a from root-relative positions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m joint_name \u001b[38;5;129;01min\u001b[39;00m kinematics_map:\n\u001b[0;32m      6\u001b[0m     qc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__zeroed_rel_qx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__zeroed_rel_qy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__zeroed_rel_qz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__zeroed_rel_qw\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mqc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     q_zeroed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([result[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m qc])\n",
            "Cell \u001b[1;32mIn[3], line 7\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m joint_name \u001b[38;5;129;01min\u001b[39;00m kinematics_map:\n\u001b[0;32m      6\u001b[0m     qc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__zeroed_rel_qx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__zeroed_rel_qy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__zeroed_rel_qz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__zeroed_rel_qw\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m qc):\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     q_zeroed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([result[c] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m qc])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ],
      "source": [
        "# Add magnitude and rotation vector features to result (required for ML/HMM/RQA)\n",
        "# These are the master features as per specification\n",
        "\n",
        "# A. Add rotation vector (rotvec) and rotation magnitude (rotmag) for zeroed quaternions\n",
        "for joint_name in kinematics_map:\n",
        "    qc = [f\"{joint_name}__zeroed_rel_qx\", f\"{joint_name}__zeroed_rel_qy\", f\"{joint_name}__zeroed_rel_qz\", f\"{joint_name}__zeroed_rel_qw\"]\n",
        "    if not all(c in result for c in qc):\n",
        "        continue\n",
        "    q_zeroed = np.column_stack([result[c] for c in qc])\n",
        "    # Rotation vector (rotvec) in radians\n",
        "    rotvec = R.from_quat(q_zeroed).as_rotvec()\n",
        "    for ax, letter in enumerate(['x', 'y', 'z']):\n",
        "        result[f\"{joint_name}__zeroed_rel_rotvec_{letter}\"] = rotvec[:, ax]\n",
        "    # Rotation magnitude (geodesic distance from T-pose) in degrees\n",
        "    result[f\"{joint_name}__zeroed_rel_rotmag\"] = np.degrees(np.linalg.norm(rotvec, axis=1))\n",
        "\n",
        "# B. Add angular velocity magnitude (omega_mag) and angular acceleration magnitude (alpha_mag)\n",
        "for joint_name in kinematics_map:\n",
        "    # Zeroed omega magnitude\n",
        "    omega_cols = [f\"{joint_name}__zeroed_rel_omega_x\", f\"{joint_name}__zeroed_rel_omega_y\", f\"{joint_name}__zeroed_rel_omega_z\"]\n",
        "    if all(c in result for c in omega_cols):\n",
        "        omega_vec = np.column_stack([result[c] for c in omega_cols])\n",
        "        result[f\"{joint_name}__zeroed_rel_omega_mag\"] = np.linalg.norm(omega_vec, axis=1)\n",
        "    \n",
        "    # Zeroed alpha magnitude\n",
        "    alpha_cols = [f\"{joint_name}__zeroed_rel_alpha_x\", f\"{joint_name}__zeroed_rel_alpha_y\", f\"{joint_name}__zeroed_rel_alpha_z\"]\n",
        "    if all(c in result for c in alpha_cols):\n",
        "        alpha_vec = np.column_stack([result[c] for c in alpha_cols])\n",
        "        result[f\"{joint_name}__zeroed_rel_alpha_mag\"] = np.linalg.norm(alpha_vec, axis=1)\n",
        "\n",
        "# C. Add linear velocity and acceleration magnitudes\n",
        "segments_with_pos = set(col.split('__')[0] for col in pos_cols if col in pos_rel)\n",
        "for seg in segments_with_pos:\n",
        "    # Linear velocity magnitude\n",
        "    vel_cols = [f\"{seg}__lin_vel_rel_x\", f\"{seg}__lin_vel_rel_y\", f\"{seg}__lin_vel_rel_z\"]\n",
        "    if all(c in result for c in vel_cols):\n",
        "        vel_vec = np.column_stack([result[c] for c in vel_cols])\n",
        "        result[f\"{seg}__lin_vel_rel_mag\"] = np.linalg.norm(vel_vec, axis=1)\n",
        "    \n",
        "    # Linear acceleration magnitude\n",
        "    acc_cols = [f\"{seg}__lin_acc_rel_x\", f\"{seg}__lin_acc_rel_y\", f\"{seg}__lin_acc_rel_z\"]\n",
        "    if all(c in result for c in acc_cols):\n",
        "        acc_vec = np.column_stack([result[c] for c in acc_cols])\n",
        "        result[f\"{seg}__lin_acc_rel_mag\"] = np.linalg.norm(acc_vec, axis=1)\n",
        "\n",
        "# D. Add root-relative positions (lin_rel_px, py, pz)\n",
        "for col in pos_cols:\n",
        "    seg, suffix = col.split('__')[0], '__' + col.split('__')[1]\n",
        "    if col in pos_rel:\n",
        "        axis_letter = col[-1]\n",
        "        result[f\"{seg}__lin_rel_p{axis_letter}\"] = pos_rel[col]\n",
        "\n",
        "print(f\"Added derived features: rotvec (x,y,z), rotmag, omega_mag, alpha_mag, vel_mag, acc_mag, and lin_rel positions for {len(validation_rows)} joints and {len(segments_with_pos)} segments.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Root-relative positions\n",
        "root_pos_cols = [f\"{ROOT_SEGMENT}__px\", f\"{ROOT_SEGMENT}__py\", f\"{ROOT_SEGMENT}__pz\"]\n",
        "root_pos = df_in[root_pos_cols].values if all(c in df_in.columns for c in root_pos_cols) else None\n",
        "pos_cols = [c for c in df_in.columns if c.endswith(('__px', '__py', '__pz')) and df_in[c].notna().all()]\n",
        "axis_idx = {'__px': 0, '__py': 1, '__pz': 2}\n",
        "pos_rel = {}\n",
        "if root_pos is not None:\n",
        "    for col in pos_cols:\n",
        "        seg, suffix = col.split('__')[0], '__' + col.split('__')[1]\n",
        "        idx = axis_idx.get(suffix, 0)\n",
        "        pos_rel[col] = df_in[col].values - root_pos[:, idx]\n",
        "\n",
        "# Master result: time_s first\n",
        "result = {'time_s': df_in['time_s'].values}\n",
        "validation_rows = []\n",
        "OMEGA_THRESH = 3000.0\n",
        "LIN_ACC_THRESH = 20000.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Master Parquet Feature Set (Gold Standard for ML/HMM/RQA)\n",
        "\n",
        "The exported `kinematics_master.parquet` contains the following feature categories per joint/segment:\n",
        "\n",
        "### A. Orientation (Posture) - Per Joint\n",
        "- `{joint}__raw_rel_qx, qy, qz, qw`: Original hierarchical quaternions (parent→child)\n",
        "- `{joint}__zeroed_rel_qx, qy, qz, qw`: T-pose normalized quaternions\n",
        "- `{joint}__zeroed_rel_rotvec_x, y, z`: **Rotation Vector in rad** (crucial for HMM/ML)\n",
        "- `{joint}__zeroed_rel_rotmag`: **Geodesic distance from T-pose in deg** (crucial for RQA)\n",
        "\n",
        "### B. Angular Kinematics (Zeroed Track) - Per Joint\n",
        "- `{joint}__zeroed_rel_omega_x, y, z`: Angular velocity vector in deg/s\n",
        "- `{joint}__zeroed_rel_omega_mag`: **Angular velocity magnitude in deg/s** (invariant)\n",
        "- `{joint}__zeroed_rel_alpha_x, y, z`: Angular acceleration vector in deg/s²\n",
        "- `{joint}__zeroed_rel_alpha_mag`: **Angular acceleration magnitude in deg/s²**\n",
        "\n",
        "### C. Linear Kinematics (Root-Relative) - Per Segment\n",
        "- `{segment}__lin_rel_px, py, pz`: Root-relative position in mm\n",
        "- `{segment}__lin_vel_rel_x, y, z`: Linear velocity vector in mm/s\n",
        "- `{segment}__lin_vel_rel_mag`: **Linear velocity magnitude in mm/s**\n",
        "- `{segment}__lin_acc_rel_x, y, z`: Linear acceleration vector in mm/s²\n",
        "- `{segment}__lin_acc_rel_mag`: **Linear acceleration magnitude in mm/s²**\n",
        "\n",
        "**Note:** Raw angular features (raw_rel_omega, raw_rel_alpha) are also included for comparison and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for joint_name, info in kinematics_map.items():\n",
        "    parent_name = info.get('parent')\n",
        "    q_c_cols = [f\"{joint_name}__qx\", f\"{joint_name}__qy\", f\"{joint_name}__qz\", f\"{joint_name}__qw\"]\n",
        "    if not all(c in df_in.columns for c in q_c_cols):\n",
        "        continue\n",
        "    q_c = df_in[q_c_cols].values\n",
        "    if parent_name is not None:\n",
        "        q_p_cols = [f\"{parent_name}__qx\", f\"{parent_name}__qy\", f\"{parent_name}__qz\", f\"{parent_name}__qw\"]\n",
        "        if not all(c in df_in.columns for c in q_p_cols):\n",
        "            continue\n",
        "        q_p = df_in[q_p_cols].values\n",
        "        rot_p = R.from_quat(q_p)\n",
        "        rot_c = R.from_quat(q_c)\n",
        "        q_rel = (rot_p.inv() * rot_c).as_quat()\n",
        "    else:\n",
        "        q_rel = q_c.copy()\n",
        "    q_rel = unroll_quat(q_rel)\n",
        "    for ax, i in enumerate(['x', 'y', 'z', 'w']):\n",
        "        q_rel[:, ax] = savgol_filter(q_rel[:, ax], W_LEN, SG_POLYORDER, mode='interp')\n",
        "    q_raw_smooth = renormalize_quat(q_rel)\n",
        "    q_ref_c = np.array([ref_pose[f\"{joint_name}__qx\"], ref_pose[f\"{joint_name}__qy\"], ref_pose[f\"{joint_name}__qz\"], ref_pose[f\"{joint_name}__qw\"]])\n",
        "    if parent_name is not None:\n",
        "        q_ref_p = np.array([ref_pose[f\"{parent_name}__qx\"], ref_pose[f\"{parent_name}__qy\"], ref_pose[f\"{parent_name}__qz\"], ref_pose[f\"{parent_name}__qw\"]])\n",
        "        q_rel_ref = (R.from_quat(q_ref_p).inv() * R.from_quat(q_ref_c)).as_quat()\n",
        "    else:\n",
        "        q_rel_ref = q_ref_c\n",
        "    rot_ref = R.from_quat(q_rel_ref)\n",
        "    q_zeroed = (rot_ref.inv() * R.from_quat(q_raw_smooth)).as_quat()\n",
        "    q_zeroed = renormalize_quat(q_zeroed)\n",
        "    omega_raw_rad, alpha_raw_rad = compute_omega_and_alpha(q_raw_smooth, FS, method=OMEGA_METHOD, frame=OMEGA_FRAME, savgol_window=W_LEN, savgol_poly=SG_POLYORDER)\n",
        "    omega_zeroed_rad, alpha_zeroed_rad = compute_omega_and_alpha(q_zeroed, FS, method=OMEGA_METHOD, frame=OMEGA_FRAME, savgol_window=W_LEN, savgol_poly=SG_POLYORDER)\n",
        "    omega_raw_deg = np.degrees(omega_raw_rad)\n",
        "    omega_zeroed_deg = np.degrees(omega_zeroed_rad)\n",
        "    alpha_raw = np.degrees(alpha_raw_rad)\n",
        "    alpha_zeroed = np.degrees(alpha_zeroed_rad)\n",
        "    for ax, letter in enumerate(['x', 'y', 'z']):\n",
        "        result[f\"{joint_name}__raw_rel_omega_{letter}\"] = omega_raw_deg[:, ax]\n",
        "        result[f\"{joint_name}__zeroed_rel_omega_{letter}\"] = omega_zeroed_deg[:, ax]\n",
        "    for ax, letter in enumerate(['x', 'y', 'z']):\n",
        "        result[f\"{joint_name}__raw_rel_alpha_{letter}\"] = alpha_raw[:, ax]\n",
        "        result[f\"{joint_name}__zeroed_rel_alpha_{letter}\"] = alpha_zeroed[:, ax]\n",
        "    for ax, letter in enumerate(['x', 'y', 'z', 'w']):\n",
        "        result[f\"{joint_name}__raw_rel_q{letter}\"] = q_raw_smooth[:, ax]\n",
        "        result[f\"{joint_name}__zeroed_rel_q{letter}\"] = q_zeroed[:, ax]\n",
        "    mag_omega_raw = np.linalg.norm(omega_raw_deg, axis=1)\n",
        "    mag_omega_zeroed = np.linalg.norm(omega_zeroed_deg, axis=1)\n",
        "    geodesic_deg = np.degrees(2 * np.arccos(np.clip(np.abs((q_raw_smooth * q_zeroed).sum(axis=1)), 0, 1)))\n",
        "    vel_align = 100.0 * pearsonr(mag_omega_raw, mag_omega_zeroed)[0] if np.std(mag_omega_raw) > 1e-10 else 100.0\n",
        "    validation_rows.append({\n",
        "        'joint': joint_name,\n",
        "        'geodesic_offset_std': round(float(np.std(geodesic_deg)), 6),\n",
        "        'velocity_alignment_pct': round(vel_align, 2),\n",
        "        'max_omega_deg_s': round(float(np.max(mag_omega_raw)), 2),\n",
        "        'mean_omega_deg_s': round(float(np.mean(mag_omega_raw)), 2),\n",
        "        'median_omega_deg_s': round(float(np.median(mag_omega_raw)), 2),\n",
        "        'exceeded_omega_threshold': bool(np.max(mag_omega_raw) > OMEGA_THRESH),\n",
        "    })\n",
        "print(f\"Processed {len(validation_rows)} joints (dual-track omega, alpha, quaternions).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validate Master Feature Set Completeness (Pre-Export Check)\n",
        "required_features_per_joint = {\n",
        "    'orientation': ['raw_rel_qx', 'raw_rel_qy', 'raw_rel_qz', 'raw_rel_qw',\n",
        "                    'zeroed_rel_qx', 'zeroed_rel_qy', 'zeroed_rel_qz', 'zeroed_rel_qw',\n",
        "                    'zeroed_rel_rotvec_x', 'zeroed_rel_rotvec_y', 'zeroed_rel_rotvec_z',\n",
        "                    'zeroed_rel_rotmag'],\n",
        "    'angular_kinematics': ['zeroed_rel_omega_x', 'zeroed_rel_omega_y', 'zeroed_rel_omega_z', 'zeroed_rel_omega_mag',\n",
        "                          'zeroed_rel_alpha_x', 'zeroed_rel_alpha_y', 'zeroed_rel_alpha_z', 'zeroed_rel_alpha_mag']\n",
        "}\n",
        "\n",
        "required_features_per_segment = {\n",
        "    'linear_kinematics': ['lin_rel_px', 'lin_rel_py', 'lin_rel_pz',\n",
        "                         'lin_vel_rel_x', 'lin_vel_rel_y', 'lin_vel_rel_z', 'lin_vel_rel_mag',\n",
        "                         'lin_acc_rel_x', 'lin_acc_rel_y', 'lin_acc_rel_z', 'lin_acc_rel_mag']\n",
        "}\n",
        "\n",
        "print(\"Feature Set Validation:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check joints\n",
        "sample_joint = next(iter(kinematics_map.keys()), None)\n",
        "if sample_joint:\n",
        "    missing_orientation = [f for f in required_features_per_joint['orientation'] if f\"{sample_joint}__{f}\" not in result]\n",
        "    missing_angular = [f for f in required_features_per_joint['angular_kinematics'] if f\"{sample_joint}__{f}\" not in result]\n",
        "    \n",
        "    if not missing_orientation and not missing_angular:\n",
        "        print(f\"✓ Joint features complete for sample joint '{sample_joint}'\")\n",
        "        print(f\"  - Orientation features: {len(required_features_per_joint['orientation'])}\")\n",
        "        print(f\"  - Angular kinematics features: {len(required_features_per_joint['angular_kinematics'])}\")\n",
        "    else:\n",
        "        print(f\"✗ Missing joint features for '{sample_joint}':\")\n",
        "        if missing_orientation:\n",
        "            print(f\"  - Orientation: {missing_orientation}\")\n",
        "        if missing_angular:\n",
        "            print(f\"  - Angular: {missing_angular}\")\n",
        "\n",
        "# Check segments\n",
        "sample_segment = next(iter(segments_with_pos), None)\n",
        "if sample_segment:\n",
        "    missing_linear = [f for f in required_features_per_segment['linear_kinematics'] if f\"{sample_segment}__{f}\" not in result]\n",
        "    \n",
        "    if not missing_linear:\n",
        "        print(f\"✓ Segment features complete for sample segment '{sample_segment}'\")\n",
        "        print(f\"  - Linear kinematics features: {len(required_features_per_segment['linear_kinematics'])}\")\n",
        "    else:\n",
        "        print(f\"✗ Missing segment features for '{sample_segment}':\")\n",
        "        print(f\"  - Linear: {missing_linear}\")\n",
        "\n",
        "print(f\"\\nTotal result dictionary keys: {len(result)}\")\n",
        "print(f\"Joints processed: {len(validation_rows)}\")\n",
        "print(f\"Segments with position data: {len(segments_with_pos)}\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear velocity and acceleration from root-relative positions (same SavGol)\n",
        "for col in pos_cols:\n",
        "    seg, suffix = col.split('__')[0], '__' + col.split('__')[1]\n",
        "    if col not in pos_rel:\n",
        "        continue\n",
        "    pr = pos_rel[col]\n",
        "    vel = savgol_filter(pr, W_LEN, SG_POLYORDER, deriv=1, delta=dt, mode='interp')\n",
        "    acc = savgol_filter(pr, W_LEN, SG_POLYORDER, deriv=2, delta=dt, mode='interp')\n",
        "    axis_letter = col[-1]\n",
        "    result[f\"{seg}__lin_vel_rel_{axis_letter}\"] = vel\n",
        "    result[f\"{seg}__lin_acc_rel_{axis_letter}\"] = acc\n",
        "segments_with_pos = set(col.split('__')[0] for col in pos_cols if col in pos_rel)\n",
        "lin_audit = []\n",
        "for seg in segments_with_pos:\n",
        "    cx, cy, cz = f\"{seg}__lin_acc_rel_x\", f\"{seg}__lin_acc_rel_y\", f\"{seg}__lin_acc_rel_z\"\n",
        "    if cx in result and cy in result and cz in result:\n",
        "        mag_acc = np.linalg.norm(np.column_stack([result[cx], result[cy], result[cz]]), axis=1)\n",
        "        lin_audit.append({'segment': seg, 'max_lin_acc_mm_s2': round(float(np.max(mag_acc)), 2), 'exceeded_lin_acc_threshold': bool(np.max(mag_acc) > LIN_ACC_THRESH)})\n",
        "print(f\"Linear v,a computed for {len(pos_cols)} position components; {len(lin_audit)} segments audited.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method Selection Report (mandatory diagnostic)\n",
        "\n",
        "Methodological justification for using **quat_log** for angular velocity: compare quaternion logarithm vs finite-difference methods. Runs every time to provide an audit trail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method Selection Report: compare quat_log vs 5-point vs central difference (runs every time)\n",
        "rep_joint = next((j for j in kinematics_map if all(f\"{j}__raw_rel_q{c}\" in result for c in \"xyzw\")), None)\n",
        "if rep_joint is not None:\n",
        "    q_rep = np.column_stack([result[f\"{rep_joint}__raw_rel_qx\"], result[f\"{rep_joint}__raw_rel_qy\"],\n",
        "                             result[f\"{rep_joint}__raw_rel_qz\"], result[f\"{rep_joint}__raw_rel_qw\"]])\n",
        "    cmp = compare_angular_velocity_methods(q_rep, FS, frame=\"local\")\n",
        "    stats = cmp[\"statistics\"]\n",
        "    rec = cmp[\"method_recommendation\"]\n",
        "    print(\"Method Selection Report (representative joint:\", rep_joint, \")\")\n",
        "    print(\"  Noise (2nd-deriv std): quat_log = {:.4f}, 5pt = {:.4f}, central = {:.4f}\".format(\n",
        "        stats[\"noise_qlog\"], stats[\"noise_5pt\"], stats[\"noise_central\"]))\n",
        "    print(\"  Noise reduction quat_log vs central: {:.2f}x\".format(stats[\"noise_reduction_qlog_vs_central\"]))\n",
        "    print(\"  Recommendation:\", rec)\n",
        "else:\n",
        "    print(\"Method Selection Report: no joint with raw_rel quaternions found; skip.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export master parquet and validation report JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_master = pd.DataFrame(result)\n",
        "out_parquet = Path(OUT_DIR) / f\"{RUN_ID}__kinematics_master.parquet\"\n",
        "df_master.to_parquet(out_parquet, index=False)\n",
        "print(f\"Saved: {out_parquet}\")\n",
        "\n",
        "validation_report = {\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"total_frames\": len(df_master),\n",
        "    \"per_joint\": {r[\"joint\"]: {\"geodesic_offset_std\": r[\"geodesic_offset_std\"], \"velocity_alignment_pct\": r[\"velocity_alignment_pct\"], \"max_omega_deg_s\": r[\"max_omega_deg_s\"], \"mean_omega_deg_s\": r[\"mean_omega_deg_s\"], \"median_omega_deg_s\": r[\"median_omega_deg_s\"], \"exceeded_omega_threshold\": r[\"exceeded_omega_threshold\"]} for r in validation_rows},\n",
        "    \"per_segment_linear\": {a[\"segment\"]: {\"max_lin_acc_mm_s2\": a[\"max_lin_acc_mm_s2\"], \"exceeded_lin_acc_threshold\": a[\"exceeded_lin_acc_threshold\"]} for a in lin_audit},\n",
        "}\n",
        "out_json = Path(OUT_DIR) / f\"{RUN_ID}__validation_report.json\"\n",
        "with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(validation_report, f, indent=2)\n",
        "print(f\"Saved: {out_json}\")\n",
        "max_geodesic = max(r[\"geodesic_offset_std\"] for r in validation_rows)\n",
        "mean_align = np.mean([r[\"velocity_alignment_pct\"] for r in validation_rows])\n",
        "print(\"Velocity Magnitude Alignment: mean similarity (raw vs zeroed) = {:.2f}% (expect close to 100%).\".format(mean_align))\n",
        "print(\"Stability Proof (quaternion): max Std of geodesic distance over joints = {:.6f}° (expect near zero; constant T-pose → constant rotation).\".format(max_geodesic))\n",
        "print()\n",
        "validation_table = pd.DataFrame([{\"joint\": r[\"joint\"], \"velocity_similarity_pct\": r[\"velocity_alignment_pct\"], \"geodesic_std_deg\": r[\"geodesic_offset_std\"]} for r in validation_rows])\n",
        "print(\"Validation Summary Table (quaternion-based proof for proceeding with zeroed data):\")\n",
        "display(validation_table)\n",
        "if mean_align >= 99.0 and np.isfinite(max_geodesic) and max_geodesic < 0.1:\n",
        "    print(\"Conclusion: T-pose is stable; zeroed data aligns with raw. Proceed using zeroed data.\")\n",
        "else:\n",
        "    print(\"Conclusion: Review T-pose or per-joint metrics above before relying solely on zeroed data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outlier validation: frame counts and % by metric (3-tier: Warning / Alert / Critical)\n",
        "\n",
        "Per-metric tables: joints as rows; columns = outlier frame counts and percentage of total recording frames for each threshold level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_frames = len(df_master)\n",
        "THRESH = {\n",
        "    'rotation_mag_deg': {'WARNING': 140.0, 'ALERT': 160.0, 'CRITICAL': 180.0},\n",
        "    'angular_velocity_deg_s': {'WARNING': 800.0, 'ALERT': 1200.0, 'CRITICAL': 1500.0},\n",
        "    'angular_acceleration_deg_s2': {'WARNING': 35000.0, 'ALERT': 50000.0, 'CRITICAL': 80000.0},\n",
        "    'linear_velocity_mm_s': {'WARNING': 3000.0, 'ALERT': 5000.0, 'CRITICAL': 7000.0},\n",
        "    'linear_acceleration_mm_s2': {'WARNING': 60000.0, 'ALERT': 100000.0, 'CRITICAL': 150000.0},\n",
        "}\n",
        "\n",
        "def outlier_table(joint_or_segment_list, magnitude_per_name, thresh_dict, total_frames, name_col='joint'):\n",
        "    rows = []\n",
        "    for name in joint_or_segment_list:\n",
        "        mag = magnitude_per_name.get(name)\n",
        "        if mag is None or len(mag) == 0:\n",
        "            continue\n",
        "        n_w = int(np.sum(mag > thresh_dict['WARNING']))\n",
        "        n_a = int(np.sum(mag > thresh_dict['ALERT']))\n",
        "        n_c = int(np.sum(mag > thresh_dict['CRITICAL']))\n",
        "        rows.append({\n",
        "            name_col: name,\n",
        "            'n_frames_WARNING': n_w, 'n_frames_ALERT': n_a, 'n_frames_CRITICAL': n_c,\n",
        "            'pct_WARNING': round(100.0 * n_w / total_frames, 2),\n",
        "            'pct_ALERT': round(100.0 * n_a / total_frames, 2),\n",
        "            'pct_CRITICAL': round(100.0 * n_c / total_frames, 2),\n",
        "            'total_frames': total_frames,\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# 1. Rotation vector magnitude (total rotation from T-pose) — zeroed quat\n",
        "rot_mag_per_joint = {}\n",
        "for j in kinematics_map:\n",
        "    qc = [f\"{j}__zeroed_rel_qx\", f\"{j}__zeroed_rel_qy\", f\"{j}__zeroed_rel_qz\", f\"{j}__zeroed_rel_qw\"]\n",
        "    if not all(c in df_master.columns for c in qc):\n",
        "        continue\n",
        "    q = df_master[qc].values\n",
        "    rot_mag_per_joint[j] = np.degrees(np.linalg.norm(R.from_quat(q).as_rotvec(), axis=1))\n",
        "df_rot = outlier_table(list(rot_mag_per_joint.keys()), rot_mag_per_joint, THRESH['rotation_mag_deg'], total_frames)\n",
        "print(\"Rotation magnitude (deg) — thresholds 140° / 160° / 180°\")\n",
        "display(df_rot)\n",
        "\n",
        "# 2. Angular velocity (deg/s)\n",
        "omega_mag_per_joint = {}\n",
        "for j in kinematics_map:\n",
        "    cols = [f\"{j}__zeroed_rel_omega_x\", f\"{j}__zeroed_rel_omega_y\", f\"{j}__zeroed_rel_omega_z\"]\n",
        "    if not all(c in df_master.columns for c in cols):\n",
        "        continue\n",
        "    omega_mag_per_joint[j] = np.linalg.norm(df_master[cols].values, axis=1)\n",
        "df_omega = outlier_table(list(omega_mag_per_joint.keys()), omega_mag_per_joint, THRESH['angular_velocity_deg_s'], total_frames)\n",
        "print(\"Angular velocity (deg/s) — thresholds 800 / 1200 / 1500\")\n",
        "display(df_omega)\n",
        "\n",
        "# 3. Angular acceleration (deg/s²)\n",
        "alpha_mag_per_joint = {}\n",
        "for j in kinematics_map:\n",
        "    cols = [f\"{j}__zeroed_rel_alpha_x\", f\"{j}__zeroed_rel_alpha_y\", f\"{j}__zeroed_rel_alpha_z\"]\n",
        "    if not all(c in df_master.columns for c in cols):\n",
        "        continue\n",
        "    alpha_mag_per_joint[j] = np.linalg.norm(df_master[cols].values, axis=1)\n",
        "df_alpha = outlier_table(list(alpha_mag_per_joint.keys()), alpha_mag_per_joint, THRESH['angular_acceleration_deg_s2'], total_frames)\n",
        "print(\"Angular acceleration (deg/s²) — thresholds 35000 / 50000 / 80000\")\n",
        "display(df_alpha)\n",
        "\n",
        "# 4. Linear velocity (mm/s) — per segment\n",
        "lin_vel_segments = [c.split('__')[0] for c in df_master.columns if c.endswith('__lin_vel_rel_x')]\n",
        "lin_vel_mag = {}\n",
        "for seg in lin_vel_segments:\n",
        "    cx, cy, cz = f\"{seg}__lin_vel_rel_x\", f\"{seg}__lin_vel_rel_y\", f\"{seg}__lin_vel_rel_z\"\n",
        "    if cx in df_master.columns and cy in df_master.columns and cz in df_master.columns:\n",
        "        lin_vel_mag[seg] = np.linalg.norm(df_master[[cx, cy, cz]].values, axis=1)\n",
        "df_linvel = outlier_table(list(lin_vel_mag.keys()), lin_vel_mag, THRESH['linear_velocity_mm_s'], total_frames, name_col='segment')\n",
        "print(\"Linear velocity (mm/s) — thresholds 3000 / 5000 / 7000\")\n",
        "display(df_linvel)\n",
        "\n",
        "# 5. Linear acceleration (mm/s²)\n",
        "lin_acc_segments = [c.split('__')[0] for c in df_master.columns if c.endswith('__lin_acc_rel_x')]\n",
        "lin_acc_mag = {}\n",
        "for seg in lin_acc_segments:\n",
        "    cx, cy, cz = f\"{seg}__lin_acc_rel_x\", f\"{seg}__lin_acc_rel_y\", f\"{seg}__lin_acc_rel_z\"\n",
        "    if cx in df_master.columns and cy in df_master.columns and cz in df_master.columns:\n",
        "        lin_acc_mag[seg] = np.linalg.norm(df_master[[cx, cy, cz]].values, axis=1)\n",
        "df_linacc = outlier_table(list(lin_acc_mag.keys()), lin_acc_mag, THRESH['linear_acceleration_mm_s2'], total_frames, name_col='segment')\n",
        "print(\"Linear acceleration (mm/s²) — thresholds 60000 / 100000 / 150000\")\n",
        "display(df_linacc)\n",
        "\n",
        "# --- Surgical repair (when ENFORCE_CLEANING and any Critical): delegate to kinematic_repair ---\n",
        "from kinematic_repair import identify_critical_units, apply_surgical_repair\n",
        "\n",
        "angular_critical_joints, linear_critical_segments = identify_critical_units(\n",
        "    df_rot, df_omega, df_alpha, df_linvel, df_linacc\n",
        ")\n",
        "\n",
        "if ENFORCE_CLEANING and (angular_critical_joints or linear_critical_segments):\n",
        "    apply_surgical_repair(\n",
        "        result,\n",
        "        pos_rel,\n",
        "        validation_rows,\n",
        "        lin_audit,\n",
        "        angular_critical_joints,\n",
        "        linear_critical_segments,\n",
        "        rot_mag_per_joint,\n",
        "        omega_mag_per_joint,\n",
        "        alpha_mag_per_joint,\n",
        "        lin_vel_mag,\n",
        "        lin_acc_mag,\n",
        "        THRESH,\n",
        "        kinematics_map,\n",
        "        ref_pose,\n",
        "        FS,\n",
        "        W_LEN,\n",
        "        SG_POLYORDER,\n",
        "        dt,\n",
        "        OMEGA_THRESH,\n",
        "        LIN_ACC_THRESH,\n",
        "    )\n",
        "    # (Angular/linear repair done in-place by kinematic_repair; now save and rebuild outlier tables)\n",
        "    df_master = pd.DataFrame(result)\n",
        "    out_parquet = Path(OUT_DIR) / f\"{RUN_ID}__kinematics_master.parquet\"\n",
        "    df_master.to_parquet(out_parquet, index=False)\n",
        "    print(\"Surgical repair applied; overwrote\", out_parquet)\n",
        "    validation_report = {\"run_id\": RUN_ID, \"total_frames\": len(df_master), \"per_joint\": {r[\"joint\"]: {\"geodesic_offset_std\": r[\"geodesic_offset_std\"], \"velocity_alignment_pct\": r[\"velocity_alignment_pct\"], \"max_omega_deg_s\": r[\"max_omega_deg_s\"], \"mean_omega_deg_s\": r[\"mean_omega_deg_s\"], \"median_omega_deg_s\": r[\"median_omega_deg_s\"], \"exceeded_omega_threshold\": r[\"exceeded_omega_threshold\"]} for r in validation_rows}, \"per_segment_linear\": {a[\"segment\"]: {\"max_lin_acc_mm_s2\": a[\"max_lin_acc_mm_s2\"], \"exceeded_lin_acc_threshold\": a[\"exceeded_lin_acc_threshold\"]} for a in lin_audit}}\n",
        "    out_json = Path(OUT_DIR) / f\"{RUN_ID}__validation_report.json\"\n",
        "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(validation_report, f, indent=2)\n",
        "    print(\"Overwrote\", out_json)\n",
        "    # Rebuild outlier tables from repaired df_master\n",
        "    rot_mag_per_joint = {j: np.degrees(np.linalg.norm(R.from_quat(df_master[[f\"{j}__zeroed_rel_qx\", f\"{j}__zeroed_rel_qy\", f\"{j}__zeroed_rel_qz\", f\"{j}__zeroed_rel_qw\"]].values).as_rotvec(), axis=1)) for j in kinematics_map if all(f\"{j}__zeroed_rel_q{c}\" in df_master.columns for c in \"xyzw\")}\n",
        "    omega_mag_per_joint = {j: np.linalg.norm(df_master[[f\"{j}__zeroed_rel_omega_x\", f\"{j}__zeroed_rel_omega_y\", f\"{j}__zeroed_rel_omega_z\"]].values, axis=1) for j in kinematics_map if all(f\"{j}__zeroed_rel_omega_{c}\" in df_master.columns for c in \"xyz\")}\n",
        "    alpha_mag_per_joint = {j: np.linalg.norm(df_master[[f\"{j}__zeroed_rel_alpha_x\", f\"{j}__zeroed_rel_alpha_y\", f\"{j}__zeroed_rel_alpha_z\"]].values, axis=1) for j in kinematics_map if all(f\"{j}__zeroed_rel_alpha_{c}\" in df_master.columns for c in \"xyz\")}\n",
        "    lin_vel_mag = {seg: np.linalg.norm(df_master[[f\"{seg}__lin_vel_rel_x\", f\"{seg}__lin_vel_rel_y\", f\"{seg}__lin_vel_rel_z\"]].values, axis=1) for seg in lin_vel_segments if all(f\"{seg}__lin_vel_rel_{c}\" in df_master.columns for c in \"xyz\")}\n",
        "    lin_acc_mag = {seg: np.linalg.norm(df_master[[f\"{seg}__lin_acc_rel_x\", f\"{seg}__lin_acc_rel_y\", f\"{seg}__lin_acc_rel_z\"]].values, axis=1) for seg in lin_acc_segments if all(f\"{seg}__lin_acc_rel_{c}\" in df_master.columns for c in \"xyz\")}\n",
        "    df_rot = outlier_table(list(rot_mag_per_joint.keys()), rot_mag_per_joint, THRESH[\"rotation_mag_deg\"], total_frames)\n",
        "    df_omega = outlier_table(list(omega_mag_per_joint.keys()), omega_mag_per_joint, THRESH[\"angular_velocity_deg_s\"], total_frames)\n",
        "    df_alpha = outlier_table(list(alpha_mag_per_joint.keys()), alpha_mag_per_joint, THRESH[\"angular_acceleration_deg_s2\"], total_frames)\n",
        "    df_linvel = outlier_table(list(lin_vel_mag.keys()), lin_vel_mag, THRESH[\"linear_velocity_mm_s\"], total_frames, name_col=\"segment\")\n",
        "    df_linacc = outlier_table(list(lin_acc_mag.keys()), lin_acc_mag, THRESH[\"linear_acceleration_mm_s2\"], total_frames, name_col=\"segment\")\n",
        "\n",
        "# ============================================================\n",
        "# PHASE 2: PATH LENGTH & BILATERAL SYMMETRY COMPUTATION\n",
        "# ============================================================\n",
        "# Must run BEFORE validation_report export (moved here from cells 15-16)\n",
        "\n",
        "def compute_path_length(positions_mm):\n",
        "    \"\"\"Compute cumulative 3D path length from position time series.\"\"\"\n",
        "    if len(positions_mm) < 2:\n",
        "        return 0.0\n",
        "    deltas = np.diff(positions_mm, axis=0)\n",
        "    distances = np.linalg.norm(deltas, axis=1)\n",
        "    total_mm = np.sum(distances)\n",
        "    total_m = total_mm / 1000.0\n",
        "    return total_m\n",
        "\n",
        "def compute_bilateral_symmetry(left_values, right_values, metric_name=\"metric\"):\n",
        "    \"\"\"Compute bilateral symmetry index between paired measurements.\"\"\"\n",
        "    left = float(left_values)\n",
        "    right = float(right_values)\n",
        "    if left == 0 and right == 0:\n",
        "        return {\"left_value\": 0.0, \"right_value\": 0.0, \"absolute_diff\": 0.0, \"percent_diff\": 0.0, \"symmetry_index\": 1.0, \"metric_name\": metric_name}\n",
        "    abs_diff = abs(left - right)\n",
        "    max_val = max(abs(left), abs(right))\n",
        "    if max_val == 0:\n",
        "        symmetry_index = 1.0\n",
        "        percent_diff = 0.0\n",
        "    else:\n",
        "        symmetry_index = 1.0 - (abs_diff / max_val)\n",
        "        percent_diff = (abs_diff / max_val) * 100.0\n",
        "    return {\"left_value\": left, \"right_value\": right, \"absolute_diff\": abs_diff, \"percent_diff\": percent_diff, \"symmetry_index\": symmetry_index, \"metric_name\": metric_name}\n",
        "\n",
        "# Compute path length for all segments\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PHASE 2: Computing path length and bilateral symmetry...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "path_lengths = {}\n",
        "for segment in kinematics_map:\n",
        "    pos_cols = [f\"{segment}__pos_rel_x\", f\"{segment}__pos_rel_y\", f\"{segment}__pos_rel_z\"]\n",
        "    if all(col in df_master.columns for col in pos_cols):\n",
        "        positions = df_master[pos_cols].values\n",
        "        path_length_m = compute_path_length(positions)\n",
        "        path_lengths[segment] = path_length_m\n",
        "    else:\n",
        "        path_lengths[segment] = 0.0\n",
        "\n",
        "path_lengths_sorted = dict(sorted(path_lengths.items(), key=lambda x: x[1], reverse=True))\n",
        "print(f\"✓ Path length computed for {len(path_lengths)} segments\")\n",
        "print(f\"  Top 3: {list(path_lengths_sorted.keys())[:3]}\")\n",
        "\n",
        "# Compute bilateral symmetry\n",
        "BILATERAL_PAIRS = {\n",
        "    \"upper_arm\": (\"LeftArm\", \"RightArm\"),\n",
        "    \"forearm\": (\"LeftForeArm\", \"RightForeArm\"),\n",
        "    \"hand\": (\"LeftHand\", \"RightHand\"),\n",
        "    \"thigh\": (\"LeftUpLeg\", \"RightUpLeg\"),\n",
        "    \"shin\": (\"LeftLeg\", \"RightLeg\"),\n",
        "    \"foot\": (\"LeftFoot\", \"RightFoot\"),\n",
        "}\n",
        "\n",
        "bilateral_symmetry = {}\n",
        "\n",
        "# Path length symmetry\n",
        "for pair_name, (left_seg, right_seg) in BILATERAL_PAIRS.items():\n",
        "    if left_seg in path_lengths and right_seg in path_lengths:\n",
        "        symmetry = compute_bilateral_symmetry(path_lengths[left_seg], path_lengths[right_seg], metric_name=f\"path_length_{pair_name}\")\n",
        "        bilateral_symmetry[f\"path_length_{pair_name}\"] = symmetry\n",
        "\n",
        "# Angular velocity symmetry\n",
        "for pair_name, (left_seg, right_seg) in BILATERAL_PAIRS.items():\n",
        "    if left_seg in omega_mag_per_joint and right_seg in omega_mag_per_joint:\n",
        "        left_max = np.max(omega_mag_per_joint[left_seg])\n",
        "        right_max = np.max(omega_mag_per_joint[right_seg])\n",
        "        symmetry = compute_bilateral_symmetry(left_max, right_max, metric_name=f\"max_omega_{pair_name}\")\n",
        "        bilateral_symmetry[f\"max_omega_{pair_name}\"] = symmetry\n",
        "\n",
        "# Linear acceleration symmetry\n",
        "for pair_name, (left_seg, right_seg) in BILATERAL_PAIRS.items():\n",
        "    if left_seg in lin_acc_mag and right_seg in lin_acc_mag:\n",
        "        left_max = np.max(lin_acc_mag[left_seg])\n",
        "        right_max = np.max(lin_acc_mag[right_seg])\n",
        "        symmetry = compute_bilateral_symmetry(left_max, right_max, metric_name=f\"max_lin_acc_{pair_name}\")\n",
        "        bilateral_symmetry[f\"max_lin_acc_{pair_name}\"] = symmetry\n",
        "\n",
        "print(f\"✓ Bilateral symmetry computed for {len(bilateral_symmetry)} metrics\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# ============================================================\n",
        "# OUTLIER VALIDATION & VALIDATION REPORT EXPORT\n",
        "# ============================================================\n",
        "\n",
        "# Save outlier validation tables to JSON (standalone and into validation_report)\n",
        "outlier_report = {\n",
        "    \"run_id\": RUN_ID,\n",
        "    \"total_frames\": total_frames,\n",
        "    \"thresholds\": THRESH,\n",
        "    \"rotation_mag_deg\": df_rot.to_dict(orient=\"records\"),\n",
        "    \"angular_velocity_deg_s\": df_omega.to_dict(orient=\"records\"),\n",
        "    \"angular_acceleration_deg_s2\": df_alpha.to_dict(orient=\"records\"),\n",
        "    \"linear_velocity_mm_s\": df_linvel.to_dict(orient=\"records\"),\n",
        "    \"linear_acceleration_mm_s2\": df_linacc.to_dict(orient=\"records\"),\n",
        "}\n",
        "outlier_json_path = Path(OUT_DIR) / f\"{RUN_ID}__outlier_validation.json\"\n",
        "with open(outlier_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(outlier_report, f, indent=2)\n",
        "print(f\"Saved: {outlier_json_path}\")\n",
        "\n",
        "# Append outlier_validation (frame counts and percentages) to validation_report.json\n",
        "validation_report_path = Path(OUT_DIR) / f\"{RUN_ID}__validation_report.json\"\n",
        "if validation_report_path.exists():\n",
        "    with open(validation_report_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        v = json.load(f)\n",
        "    v[\"total_frames\"] = total_frames\n",
        "    v[\"outlier_validation\"] = {\n",
        "        \"total_frames\": total_frames,\n",
        "        \"thresholds\": THRESH,\n",
        "        \"rotation_mag_deg\": df_rot.to_dict(orient=\"records\"),\n",
        "        \"angular_velocity_deg_s\": df_omega.to_dict(orient=\"records\"),\n",
        "        \"angular_acceleration_deg_s2\": df_alpha.to_dict(orient=\"records\"),\n",
        "        \"linear_velocity_mm_s\": df_linvel.to_dict(orient=\"records\"),\n",
        "        \"linear_acceleration_mm_s2\": df_linacc.to_dict(orient=\"records\"),\n",
        "    }\n",
        "    \n",
        "    # Phase 2: Add path length and bilateral symmetry metrics\n",
        "    v[\"path_length_m\"] = path_lengths_sorted\n",
        "    v[\"bilateral_symmetry\"] = bilateral_symmetry\n",
        "    \n",
        "    with open(validation_report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(v, f, indent=2)\n",
        "    print(f\"Updated: {validation_report_path} (outlier_validation + path_length + bilateral_symmetry)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: Path Length & Bilateral Symmetry\n",
        "\n",
        "Compute cumulative path length (movement intensity) and bilateral symmetry indices for paired limbs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# PATH LENGTH COMPUTATION (Movement Intensity Index)\n",
        "# ============================================================\n",
        "\n",
        "def compute_path_length(positions_mm):\n",
        "    \"\"\"\n",
        "    Compute cumulative 3D path length from position time series.\n",
        "    \n",
        "    Args:\n",
        "        positions_mm: (T, 3) array of [x, y, z] positions in mm\n",
        "        \n",
        "    Returns:\n",
        "        float: Total path length in meters\n",
        "    \"\"\"\n",
        "    if len(positions_mm) < 2:\n",
        "        return 0.0\n",
        "    \n",
        "    # Compute frame-to-frame Euclidean distances\n",
        "    deltas = np.diff(positions_mm, axis=0)\n",
        "    distances = np.linalg.norm(deltas, axis=1)\n",
        "    \n",
        "    # Sum and convert mm -> meters\n",
        "    total_mm = np.sum(distances)\n",
        "    total_m = total_mm / 1000.0\n",
        "    \n",
        "    return total_m\n",
        "\n",
        "# Compute path length for all segments\n",
        "print(\"\\nComputing path length (movement intensity)...\")\n",
        "path_lengths = {}\n",
        "\n",
        "for segment in kinematics_map:\n",
        "    pos_cols = [f\"{segment}__pos_rel_x\", f\"{segment}__pos_rel_y\", f\"{segment}__pos_rel_z\"]\n",
        "    \n",
        "    if all(col in df_master.columns for col in pos_cols):\n",
        "        positions = df_master[pos_cols].values\n",
        "        path_length_m = compute_path_length(positions)\n",
        "        path_lengths[segment] = path_length_m\n",
        "    else:\n",
        "        path_lengths[segment] = 0.0\n",
        "\n",
        "# Sort by path length (most active segments first)\n",
        "path_lengths_sorted = dict(sorted(path_lengths.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(f\"\\n✓ Path length computed for {len(path_lengths)} segments\")\n",
        "print(f\"  Most active: {list(path_lengths_sorted.keys())[:5]}\")\n",
        "print(f\"  Range: {min(path_lengths.values()):.2f}m - {max(path_lengths.values()):.2f}m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# BILATERAL SYMMETRY COMPUTATION\n",
        "# ============================================================\n",
        "\n",
        "def compute_bilateral_symmetry(left_values, right_values, metric_name=\"metric\"):\n",
        "    \"\"\"\n",
        "    Compute bilateral symmetry index between paired left/right measurements.\n",
        "    \n",
        "    Symmetry Index = 1 - |L - R| / max(L, R)\n",
        "    \n",
        "    Returns:\n",
        "        dict: {\n",
        "            \"left_value\": float,\n",
        "            \"right_value\": float,\n",
        "            \"absolute_diff\": float,\n",
        "            \"percent_diff\": float,  # Relative difference (%)\n",
        "            \"symmetry_index\": float,  # 1.0 = perfect symmetry, 0.0 = complete asymmetry\n",
        "            \"metric_name\": str\n",
        "        }\n",
        "    \"\"\"\n",
        "    left = float(left_values)\n",
        "    right = float(right_values)\n",
        "    \n",
        "    if left == 0 and right == 0:\n",
        "        return {\n",
        "            \"left_value\": 0.0,\n",
        "            \"right_value\": 0.0,\n",
        "            \"absolute_diff\": 0.0,\n",
        "            \"percent_diff\": 0.0,\n",
        "            \"symmetry_index\": 1.0,  # Perfect symmetry (both zero)\n",
        "            \"metric_name\": metric_name\n",
        "        }\n",
        "    \n",
        "    abs_diff = abs(left - right)\n",
        "    max_val = max(abs(left), abs(right))\n",
        "    \n",
        "    if max_val == 0:\n",
        "        symmetry_index = 1.0\n",
        "        percent_diff = 0.0\n",
        "    else:\n",
        "        symmetry_index = 1.0 - (abs_diff / max_val)\n",
        "        percent_diff = (abs_diff / max_val) * 100.0\n",
        "    \n",
        "    return {\n",
        "        \"left_value\": left,\n",
        "        \"right_value\": right,\n",
        "        \"absolute_diff\": abs_diff,\n",
        "        \"percent_diff\": percent_diff,\n",
        "        \"symmetry_index\": symmetry_index,\n",
        "        \"metric_name\": metric_name\n",
        "    }\n",
        "\n",
        "# Define bilateral pairs (standard anatomical naming)\n",
        "BILATERAL_PAIRS = {\n",
        "    \"upper_arm\": (\"LeftArm\", \"RightArm\"),\n",
        "    \"forearm\": (\"LeftForeArm\", \"RightForeArm\"),\n",
        "    \"hand\": (\"LeftHand\", \"RightHand\"),\n",
        "    \"thigh\": (\"LeftUpLeg\", \"RightUpLeg\"),\n",
        "    \"shin\": (\"LeftLeg\", \"RightLeg\"),\n",
        "    \"foot\": (\"LeftFoot\", \"RightFoot\"),\n",
        "}\n",
        "\n",
        "print(\"\\nComputing bilateral symmetry...\")\n",
        "bilateral_symmetry = {}\n",
        "\n",
        "# Path length symmetry\n",
        "for pair_name, (left_seg, right_seg) in BILATERAL_PAIRS.items():\n",
        "    if left_seg in path_lengths and right_seg in path_lengths:\n",
        "        symmetry = compute_bilateral_symmetry(\n",
        "            path_lengths[left_seg],\n",
        "            path_lengths[right_seg],\n",
        "            metric_name=f\"path_length_{pair_name}\"\n",
        "        )\n",
        "        bilateral_symmetry[f\"path_length_{pair_name}\"] = symmetry\n",
        "\n",
        "# Angular velocity symmetry (max omega)\n",
        "for pair_name, (left_seg, right_seg) in BILATERAL_PAIRS.items():\n",
        "    if left_seg in omega_mag_per_joint and right_seg in omega_mag_per_joint:\n",
        "        left_max = np.max(omega_mag_per_joint[left_seg])\n",
        "        right_max = np.max(omega_mag_per_joint[right_seg])\n",
        "        \n",
        "        symmetry = compute_bilateral_symmetry(\n",
        "            left_max,\n",
        "            right_max,\n",
        "            metric_name=f\"max_omega_{pair_name}\"\n",
        "        )\n",
        "        bilateral_symmetry[f\"max_omega_{pair_name}\"] = symmetry\n",
        "\n",
        "# Linear acceleration symmetry (max acceleration)\n",
        "for pair_name, (left_seg, right_seg) in BILATERAL_PAIRS.items():\n",
        "    if left_seg in lin_acc_mag and right_seg in lin_acc_mag:\n",
        "        left_max = np.max(lin_acc_mag[left_seg])\n",
        "        right_max = np.max(lin_acc_mag[right_seg])\n",
        "        \n",
        "        symmetry = compute_bilateral_symmetry(\n",
        "            left_max,\n",
        "            right_max,\n",
        "            metric_name=f\"max_lin_acc_{pair_name}\"\n",
        "        )\n",
        "        bilateral_symmetry[f\"max_lin_acc_{pair_name}\"] = symmetry\n",
        "\n",
        "print(f\"\\n✓ Bilateral symmetry computed for {len(bilateral_symmetry)} metrics\")\n",
        "print(\"\\nSymmetry indices (1.0 = perfect, 0.0 = asymmetric):\")\n",
        "for key, data in sorted(bilateral_symmetry.items(), key=lambda x: x[1][\"symmetry_index\"]):\n",
        "    print(f\"  {key:30s}: {data['symmetry_index']:.3f} (L={data['left_value']:.1f}, R={data['right_value']:.1f}, diff={data['percent_diff']:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotly dashboard: 3D skeleton (slider + animation), Raw vs Zeroed ω, Geodesic stability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Build root-relative position arrays per segment for skeleton\n",
        "seg_xyz = {}\n",
        "for seg in segments_with_pos:\n",
        "    kx, ky, kz = f\"{seg}__px\", f\"{seg}__py\", f\"{seg}__pz\"\n",
        "    if kx in pos_rel and ky in pos_rel and kz in pos_rel:\n",
        "        seg_xyz[seg] = np.column_stack([pos_rel[kx], pos_rel[ky], pos_rel[kz]])\n",
        "n_f = len(df_in)\n",
        "t_axis = df_in['time_s'].values\n",
        "\n",
        "# Edges from kinematics_map (parent -> child) where both have position\n",
        "edges = []\n",
        "for jname, jinfo in kinematics_map.items():\n",
        "    pname = jinfo.get(\"parent\")\n",
        "    if pname is None:\n",
        "        continue\n",
        "    if jname in seg_xyz and pname in seg_xyz:\n",
        "        edges.append((pname, jname))\n",
        "\n",
        "def skeleton_trace(frame_ix):\n",
        "    scatter = go.Scatter3d(\n",
        "        x=[seg_xyz[s][frame_ix, 0] for s in seg_xyz],\n",
        "        y=[seg_xyz[s][frame_ix, 1] for s in seg_xyz],\n",
        "        z=[seg_xyz[s][frame_ix, 2] for s in seg_xyz],\n",
        "        mode='markers+text', text=list(seg_xyz.keys()), textposition='top center', marker=dict(size=4, color='blue'),\n",
        "        name='segments'\n",
        "    )\n",
        "    line_x, line_y, line_z = [], [], []\n",
        "    for p, c in edges:\n",
        "        line_x += [seg_xyz[p][frame_ix, 0], seg_xyz[c][frame_ix, 0], None]\n",
        "        line_y += [seg_xyz[p][frame_ix, 1], seg_xyz[c][frame_ix, 1], None]\n",
        "        line_z += [seg_xyz[p][frame_ix, 2], seg_xyz[c][frame_ix, 2], None]\n",
        "    bone = go.Scatter3d(x=line_x, y=line_y, z=line_z, mode='lines', line=dict(color='gray', width=2), name='bones')\n",
        "    return [scatter, bone]\n",
        "\n",
        "n_slider = min(150, n_f)\n",
        "step = max(1, (n_f - 1) // n_slider)\n",
        "frame_indices = list(range(0, n_f, step))\n",
        "if frame_indices[-1] != n_f - 1:\n",
        "    frame_indices.append(n_f - 1)\n",
        "fig_skel = go.Figure(data=skeleton_trace(0))\n",
        "fig_skel.update_layout(\n",
        "    title=f'Root-relative skeleton — {RUN_ID}',\n",
        "    scene=dict(\n",
        "        xaxis_title='X (mm) — floor',\n",
        "        yaxis_title='Y (mm) — up',\n",
        "        zaxis_title='Z (mm) — floor',\n",
        "        aspectmode='data',\n",
        "        camera=dict(up=dict(x=0, y=1, z=0), eye=dict(x=1.2, y=1.2, z=1.2)),\n",
        "    ),\n",
        "    updatemenus=[dict(type='buttons', showactive=False, y=0.1, buttons=[dict(label='Play', method='animate', args=[None, dict(frame=dict(duration=40, redraw=True), fromcurrent=True)])])],\n",
        "    sliders=[dict(active=0, len=0.9, x=0.1, steps=[dict(args=[[str(i)], dict(frame=dict(duration=0), mode='immediate')], label=str(frame_indices[i]), method='animate') for i in range(len(frame_indices))])]\n",
        ")\n",
        "fig_skel.frames = [go.Frame(data=skeleton_trace(fi), name=str(i)) for i, fi in enumerate(frame_indices)]\n",
        "if seg_xyz and edges:\n",
        "    fig_skel.show()\n",
        "else:\n",
        "    print(\"No root-relative positions or edges; skipping 3D skeleton.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison: Raw vs Zeroed omega magnitude; Geodesic distance over time (one joint)\n",
        "rep_joint = next((j for j in kinematics_map if f\"{j}__raw_rel_omega_x\" in result), list(kinematics_map.keys())[0])\n",
        "mag_raw = np.linalg.norm(np.column_stack([result[f\"{rep_joint}__raw_rel_omega_x\"], result[f\"{rep_joint}__raw_rel_omega_y\"], result[f\"{rep_joint}__raw_rel_omega_z\"]]), axis=1)\n",
        "mag_zeroed = np.linalg.norm(np.column_stack([result[f\"{rep_joint}__zeroed_rel_omega_x\"], result[f\"{rep_joint}__zeroed_rel_omega_y\"], result[f\"{rep_joint}__zeroed_rel_omega_z\"]]), axis=1)\n",
        "q_raw = np.column_stack([result[f\"{rep_joint}__raw_rel_qx\"], result[f\"{rep_joint}__raw_rel_qy\"], result[f\"{rep_joint}__raw_rel_qz\"], result[f\"{rep_joint}__raw_rel_qw\"]])\n",
        "q_zeroed = np.column_stack([result[f\"{rep_joint}__zeroed_rel_qx\"], result[f\"{rep_joint}__zeroed_rel_qy\"], result[f\"{rep_joint}__zeroed_rel_qz\"], result[f\"{rep_joint}__zeroed_rel_qw\"]])\n",
        "geodesic_deg = np.degrees(2 * np.arccos(np.clip(np.abs((q_raw * q_zeroed).sum(axis=1)), 0, 1)))\n",
        "\n",
        "fig_comp = make_subplots(rows=2, cols=1, subplot_titles=(f'{rep_joint}: Raw vs Zeroed ω magnitude (°/s)', 'Geodesic distance (°) — should be flat'))\n",
        "fig_comp.add_trace(go.Scatter(x=t_axis, y=mag_raw, name='raw_rel ω', line=dict(color='blue')), row=1, col=1)\n",
        "fig_comp.add_trace(go.Scatter(x=t_axis, y=mag_zeroed, name='zeroed_rel ω', line=dict(color='orange')), row=1, col=1)\n",
        "fig_comp.add_trace(go.Scatter(x=t_axis, y=geodesic_deg, name='geodesic', line=dict(color='green')), row=2, col=1)\n",
        "fig_comp.update_layout(height=500, title_text=f'Validation: {rep_joint}')\n",
        "fig_comp.update_xaxes(title_text='Time (s)', row=2, col=1)\n",
        "fig_comp.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
