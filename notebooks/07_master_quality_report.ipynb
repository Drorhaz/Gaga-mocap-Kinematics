{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# 07 - Master Quality Report\n",
        "\n",
        "**Purpose:** Aggregate all pipeline outputs into a comprehensive quality audit report.\n",
        "\n",
        "**Outputs:**\n",
        "- `reports/Master_Audit_Log_YYYYMMDD_HHMMSS.xlsx` (4 sheets)\n",
        "- Console summary with quality decisions\n",
        "\n",
        "**References:**\n",
        "- Cereatti et al. (2024) - Data lineage & SNR\n",
        "- Winter (2009) - Residual validation\n",
        "- R√°cz et al. (2025) - Calibration layer\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "toc",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "\n",
        "1. [Setup & Data Loading](#setup) - Load all JSON files once\n",
        "2. [Data Lineage & Provenance](#section-0) - Section 0\n",
        "3. [Calibration Layer](#section-1) - Section 1 (R√°cz)\n",
        "4. [Temporal Quality](#section-2) - Section 2\n",
        "5. [Interpolation Transparency](#section-3) - Section 3 (Winter)\n",
        "6. [Filtering Validation](#section-4) - Section 4 (Winter)\n",
        "7. [Reference Quality](#section-5) - Section 5\n",
        "8. [Biomechanics & Outliers](#section-6) - Section 6\n",
        "9. [Quality Scores](#section-7) - Component breakdown\n",
        "10. [Decision Matrix](#section-8) - Final ACCEPT/REVIEW/REJECT\n",
        "11. [Excel Export](#export) - Generate Master Audit Log"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"setup\"></a>\n",
        "## 1. Setup & Data Loading\n",
        "\n",
        "Load all JSON files **once** and reuse throughout the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "setup-imports",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project Root: c:\\Users\\drorh\\OneDrive - Mobileye\\Desktop\\gaga\n",
            "Git Hash: d5c8380\n",
            "Timestamp: 2026-01-29 14:56:38\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# IMPORTS & PATH SETUP\n",
        "# ============================================================\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Setup paths\n",
        "if os.path.basename(os.getcwd()) == 'notebooks':\n",
        "    PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "else:\n",
        "    PROJECT_ROOT = os.path.abspath(os.getcwd())\n",
        "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
        "if SRC_PATH not in sys.path:\n",
        "    sys.path.insert(0, SRC_PATH)\n",
        "\n",
        "# Import our utility module\n",
        "from utils_nb07 import (\n",
        "    load_all_runs, filter_complete_runs, build_quality_row,\n",
        "    extract_parameters_flat, export_to_excel, export_schema_json,\n",
        "    export_schema_markdown, safe_get_path, safe_float, safe_int,\n",
        "    get_git_hash, print_section_header, PARAMETER_SCHEMA, SECTION_DESCRIPTIONS\n",
        ")\n",
        "\n",
        "print(f\"Project Root: {PROJECT_ROOT}\")\n",
        "print(f\"Git Hash: {get_git_hash(PROJECT_ROOT)}\")\n",
        "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "load-data",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading JSON files...\n",
            "Found 1 total runs\n",
            "Complete runs: 1\n",
            "\n",
            "Steps available per run:\n",
            "  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002...\n",
            "    Found: ['step_01', 'step_02', 'step_03', 'step_04', 'step_05', 'step_06']\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# LOAD ALL DATA (ONCE)\n",
        "# ============================================================\n",
        "DERIV_ROOT = os.path.join(PROJECT_ROOT, \"derivatives\")\n",
        "\n",
        "# Load all JSON files\n",
        "print(\"Loading JSON files...\")\n",
        "all_runs = load_all_runs(DERIV_ROOT)\n",
        "print(f\"Found {len(all_runs)} total runs\")\n",
        "\n",
        "# Filter to complete runs (require step_01 and step_06)\n",
        "runs_data = filter_complete_runs(all_runs, required_steps=[\"step_01\", \"step_06\"])\n",
        "print(f\"Complete runs: {len(runs_data)}\")\n",
        "\n",
        "# Show available steps per run (expecting: step_01 through step_06)\n",
        "print(\"\\nSteps available per run:\")\n",
        "expected_steps = ['step_01', 'step_02', 'step_03', 'step_04', 'step_05', 'step_06']\n",
        "for run_id, steps in runs_data.items():\n",
        "    steps_list = sorted(steps.keys())\n",
        "    missing = [s for s in expected_steps if s not in steps_list]\n",
        "    print(f\"  {run_id[:50]}...\")\n",
        "    print(f\"    Found: {steps_list}\")\n",
        "    if missing:\n",
        "        print(f\"    ‚ö†Ô∏è Missing: {missing}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "build-dataframes",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quality DataFrame: 1 rows x 118 columns\n",
            "Parameter DataFrame: 1 rows x 78 columns\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# BUILD MASTER DATAFRAMES (REUSED IN ALL SECTIONS)\n",
        "# ============================================================\n",
        "\n",
        "# Quality report DataFrame (aggregated metrics)\n",
        "quality_rows = [build_quality_row(run_id, steps) for run_id, steps in runs_data.items()]\n",
        "df_quality = pd.DataFrame(quality_rows)\n",
        "df_quality = df_quality.sort_values(\"Quality_Score\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "# Parameter audit DataFrame (raw JSON values)\n",
        "param_rows = [extract_parameters_flat(run_id, steps) for run_id, steps in runs_data.items()]\n",
        "df_params = pd.DataFrame(param_rows)\n",
        "\n",
        "print(f\"Quality DataFrame: {len(df_quality)} rows x {len(df_quality.columns)} columns\")\n",
        "print(f\"Parameter DataFrame: {len(df_params)} rows x {len(df_params.columns)} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-0-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-0\"></a>\n",
        "## 2. Section 0: Data Lineage & Provenance\n",
        "\n",
        "**Purpose:** Ensure recording traceability from raw file to final result (Cereatti et al., 2024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "section-0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTION 0: DATA LINEAGE & PROVENANCE\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>Subject_ID</th>\n",
              "      <th>Session_ID</th>\n",
              "      <th>Processing_Date</th>\n",
              "      <th>Pipeline_Version</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002</td>\n",
              "      <td>734</td>\n",
              "      <td>T3</td>\n",
              "      <td>2026-01-29 11:38</td>\n",
              "      <td>v2.6_calibration_enhanced</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Run_ID Subject_ID Session_ID  \\\n",
              "0  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002        734         T3   \n",
              "\n",
              "    Processing_Date           Pipeline_Version  \n",
              "0  2026-01-29 11:38  v2.6_calibration_enhanced  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total Runs: 1\n",
            "Subjects: 1\n",
            "Sessions: 1\n"
          ]
        }
      ],
      "source": [
        "print_section_header(\"SECTION 0: DATA LINEAGE & PROVENANCE\")\n",
        "\n",
        "# Display provenance info\n",
        "cols_s0 = ['Run_ID', 'Subject_ID', 'Session_ID', 'Processing_Date', 'Pipeline_Version']\n",
        "display(df_quality[cols_s0])\n",
        "\n",
        "print(f\"\\nTotal Runs: {len(df_quality)}\")\n",
        "print(f\"Subjects: {df_quality['Subject_ID'].nunique()}\")\n",
        "print(f\"Sessions: {df_quality['Session_ID'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-1-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-1\"></a>\n",
        "## 3. Section 1: R√°cz Calibration Layer\n",
        "\n",
        "**Purpose:** Verify the \"Ground Truth\" of the skeleton setup (R√°cz et al., 2025)\n",
        "\n",
        "**Thresholds:**\n",
        "- Pointer ‚â§ 2.0mm\n",
        "- Wand ‚â§ 1.0mm\n",
        "- Bone CV ‚â§ 1.5%\n",
        "- Static Offset ‚â§ 15.0¬∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "section-1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTION 1: R√ÅCZ CALIBRATION LAYER\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>OptiTrack_Error_mm</th>\n",
              "      <th>Bone_CV_%</th>\n",
              "      <th>Bone_Status</th>\n",
              "      <th>Worst_Bone</th>\n",
              "      <th>Left_Offset_Deg</th>\n",
              "      <th>Right_Offset_Deg</th>\n",
              "      <th>Score_Calibration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.532</td>\n",
              "      <td>GOLD</td>\n",
              "      <td>Hips-&gt;Spine</td>\n",
              "      <td>7.67</td>\n",
              "      <td>9.89</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Run_ID  OptiTrack_Error_mm  \\\n",
              "0  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002                 0.0   \n",
              "\n",
              "   Bone_CV_% Bone_Status   Worst_Bone  Left_Offset_Deg  Right_Offset_Deg  \\\n",
              "0      0.532        GOLD  Hips->Spine             7.67              9.89   \n",
              "\n",
              "   Score_Calibration  \n",
              "0               95.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calibration Summary:\n",
            "  Mean Bone CV: 0.532%\n",
            "  Max Left Offset: 7.7¬∞\n",
            "  Max Right Offset: 9.9¬∞\n",
            "  Mean Calibration Score: 95.0/100\n"
          ]
        }
      ],
      "source": [
        "print_section_header(\"SECTION 1: R√ÅCZ CALIBRATION LAYER\")\n",
        "\n",
        "cols_s1 = ['Run_ID', 'OptiTrack_Error_mm', 'Bone_CV_%', 'Bone_Status', \n",
        "           'Worst_Bone', 'Left_Offset_Deg', 'Right_Offset_Deg', 'Score_Calibration']\n",
        "display(df_quality[cols_s1])\n",
        "\n",
        "# Summary\n",
        "print(f\"\\nCalibration Summary:\")\n",
        "print(f\"  Mean Bone CV: {df_quality['Bone_CV_%'].mean():.3f}%\")\n",
        "print(f\"  Max Left Offset: {df_quality['Left_Offset_Deg'].max():.1f}¬∞\")\n",
        "print(f\"  Max Right Offset: {df_quality['Right_Offset_Deg'].max():.1f}¬∞\")\n",
        "print(f\"  Mean Calibration Score: {df_quality['Score_Calibration'].mean():.1f}/100\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-2-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-2\"></a>\n",
        "## 4. Section 2: Temporal Quality & Sampling\n",
        "\n",
        "**Purpose:** Verify sampling rate and recording duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "section-2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTION 2: TEMPORAL QUALITY & SAMPLING\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>Total_Frames</th>\n",
              "      <th>Duration_Sec</th>\n",
              "      <th>Sampling_Rate_Hz</th>\n",
              "      <th>Target_Fs_Hz</th>\n",
              "      <th>Time_Grid_Std_Dt</th>\n",
              "      <th>Temporal_Status</th>\n",
              "      <th>Score_Temporal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002</td>\n",
              "      <td>16504</td>\n",
              "      <td>137.5</td>\n",
              "      <td>120.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>PERFECT</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Run_ID  Total_Frames  Duration_Sec  \\\n",
              "0  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002         16504         137.5   \n",
              "\n",
              "   Sampling_Rate_Hz  Target_Fs_Hz  Time_Grid_Std_Dt Temporal_Status  \\\n",
              "0             120.0         120.0               0.0         PERFECT   \n",
              "\n",
              "   Score_Temporal  \n",
              "0           100.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Temporal Summary:\n",
            "  Total Frames: 16,504\n",
            "  Total Duration: 2.3 minutes\n",
            "  Mean Sampling Rate: 120.00 Hz\n",
            "  Temporal Grid PERFECT: 1/1\n",
            "  Mean Temporal Score: 100.0/100\n"
          ]
        }
      ],
      "source": [
        "print_section_header(\"SECTION 2: TEMPORAL QUALITY & SAMPLING\")\n",
        "\n",
        "# Include step_03 resample validation fields\n",
        "cols_s2 = ['Run_ID', 'Total_Frames', 'Duration_Sec', 'Sampling_Rate_Hz', \n",
        "           'Target_Fs_Hz', 'Time_Grid_Std_Dt', 'Temporal_Status', 'Score_Temporal']\n",
        "display(df_quality[cols_s2])\n",
        "\n",
        "print(f\"\\nTemporal Summary:\")\n",
        "print(f\"  Total Frames: {df_quality['Total_Frames'].sum():,}\")\n",
        "print(f\"  Total Duration: {df_quality['Duration_Sec'].sum()/60:.1f} minutes\")\n",
        "print(f\"  Mean Sampling Rate: {df_quality['Sampling_Rate_Hz'].mean():.2f} Hz\")\n",
        "\n",
        "# Step 03 resample validation\n",
        "if 'Temporal_Status' in df_quality.columns:\n",
        "    perfect_count = (df_quality['Temporal_Status'] == 'PERFECT').sum()\n",
        "    print(f\"  Temporal Grid PERFECT: {perfect_count}/{len(df_quality)}\")\n",
        "print(f\"  Mean Temporal Score: {df_quality['Score_Temporal'].mean():.1f}/100\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-3-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-3\"></a>\n",
        "## 5. Section 3: Gap & Interpolation Transparency\n",
        "\n",
        "**Purpose:** \"No Silent Fixes\" (Winter, 2009) - Full disclosure of data reconstruction\n",
        "\n",
        "**Thresholds:**\n",
        "- Missing data ‚â§ 5.0%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "section-3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTION 3: GAP & INTERPOLATION TRANSPARENCY (Winter, 2009)\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>Raw_Missing_%</th>\n",
              "      <th>Interpolation_Method</th>\n",
              "      <th>Resample_Interp_Positions</th>\n",
              "      <th>Resample_Interp_Rotations</th>\n",
              "      <th>Score_Interpolation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002</td>\n",
              "      <td>0.0</td>\n",
              "      <td>linear_quaternion_normalized</td>\n",
              "      <td>CubicSpline</td>\n",
              "      <td>SLERP</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Run_ID  Raw_Missing_%  \\\n",
              "0  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002            0.0   \n",
              "\n",
              "           Interpolation_Method Resample_Interp_Positions  \\\n",
              "0  linear_quaternion_normalized               CubicSpline   \n",
              "\n",
              "  Resample_Interp_Rotations  Score_Interpolation  \n",
              "0                     SLERP                100.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Interpolation Summary:\n",
            "  Pristine Data (0% missing): 1/1\n",
            "  Mean Missing: 0.00%\n",
            "  Mean Interpolation Score: 100.0/100\n",
            "\n",
            "Step 03 Resample Methods:\n",
            "  Rotations using SLERP: 1/1\n",
            "  Position Methods: {'CubicSpline': 1}\n",
            "\n",
            "Gap-Fill Method Distribution:\n",
            "Method_Category\n",
            "‚úÖ Quaternion (SLERP)    1\n"
          ]
        }
      ],
      "source": [
        "print_section_header(\"SECTION 3: GAP & INTERPOLATION TRANSPARENCY (Winter, 2009)\")\n",
        "\n",
        "# Include step_03 interpolation methods for positions and rotations\n",
        "cols_s3 = ['Run_ID', 'Raw_Missing_%', 'Interpolation_Method', \n",
        "           'Resample_Interp_Positions', 'Resample_Interp_Rotations', 'Score_Interpolation']\n",
        "display(df_quality[cols_s3])\n",
        "\n",
        "# Classify interpolation methods\n",
        "def classify_method(method):\n",
        "    method_str = str(method).lower()\n",
        "    if 'quaternion' in method_str or 'slerp' in method_str:\n",
        "        return '‚úÖ Quaternion (SLERP)'\n",
        "    elif 'spline' in method_str or 'cubic' in method_str:\n",
        "        return '‚úÖ Spline/Cubic'\n",
        "    elif 'linear' in method_str:\n",
        "        return 'üü† Linear Fallback'\n",
        "    else:\n",
        "        return '‚ö†Ô∏è Unknown'\n",
        "\n",
        "df_quality['Method_Category'] = df_quality['Interpolation_Method'].apply(classify_method)\n",
        "\n",
        "print(f\"\\nInterpolation Summary:\")\n",
        "print(f\"  Pristine Data (0% missing): {(df_quality['Raw_Missing_%'] == 0).sum()}/{len(df_quality)}\")\n",
        "print(f\"  Mean Missing: {df_quality['Raw_Missing_%'].mean():.2f}%\")\n",
        "print(f\"  Mean Interpolation Score: {df_quality['Score_Interpolation'].mean():.1f}/100\")\n",
        "\n",
        "# Step 03: Rotation & Position Methods\n",
        "if 'Resample_Interp_Rotations' in df_quality.columns:\n",
        "    slerp_count = df_quality['Resample_Interp_Rotations'].str.contains('SLERP', case=False, na=False).sum()\n",
        "    print(f\"\\nStep 03 Resample Methods:\")\n",
        "    print(f\"  Rotations using SLERP: {slerp_count}/{len(df_quality)}\")\n",
        "    print(f\"  Position Methods: {df_quality['Resample_Interp_Positions'].value_counts().to_dict()}\")\n",
        "\n",
        "print(f\"\\nGap-Fill Method Distribution:\")\n",
        "print(df_quality['Method_Category'].value_counts().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-4-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-4\"></a>\n",
        "## 6. Section 4: Winter's Residual Validation\n",
        "\n",
        "**Purpose:** Justify the filtering frequency (Winter, 2009) - Signal vs. Noise separation\n",
        "\n",
        "**Acceptable Range:** 4.0-12.0 Hz for dance movements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "section-4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTION 4: PER-REGION FILTERING VALIDATION\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>Filtering_Mode</th>\n",
              "      <th>Region_Cutoffs_Applied</th>\n",
              "      <th>Residual_RMS_mm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002</td>\n",
              "      <td>3_stage_pipeline</td>\n",
              "      <td>{'head': 14.5, 'upper_proximal': 14.5, 'trunk'...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Run_ID    Filtering_Mode  \\\n",
              "0  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002  3_stage_pipeline   \n",
              "\n",
              "                              Region_Cutoffs_Applied  Residual_RMS_mm  \n",
              "0  {'head': 14.5, 'upper_proximal': 14.5, 'trunk'...              0.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "WINTER VALIDATION PER REGION\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>RMS_Knee_Per_Region</th>\n",
              "      <th>Diminishing_Per_Region</th>\n",
              "      <th>Region_Validation_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002</td>\n",
              "      <td>{}</td>\n",
              "      <td>{}</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Run_ID RMS_Knee_Per_Region  \\\n",
              "0  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002                  {}   \n",
              "\n",
              "  Diminishing_Per_Region Region_Validation_Status  \n",
              "0                     {}                       {}  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Filtering Summary:\n",
            "  Filtering Mode: 3_stage_pipeline\n",
            "  Mean Residual RMS: 0.00 mm\n",
            "  Mean Filtering Score: 50.0/100\n",
            "\n",
            "============================================================\n",
            "TRUE RAW SNR (CAPTURE QUALITY)\n",
            "============================================================\n",
            "Method: Raw data frequency analysis (signal: 0.5-10Hz, noise: 15-50Hz)\n",
            "This measures inherent capture quality, NOT filtering effectiveness.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>Raw_SNR_Mean_dB</th>\n",
              "      <th>Raw_SNR_Min_dB</th>\n",
              "      <th>Raw_SNR_Max_dB</th>\n",
              "      <th>Raw_SNR_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002</td>\n",
              "      <td>47.9</td>\n",
              "      <td>39.5</td>\n",
              "      <td>55.9</td>\n",
              "      <td>EXCELLENT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Run_ID  Raw_SNR_Mean_dB  \\\n",
              "0  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002             47.9   \n",
              "\n",
              "   Raw_SNR_Min_dB  Raw_SNR_Max_dB Raw_SNR_Status  \n",
              "0            39.5            55.9      EXCELLENT  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "SNR Summary: Mean = 47.9 dB\n",
            "  Status: EXCELLENT - Publication quality capture\n"
          ]
        }
      ],
      "source": [
        "print_section_header(\"SECTION 4: PER-REGION FILTERING VALIDATION\")\n",
        "\n",
        "# Core filtering columns\n",
        "cols_s4 = ['Run_ID', 'Filtering_Mode', 'Region_Cutoffs_Applied', 'Residual_RMS_mm']\n",
        "display(df_quality[cols_s4])\n",
        "\n",
        "# Per-region Winter validation details\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"WINTER VALIDATION PER REGION\")\n",
        "print(\"=\"*60)\n",
        "cols_s4_detail = ['Run_ID', 'RMS_Knee_Per_Region', 'Diminishing_Per_Region', 'Region_Validation_Status']\n",
        "display(df_quality[cols_s4_detail])\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\nFiltering Summary:\")\n",
        "print(f\"  Filtering Mode: {df_quality['Filtering_Mode'].iloc[0] if len(df_quality) > 0 else 'N/A'}\")\n",
        "if 'Residual_RMS_mm' in df_quality.columns:\n",
        "    print(f\"  Mean Residual RMS: {df_quality['Residual_RMS_mm'].mean():.2f} mm\")\n",
        "print(f\"  Mean Filtering Score: {df_quality['Score_Filtering'].mean():.1f}/100\")\n",
        "\n",
        "# TRUE RAW SNR - Capture Quality Assessment\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRUE RAW SNR (CAPTURE QUALITY)\")\n",
        "print(\"=\"*60)\n",
        "print(\"Method: Raw data frequency analysis (signal: 0.5-10Hz, noise: 15-50Hz)\")\n",
        "print(\"This measures inherent capture quality, NOT filtering effectiveness.\")\n",
        "snr_cols = ['Run_ID', 'Raw_SNR_Mean_dB', 'Raw_SNR_Min_dB', 'Raw_SNR_Max_dB', 'Raw_SNR_Status']\n",
        "snr_cols_available = [c for c in snr_cols if c in df_quality.columns]\n",
        "if snr_cols_available:\n",
        "    display(df_quality[snr_cols_available])\n",
        "    if 'Raw_SNR_Mean_dB' in df_quality.columns:\n",
        "        mean_snr = df_quality['Raw_SNR_Mean_dB'].mean()\n",
        "        print(f\"\\nSNR Summary: Mean = {mean_snr:.1f} dB\")\n",
        "        if mean_snr >= 30:\n",
        "            print(\"  Status: EXCELLENT - Publication quality capture\")\n",
        "        elif mean_snr >= 20:\n",
        "            print(\"  Status: GOOD - Acceptable for research\")\n",
        "        elif mean_snr >= 15:\n",
        "            print(\"  Status: ACCEPTABLE - Review recommended\")\n",
        "        else:\n",
        "            print(\"  Status: POOR - Check capture environment\")\n",
        "else:\n",
        "    print(\"SNR data not yet computed. Re-run notebook 04_filtering.ipynb.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-5-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-5\"></a>\n",
        "## 7. Section 5: Reference Detection & Stability\n",
        "\n",
        "**Purpose:** Verify static pose alignment quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "section-5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTION 5: REFERENCE DETECTION & STABILITY\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Run_ID</th>\n",
              "      <th>Ref_Quality_Score</th>\n",
              "      <th>Ref_Confidence</th>\n",
              "      <th>Score_Reference</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002</td>\n",
              "      <td>0.895</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Run_ID  Ref_Quality_Score  \\\n",
              "0  734_T3_P2_R1_Take 2025-12-30 04.12.54 PM_002              0.895   \n",
              "\n",
              "  Ref_Confidence  Score_Reference  \n",
              "0           HIGH            100.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Reference Summary:\n",
            "  Mean Quality Score: 0.895\n",
            "  HIGH Confidence: 1/1\n",
            "  Mean Reference Score: 100.0/100\n"
          ]
        }
      ],
      "source": [
        "print_section_header(\"SECTION 5: REFERENCE DETECTION & STABILITY\")\n",
        "\n",
        "cols_s5 = ['Run_ID', 'Ref_Quality_Score', 'Ref_Confidence', 'Score_Reference']\n",
        "display(df_quality[cols_s5])\n",
        "\n",
        "print(f\"\\nReference Summary:\")\n",
        "print(f\"  Mean Quality Score: {df_quality['Ref_Quality_Score'].mean():.3f}\")\n",
        "print(f\"  HIGH Confidence: {(df_quality['Ref_Confidence'] == 'HIGH').sum()}/{len(df_quality)}\")\n",
        "print(f\"  Mean Reference Score: {df_quality['Score_Reference'].mean():.1f}/100\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-6-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-6\"></a>\n",
        "## 8. Section 6: Biomechanics & Outlier Analysis\n",
        "\n",
        "**Purpose:** Gaga-aware movement validation - distinguish extreme dance from tracking errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "section-6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTION 6: BIOMECHANICS & OUTLIER ANALYSIS\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"['Path_Length_mm', 'Intensity_Index'] not in index\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m print_section_header(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSECTION 6: BIOMECHANICS & OUTLIER ANALYSIS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m cols_s6 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRun_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPipeline_Status\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax_Ang_Vel_deg_s\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutlier_Frames\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      4\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutlier_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPath_Length_mm\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntensity_Index\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore_Biomechanics\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m display(\u001b[43mdf_quality\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_s6\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBiomechanics Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Recordings Processed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_quality)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['Path_Length_mm', 'Intensity_Index'] not in index\""
          ]
        }
      ],
      "source": [
        "print_section_header(\"SECTION 6: BIOMECHANICS & OUTLIER ANALYSIS\")\n",
        "\n",
        "cols_s6 = ['Run_ID', 'Pipeline_Status', 'Max_Ang_Vel_deg_s', 'Outlier_Frames', \n",
        "           'Outlier_%', 'Path_Length_mm', 'Intensity_Index', 'Score_Biomechanics']\n",
        "display(df_quality[cols_s6])\n",
        "\n",
        "print(f\"\\nBiomechanics Summary:\")\n",
        "print(f\"  Recordings Processed: {len(df_quality)}\")\n",
        "print(f\"  Latest Processing Step: {df_quality['Pipeline_Status'].mode()[0] if len(df_quality) > 0 else 'N/A'}\")\n",
        "print(f\"  Mean Outlier %: {df_quality['Outlier_%'].mean():.2f}%\")\n",
        "print(f\"  Max Angular Velocity: {df_quality['Max_Ang_Vel_deg_s'].max():.1f} deg/s\")\n",
        "print(f\"  Mean Biomechanics Score: {df_quality['Score_Biomechanics'].mean():.1f}/100\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-7-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-7\"></a>\n",
        "## 9. Quality Score Breakdown\n",
        "\n",
        "**Purpose:** Show how the overall quality score is computed from components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "section-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_section_header(\"QUALITY SCORE BREAKDOWN\")\n",
        "\n",
        "score_cols = ['Run_ID', 'Quality_Score', 'Score_Calibration', 'Score_Temporal', \n",
        "              'Score_Interpolation', 'Score_Filtering', 'Score_Reference', \n",
        "              'Score_Biomechanics', 'Score_Signal']\n",
        "display(df_quality[score_cols])\n",
        "\n",
        "print(f\"\\nComponent Score Summary (Mean):\")\n",
        "print(f\"  Calibration (15%):   {df_quality['Score_Calibration'].mean():.1f}\")\n",
        "print(f\"  Temporal (10%):      {df_quality['Score_Temporal'].mean():.1f}\")\n",
        "print(f\"  Interpolation (15%): {df_quality['Score_Interpolation'].mean():.1f}\")\n",
        "print(f\"  Filtering (10%):     {df_quality['Score_Filtering'].mean():.1f}\")\n",
        "print(f\"  Reference (15%):     {df_quality['Score_Reference'].mean():.1f}\")\n",
        "print(f\"  Biomechanics (15%):  {df_quality['Score_Biomechanics'].mean():.1f}\")\n",
        "print(f\"  Signal (20%):        {df_quality['Score_Signal'].mean():.1f}\")\n",
        "print(f\"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
        "print(f\"  OVERALL (weighted):  {df_quality['Quality_Score'].mean():.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "section-8-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"section-8\"></a>\n",
        "## 10. Section 8: Decision Matrix\n",
        "\n",
        "**Purpose:** Final verdict combining all QC metrics\n",
        "\n",
        "**Thresholds:**\n",
        "- ACCEPT: Score ‚â• 80\n",
        "- REVIEW: Score 60-79\n",
        "- REJECT: Score < 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "section-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_section_header(\"SECTION 8: DECISION MATRIX\")\n",
        "\n",
        "# Final decision table\n",
        "cols_decision = ['Run_ID', 'Quality_Score', 'Research_Decision', 'Pipeline_Status']\n",
        "display(df_quality[cols_decision])\n",
        "\n",
        "# Decision summary\n",
        "total = len(df_quality)\n",
        "accept = (df_quality['Research_Decision'] == 'ACCEPT').sum()\n",
        "review = (df_quality['Research_Decision'] == 'REVIEW').sum()\n",
        "reject = (df_quality['Research_Decision'] == 'REJECT').sum()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DECISION SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"  ‚úÖ ACCEPT: {accept}/{total} ({accept/total*100:.1f}%)\")\n",
        "print(f\"  ‚ö†Ô∏è REVIEW: {review}/{total} ({review/total*100:.1f}%)\")\n",
        "print(f\"  ‚ùå REJECT: {reject}/{total} ({reject/total*100:.1f}%)\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# List runs by decision\n",
        "if accept > 0:\n",
        "    print(f\"\\n‚úÖ ACCEPTED RUNS:\")\n",
        "    for _, row in df_quality[df_quality['Research_Decision'] == 'ACCEPT'].iterrows():\n",
        "        print(f\"  {row['Run_ID'][:60]} (Score: {row['Quality_Score']})\")\n",
        "\n",
        "if review > 0:\n",
        "    print(f\"\\n‚ö†Ô∏è REVIEW REQUIRED:\")\n",
        "    for _, row in df_quality[df_quality['Research_Decision'] == 'REVIEW'].iterrows():\n",
        "        print(f\"  {row['Run_ID'][:60]} (Score: {row['Quality_Score']})\")\n",
        "\n",
        "if reject > 0:\n",
        "    print(f\"\\n‚ùå REJECTED RUNS:\")\n",
        "    for _, row in df_quality[df_quality['Research_Decision'] == 'REJECT'].iterrows():\n",
        "        print(f\"  {row['Run_ID'][:60]} (Score: {row['Quality_Score']})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "export-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "<a id=\"export\"></a>\n",
        "## 11. Export to Excel\n",
        "\n",
        "**Output:** `reports/Master_Audit_Log_YYYYMMDD_HHMMSS.xlsx`\n",
        "\n",
        "**Sheets:**\n",
        "1. Executive_Summary - High-level statistics\n",
        "2. Quality_Report - Aggregated metrics per run\n",
        "3. Parameter_Audit - All raw JSON values\n",
        "4. Parameter_Schema - What each parameter means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "export-excel",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_section_header(\"EXPORT TO EXCEL\")\n",
        "\n",
        "# Create output path\n",
        "REPORTS_DIR = os.path.join(PROJECT_ROOT, \"reports\")\n",
        "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "excel_path = os.path.join(REPORTS_DIR, f\"Master_Audit_Log_{timestamp}.xlsx\")\n",
        "\n",
        "# Export\n",
        "output_path = export_to_excel(runs_data, excel_path, PROJECT_ROOT)\n",
        "\n",
        "print(f\"\\n‚úÖ Excel Report Created:\")\n",
        "print(f\"   {output_path}\")\n",
        "print(f\"\\n   Sheets:\")\n",
        "print(f\"   1. Executive_Summary - High-level statistics\")\n",
        "print(f\"   2. Quality_Report - {len(df_quality)} runs with metrics\")\n",
        "print(f\"   3. Parameter_Audit - {len(df_params.columns)} parameters extracted\")\n",
        "print(f\"   4. Parameter_Schema - Parameter documentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "export-schema",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# OPTIONAL: Export schema documentation\n",
        "# ============================================================\n",
        "DOCS_DIR = os.path.join(PROJECT_ROOT, \"docs\", \"technical\")\n",
        "CONFIG_DIR = os.path.join(PROJECT_ROOT, \"config\")\n",
        "\n",
        "# Export Markdown schema\n",
        "md_path = os.path.join(DOCS_DIR, \"PARAMETER_SCHEMA.md\")\n",
        "export_schema_markdown(md_path)\n",
        "print(f\"‚úÖ Markdown Schema: {md_path}\")\n",
        "\n",
        "# Export JSON schema\n",
        "json_path = os.path.join(CONFIG_DIR, \"report_schema.json\")\n",
        "export_schema_json(json_path)\n",
        "print(f\"‚úÖ JSON Schema: {json_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary-header",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook aggregated quality metrics from all pipeline steps and generated:\n",
        "\n",
        "1. **Console Summary** - Section-by-section quality analysis\n",
        "2. **Excel Report** - 4-sheet comprehensive audit log\n",
        "3. **Schema Documentation** - Parameter reference (MD + JSON)\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Review runs marked as **REVIEW** manually\n",
        "- Investigate runs marked as **REJECT** for reprocessing\n",
        "- Use **Parameter_Audit** sheet to trace any issues back to source JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "final-summary",
      "metadata": {},
      "outputs": [],
      "source": [
        "print_section_header(\"NOTEBOOK COMPLETE\")\n",
        "print(f\"\\nRuns Processed: {len(runs_data)}\")\n",
        "print(f\"Excel Output: {excel_path}\")\n",
        "print(f\"\\nDecision Distribution:\")\n",
        "print(df_quality['Research_Decision'].value_counts().to_string())\n",
        "print(f\"\\nMean Quality Score: {df_quality['Quality_Score'].mean():.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
