{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3524988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Found data for 2 run(s)\n",
      "üìÅ Steps loaded per run:\n",
      "  734_T1_P2_R1_Take 2025-12-01 02.28.24 PM: ['step_01', 'step_02', 'step_04', 'step_05', 'step_06']\n",
      "  763_T2_P2_R2_Take_2025-12-25 10.51.23 AM_005: ['step_01', 'step_02', 'step_04', 'step_05', 'step_06']\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üéâ Master Audit Log Created\n",
      "======================================================================\n",
      "üìä Total Runs: 2\n",
      "üíæ File: c:\\Users\\drorh\\OneDrive - Mobileye\\Desktop\\gaga\\reports\\Master_Audit_Log_20260113_211719.xlsx\n",
      "======================================================================\n",
      "\n",
      "Decision Summary:\n",
      "Research_Decision\n",
      "ACCEPT    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Quality Score Stats:\n",
      "  Mean: 87.89\n",
      "  Min:  87.88\n",
      "  Max:  87.91\n",
      "\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run_ID</th>\n",
       "      <th>Processing_Date</th>\n",
       "      <th>OptiTrack_Error_mm</th>\n",
       "      <th>Total_Frames</th>\n",
       "      <th>Missing_Raw_%</th>\n",
       "      <th>Max_Gap_Frames</th>\n",
       "      <th>Max_Gap_MS</th>\n",
       "      <th>Bone_Stability_CV</th>\n",
       "      <th>Skeletal_Alerts</th>\n",
       "      <th>Worst_Bone</th>\n",
       "      <th>...</th>\n",
       "      <th>Quat_Norm_Error</th>\n",
       "      <th>Max_Ang_Vel</th>\n",
       "      <th>Mean_Ang_Vel</th>\n",
       "      <th>Max_Lin_Acc</th>\n",
       "      <th>Outlier_Frames</th>\n",
       "      <th>Path_Length_M</th>\n",
       "      <th>Intensity_Index</th>\n",
       "      <th>Pipeline_Status</th>\n",
       "      <th>Quality_Score</th>\n",
       "      <th>Research_Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>763_T2_P2_R2_Take_2025-12-25 10.51.23 AM_005</td>\n",
       "      <td>2026-01-12 15:09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>83.33</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0</td>\n",
       "      <td>Hips-&gt;Spine</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1359.12</td>\n",
       "      <td>113.83</td>\n",
       "      <td>44376.02</td>\n",
       "      <td>40</td>\n",
       "      <td>61.28</td>\n",
       "      <td>0.291</td>\n",
       "      <td>PASS</td>\n",
       "      <td>87.91</td>\n",
       "      <td>ACCEPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>734_T1_P2_R1_Take 2025-12-01 02.28.24 PM</td>\n",
       "      <td>2026-01-13 20:35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>83.33</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0</td>\n",
       "      <td>Hips-&gt;Spine</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>900.17</td>\n",
       "      <td>44.92</td>\n",
       "      <td>19427.84</td>\n",
       "      <td>0</td>\n",
       "      <td>35.93</td>\n",
       "      <td>0.386</td>\n",
       "      <td>PASS</td>\n",
       "      <td>87.88</td>\n",
       "      <td>ACCEPT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Run_ID   Processing_Date  \\\n",
       "0  763_T2_P2_R2_Take_2025-12-25 10.51.23 AM_005  2026-01-12 15:09   \n",
       "1      734_T1_P2_R1_Take 2025-12-01 02.28.24 PM  2026-01-13 20:35   \n",
       "\n",
       "   OptiTrack_Error_mm  Total_Frames  Missing_Raw_%  Max_Gap_Frames  \\\n",
       "0                 0.0         17263            0.0              10   \n",
       "1                 0.0         19617            0.0              10   \n",
       "\n",
       "   Max_Gap_MS  Bone_Stability_CV  Skeletal_Alerts   Worst_Bone  ...  \\\n",
       "0       83.33              0.376                0  Hips->Spine  ...   \n",
       "1       83.33              0.379                0  Hips->Spine  ...   \n",
       "\n",
       "   Quat_Norm_Error Max_Ang_Vel  Mean_Ang_Vel  Max_Lin_Acc  Outlier_Frames  \\\n",
       "0              0.0     1359.12        113.83     44376.02              40   \n",
       "1              0.0      900.17         44.92     19427.84               0   \n",
       "\n",
       "   Path_Length_M  Intensity_Index  Pipeline_Status  Quality_Score  \\\n",
       "0          61.28            0.291             PASS          87.91   \n",
       "1          35.93            0.386             PASS          87.88   \n",
       "\n",
       "   Research_Decision  \n",
       "0             ACCEPT  \n",
       "1             ACCEPT  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd  # Fixed: was \"import pd\"\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# --- Setup Paths ---\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.insert(0, SRC_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ◊§◊ï◊†◊ß◊¶◊ô◊ô◊™ ◊¢◊ñ◊® ◊ú◊©◊ú◊ô◊§◊î ◊ë◊ò◊ï◊ó◊î ◊©◊ú ◊†◊™◊ï◊†◊ô◊ù ◊û◊ß◊ï◊†◊†◊ô◊ù\n",
    "def safe_get(d, *keys, default='N/A'):\n",
    "    for key in keys:\n",
    "        if isinstance(d, dict):\n",
    "            d = d.get(key, {})\n",
    "        else:\n",
    "            return default\n",
    "    return d if (d != {} and d is not None) else default\n",
    "\n",
    "def safe_float(value, default=0.0):\n",
    "    if value is None or value == 'N/A': return default\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            value = value.replace('%', '').strip()\n",
    "        return float(value)\n",
    "    except: return default\n",
    "\n",
    "# ============================================================\n",
    "# 1. ◊ò◊¢◊ô◊†◊™ ◊ß◊ë◊¶◊ô◊ù ◊ï◊ß◊ô◊ë◊ï◊• ◊ú◊§◊ô Run_ID\n",
    "# ============================================================\n",
    "DERIV_ROOT = os.path.join(PROJECT_ROOT, \"derivatives\")\n",
    "json_files = glob.glob(os.path.join(DERIV_ROOT, \"*\", \"*.json\"))\n",
    "\n",
    "from collections import defaultdict\n",
    "runs = defaultdict(dict)\n",
    "\n",
    "for json_path in json_files:\n",
    "    filename = os.path.basename(json_path)\n",
    "    run_id = filename.split('__')[0]\n",
    "    \n",
    "    with open(json_path, 'r', encoding='utf-8') as f:  # Added encoding\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # ◊û◊ô◊ï◊ü ◊ú◊ß◊ò◊í◊ï◊®◊ô◊ï◊™ ◊ú◊§◊ô ◊™◊ï◊õ◊ü ◊î◊ß◊ï◊ë◊•\n",
    "    if 'loader_report' in filename or 'step01' in filename:\n",
    "        runs[run_id]['step_01'] = data\n",
    "    elif 'preprocess_summary' in filename:\n",
    "        runs[run_id]['step_02'] = data\n",
    "    elif 'filtering_summary' in filename:\n",
    "        runs[run_id]['step_04'] = data\n",
    "    elif 'reference' in filename and 'summary' in filename:\n",
    "        runs[run_id]['step_05'] = data\n",
    "    elif 'kinematics_summary' in filename:\n",
    "        runs[run_id]['step_06'] = data\n",
    "\n",
    "print(f\"üìä Found data for {len(runs)} run(s)\")\n",
    "print(f\"üìÅ Steps loaded per run:\")\n",
    "for rid, steps in runs.items():\n",
    "    print(f\"  {rid}: {list(steps.keys())}\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# 2. ◊ë◊†◊ô◊ô◊™ ◊ò◊ë◊ú◊™ ◊î◊û◊ê◊°◊ò◊® (Master Audit)\n",
    "# ============================================================\n",
    "all_summaries = []\n",
    "for run_id, steps in runs.items():\n",
    "    s01 = steps.get('step_01', {})\n",
    "    s02 = steps.get('step_02', {})\n",
    "    s04 = steps.get('step_04', {})\n",
    "    s05 = steps.get('step_05', {})\n",
    "    s06 = steps.get('step_06', {})\n",
    "    \n",
    "    if not s01 or not s06:\n",
    "        print(f\"‚ö†Ô∏è  Skipping {run_id}: Missing critical step data\")\n",
    "        continue\n",
    "    \n",
    "    fps = safe_float(safe_get(s01, 'raw_data_quality', 'sampling_rate_actual'), default=120.0)\n",
    "    \n",
    "    row = {\n",
    "        # --- Identity ---\n",
    "        \"Run_ID\": run_id,\n",
    "        \"Processing_Date\": safe_get(s01, 'identity', 'processing_timestamp'),\n",
    "        \"OptiTrack_Error_mm\": safe_float(safe_get(s01, 'raw_data_quality', 'optitrack_mean_error_mm')),\n",
    "        \n",
    "        # --- Raw Quality & Preprocess (Step 01 & 02) ---\n",
    "        \"Total_Frames\": safe_get(s01, 'raw_data_quality', 'total_frames', default=0),\n",
    "        \"Missing_Raw_%\": safe_float(safe_get(s02, 'raw_missing_percent')),\n",
    "        \"Max_Gap_Frames\": safe_get(s02, 'max_interpolation_gap', default=0),\n",
    "        \"Max_Gap_MS\": round((safe_float(safe_get(s02, 'max_interpolation_gap')) / fps) * 1000, 2),\n",
    "        \n",
    "        # --- Bone QC (Step 02) ---\n",
    "        \"Bone_Stability_CV\": safe_float(safe_get(s02, 'bone_qc_mean_cv')),\n",
    "        \"Skeletal_Alerts\": safe_get(s02, 'bone_qc_alerts', default=0),\n",
    "        \"Worst_Bone\": safe_get(s02, 'worst_bone'),\n",
    "        \n",
    "        # --- Reference Stability (Step 05) ---\n",
    "        \"Ref_Stability_mm\": safe_float(safe_get(s05, 'reference_metrics', 'ref_stability_mm')),\n",
    "        \"Ref_Status\": safe_get(s05, 'reference_metrics', 'ref_quality_status'),\n",
    "        \n",
    "        # --- Signal Quality (Step 06) ---\n",
    "        \"Signal_Noise_RMS\": safe_float(safe_get(s06, 'signal_quality', 'avg_vel_residual_rms')),\n",
    "        \"Dom_Freq_Hz\": safe_float(safe_get(s06, 'signal_quality', 'avg_dominant_freq_hz')),\n",
    "        \"Quat_Norm_Error\": safe_float(safe_get(s06, 'signal_quality', 'max_quat_norm_error')),\n",
    "        \n",
    "        # --- Kinematics (Step 06) ---\n",
    "        \"Max_Ang_Vel\": safe_float(safe_get(s06, 'metrics', 'angular_velocity', 'max')),\n",
    "        \"Mean_Ang_Vel\": safe_float(safe_get(s06, 'metrics', 'angular_velocity', 'mean')),\n",
    "        \"Max_Lin_Acc\": safe_float(safe_get(s06, 'metrics', 'linear_accel', 'max')),\n",
    "        \"Outlier_Frames\": safe_get(s06, 'effort_metrics', 'outlier_frame_count', default=0),\n",
    "        \n",
    "        # --- Effort Metrics (Step 06) ---\n",
    "        \"Path_Length_M\": round(safe_float(safe_get(s06, 'effort_metrics', 'total_path_length_mm')) / 1000, 2),\n",
    "        \"Intensity_Index\": safe_float(safe_get(s06, 'effort_metrics', 'intensity_index')),\n",
    "        \n",
    "        # --- Overall Status ---\n",
    "        \"Pipeline_Status\": safe_get(s06, 'overall_status'),\n",
    "    }\n",
    "    \n",
    "    # === ◊ú◊ï◊í◊ô◊ß◊™ ◊¶◊ô◊ï◊ü ◊ê◊ô◊õ◊ï◊™ ◊û◊©◊ï◊ì◊®◊í◊™ ===\n",
    "    score = 100.0\n",
    "    # ◊ß◊†◊°◊ï◊™ ◊¢◊ú ◊ê◊ô◊õ◊ï◊™ ◊†◊™◊ï◊†◊ô◊ù\n",
    "    score -= safe_float(row[\"Missing_Raw_%\"]) * 5\n",
    "    score -= (safe_float(row[\"Max_Gap_MS\"]) / 10) # ◊ß◊†◊° ◊¢◊ú ◊ó◊ï◊®◊ô◊ù ◊í◊ì◊ï◊ú◊ô◊ù\n",
    "    \n",
    "    # ◊ß◊†◊°◊ï◊™ ◊¢◊ú ◊ô◊¶◊ô◊ë◊ï◊™ ◊©◊ú◊ì (Bone QC)\n",
    "    score -= safe_float(row[\"Bone_Stability_CV\"]) * 10 \n",
    "    score -= safe_float(row[\"Skeletal_Alerts\"]) * 5\n",
    "    \n",
    "    # ◊ß◊†◊° ◊¢◊ú ◊ô◊¶◊ô◊ë◊ï◊™ ◊®◊§◊®◊†◊°\n",
    "    ref_stab = safe_float(row[\"Ref_Stability_mm\"])\n",
    "    if ref_stab > 4.0: score -= 15\n",
    "    \n",
    "    row[\"Quality_Score\"] = round(max(0, min(100, score)), 2)\n",
    "    \n",
    "    # === ◊î◊ó◊ú◊ò◊î ◊û◊ó◊ß◊®◊ô◊™ ===\n",
    "    # ◊™◊†◊ê◊ô ◊°◊£ ◊û◊ó◊û◊ô◊®◊ô◊ù ◊ú-ACCEPT\n",
    "    if (row[\"Pipeline_Status\"] == \"PASS\" and \n",
    "        row[\"Quality_Score\"] >= 75 and \n",
    "        row[\"Ref_Status\"] == \"PASS\" and \n",
    "        safe_float(row[\"Bone_Stability_CV\"]) < 1.5):\n",
    "        row[\"Research_Decision\"] = \"ACCEPT\"\n",
    "    elif row[\"Pipeline_Status\"] == \"PASS\" and row[\"Quality_Score\"] >= 50:\n",
    "        row[\"Research_Decision\"] = \"REVIEW\"\n",
    "    else:\n",
    "        row[\"Research_Decision\"] = \"REJECT\"\n",
    "    \n",
    "    all_summaries.append(row)\n",
    "# ============================================================\n",
    "# 3. ◊ô◊¶◊ô◊®◊™ DataFrame ◊ï◊ô◊ô◊¶◊ï◊ê ◊ú◊ê◊ß◊°◊ú\n",
    "# ============================================================\n",
    "if not all_summaries:\n",
    "    print(\"‚ùå No complete runs found to aggregate!\")\n",
    "else:\n",
    "    df_master = pd.DataFrame(all_summaries)\n",
    "    df_master = df_master.sort_values('Quality_Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    REPORTS_DIR = os.path.join(PROJECT_ROOT, \"reports\")\n",
    "    os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "    excel_path = os.path.join(REPORTS_DIR, f\"Master_Audit_Log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\")\n",
    "    \n",
    "    with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:\n",
    "        df_master.to_excel(writer, index=False, sheet_name='Audit_Log')\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Audit_Log']\n",
    "        \n",
    "        # Header format\n",
    "        header_fmt = workbook.add_format({'bold': True, 'bg_color': '#4472C4', 'font_color': 'white'})\n",
    "        for col_num, value in enumerate(df_master.columns.values):\n",
    "            worksheet.write(0, col_num, value, header_fmt)\n",
    "        \n",
    "        # Conditional formatting for Research_Decision\n",
    "        red_fmt = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006'})\n",
    "        yellow_fmt = workbook.add_format({'bg_color': '#FFEB9C', 'font_color': '#9C6500'})\n",
    "        green_fmt = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100'})\n",
    "        \n",
    "        col_idx = df_master.columns.get_loc(\"Research_Decision\")\n",
    "        for row_num in range(1, len(df_master) + 1):\n",
    "            decision = df_master.iloc[row_num-1]['Research_Decision']\n",
    "            if decision == 'ACCEPT':\n",
    "                worksheet.write(row_num, col_idx, decision, green_fmt)\n",
    "            elif decision == 'REVIEW':\n",
    "                worksheet.write(row_num, col_idx, decision, yellow_fmt)\n",
    "            else:\n",
    "                worksheet.write(row_num, col_idx, decision, red_fmt)\n",
    "        \n",
    "        # Auto-fit columns\n",
    "        for i, col in enumerate(df_master.columns):\n",
    "            max_len = max(df_master[col].astype(str).str.len().max(), len(col))\n",
    "            worksheet.set_column(i, i, min(max_len + 2, 40))\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üéâ Master Audit Log Created\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"üìä Total Runs: {len(all_summaries)}\")\n",
    "    print(f\"üíæ File: {excel_path}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    print(\"Decision Summary:\")\n",
    "    print(df_master['Research_Decision'].value_counts())\n",
    "    \n",
    "    print(\"\\nQuality Score Stats:\")\n",
    "    print(f\"  Mean: {df_master['Quality_Score'].mean():.2f}\")\n",
    "    print(f\"  Min:  {df_master['Quality_Score'].min():.2f}\")\n",
    "    print(f\"  Max:  {df_master['Quality_Score'].max():.2f}\")\n",
    "    \n",
    "    print(\"\\nPreview:\")\n",
    "    display(df_master.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
