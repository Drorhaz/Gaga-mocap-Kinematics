{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "header",
      "metadata": {},
      "source": [
        "# NB06.5: Universal Kinematic Cleaning Lab\n",
        "\n",
        "**Purpose**: A general-purpose cleaning gate that applies to any session without hard-coding specific joint names.\n",
        "\n",
        "**Pipeline Stages**:\n",
        "1. **Adaptive Artifact Detection** - Find physically impossible values automatically\n",
        "2. **Multi-Path Repair** - PCHIP for scalars, SLERP for quaternions\n",
        "3. **Recalculation & Consistency** - Rebuild acceleration from cleaned velocity\n",
        "4. **Universal Comparison Log** - Before/After audit table\n",
        "\n",
        "**Input**: Output from NB06 (`df_combined_kinematics.parquet`)\n",
        "\n",
        "**Output**: Cleaned kinematics ready for NB07 audit\n",
        "\n",
        "---\n",
        "**Physical Ceilings** (Literature-based):\n",
        "- Angular Velocity: 1200 ¬∞/s (peak human joint velocity)\n",
        "- Angular Acceleration: 50,000 ¬∞/s¬≤ (biomechanical limit)\n",
        "- ROM: 250¬∞ (physiological joint limit for most human joints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_01_setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 01: Setup & Configuration ---\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from scipy.interpolate import PchipInterpolator\n",
        "from scipy.spatial.transform import Rotation as R, Slerp\n",
        "\n",
        "# --- Path Setup (Consistent with other notebooks) ---\n",
        "if os.path.basename(os.getcwd()) == 'notebooks':\n",
        "    PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "else:\n",
        "    PROJECT_ROOT = os.path.abspath(os.getcwd())\n",
        "SRC_PATH = os.path.join(PROJECT_ROOT, \"src\")\n",
        "if SRC_PATH not in sys.path:\n",
        "    sys.path.insert(0, SRC_PATH)\n",
        "\n",
        "from pipeline_config import CONFIG\n",
        "\n",
        "# Derive filename from config (synchronized with previous notebooks)\n",
        "csv_filename = Path(CONFIG['current_csv']).stem\n",
        "RUN_ID = csv_filename\n",
        "TARGET_FPS = CONFIG['FS_TARGET']\n",
        "\n",
        "# Paths (consistent with pipeline structure)\n",
        "DERIVATIVES = Path(PROJECT_ROOT) / CONFIG['derivatives_dir']\n",
        "STEP_06_DIR = DERIVATIVES / 'step_06_kinematics'\n",
        "STEP_065_DIR = DERIVATIVES / 'step_065_cleaned'\n",
        "STEP_065_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ============================================================\n",
        "# PHYSICAL CEILINGS (Universal - No Hard-Coded Joint Names)\n",
        "# ============================================================\n",
        "CEILING_ANGULAR_VEL = 1200.0      # deg/s - Peak human joint velocity\n",
        "CEILING_ANGULAR_ACC = 50000.0     # deg/s¬≤ - Biomechanical acceleration limit\n",
        "CEILING_ROM = 250.0               # degrees - Max physiological joint ROM\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"üî¨ NB06.5: Universal Kinematic Cleaning Lab\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Session: {RUN_ID}\")\n",
        "print(f\"Sample Rate: {TARGET_FPS} Hz\")\n",
        "print(f\"\\nüìè Physical Ceilings:\")\n",
        "print(f\"   Angular Velocity:     {CEILING_ANGULAR_VEL:,.0f} ¬∞/s\")\n",
        "print(f\"   Angular Acceleration: {CEILING_ANGULAR_ACC:,.0f} ¬∞/s¬≤\")\n",
        "print(f\"   ROM Limit:            {CEILING_ROM:.0f}¬∞\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_02_load",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 02: Load Data from NB06 ---\n",
        "input_path = STEP_06_DIR / f\"{RUN_ID}__kinematics.parquet\"\n",
        "\n",
        "if not input_path.exists():\n",
        "    raise FileNotFoundError(f\"Input file not found: {input_path}\\nPlease run NB06 first.\")\n",
        "\n",
        "df_raw = pd.read_parquet(input_path)\n",
        "df = df_raw.copy()  # Working copy for cleaning\n",
        "\n",
        "print(f\"‚úÖ Loaded: {input_path.name}\")\n",
        "print(f\"   Shape: {df.shape[0]:,} frames √ó {df.shape[1]:,} columns\")\n",
        "print(f\"   Duration: {df.shape[0] / TARGET_FPS:.2f} seconds\")\n",
        "\n",
        "# ============================================================\n",
        "# Auto-Detect Column Types (No Hard-Coded Names)\n",
        "# ============================================================\n",
        "vel_cols = [c for c in df.columns if c.endswith('_vel') or '_vel' in c]\n",
        "acc_cols = [c for c in df.columns if c.endswith('_acc') or '_acc' in c]\n",
        "mag_vel_cols = [c for c in df.columns if 'mag_vel' in c]\n",
        "quat_cols = [c for c in df.columns if any(c.endswith(s) for s in ['__qx', '__qy', '__qz', '__qw'])]\n",
        "# IMPORTANT: Angle columns for ROM = only position angles, NOT velocity/acceleration\n",
        "angle_cols = [c for c in df.columns if '_angle' in c.lower() and '_vel' not in c.lower() and '_acc' not in c.lower()]\n",
        "\n",
        "# Extract unique joint names from velocity columns\n",
        "joint_names = list(set([c.rsplit('_', 2)[0] for c in mag_vel_cols if 'mag_vel' in c]))\n",
        "\n",
        "print(f\"\\nüìä Auto-Detected Columns:\")\n",
        "print(f\"   Velocity columns:     {len(vel_cols)}\")\n",
        "print(f\"   Acceleration columns: {len(acc_cols)}\")\n",
        "print(f\"   Magnitude velocity:   {len(mag_vel_cols)}\")\n",
        "print(f\"   Quaternion columns:   {len(quat_cols)}\")\n",
        "print(f\"   Angle columns:        {len(angle_cols)}\")\n",
        "print(f\"   Unique joints:        {len(joint_names)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1348b944",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 02.5: Angle Unwrapping (Fix ¬±180¬∞ Phase Jumps) ---\n",
        "# Unwrap angles to ensure ROM reflects human envelope, not math envelope\n",
        "# Fixes cases where 179¬∞ ‚Üí -179¬∞ appears as 358¬∞ jump (actually just 2¬∞)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üîÑ ANGLE UNWRAPPING: Fixing ¬±180¬∞ Phase Jumps\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "def robust_unwrap(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Unwrap angle data to remove ¬±180¬∞ phase jumps.\n",
        "    \n",
        "    Uses np.unwrap to convert degrees to radians, unwrap, then convert back.\n",
        "    This ensures ROM reflects actual human motion, not mathematical wraparound.\n",
        "    \n",
        "    Example:\n",
        "        Raw: [179¬∞, 180¬∞, -179¬∞] ‚Üí ROM = 358¬∞ (WRONG - phase jump)\n",
        "        Unwrapped: [179¬∞, 180¬∞, 181¬∞] ‚Üí ROM = 2¬∞ (CORRECT - actual motion)\n",
        "    \"\"\"\n",
        "    # Convert to radians, unwrap, convert back to degrees\n",
        "    angles_rad = np.deg2rad(series.values)\n",
        "    unwrapped_rad = np.unwrap(angles_rad)\n",
        "    unwrapped_deg = np.rad2deg(unwrapped_rad)\n",
        "    \n",
        "    return pd.Series(unwrapped_deg, index=series.index)\n",
        "\n",
        "# Helper function for ROM calculation\n",
        "def calculate_joint_rom(angles: np.ndarray, use_wrapped: bool = False) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Range of Motion from angle data.\n",
        "    \n",
        "    Args:\n",
        "        angles: Angle values (can be wrapped or unwrapped)\n",
        "        use_wrapped: If True, wrap angles to [-180, 180] before calculating ROM\n",
        "                     This prevents cumulative rotation from inflating ROM\n",
        "    \n",
        "    Returns:\n",
        "        ROM in degrees (actual range of motion, not cumulative rotation)\n",
        "    \"\"\"\n",
        "    valid_angles = angles[np.isfinite(angles)]\n",
        "    if len(valid_angles) < 2:\n",
        "        return 0.0\n",
        "    \n",
        "    # Calculate ROM on unwrapped angles (phase jumps already fixed by unwrapping)\n",
        "    rom_unwrapped = float(np.max(valid_angles) - np.min(valid_angles))\n",
        "    \n",
        "    # If ROM > 360¬∞, it means the joint rotated more than one full cycle\n",
        "    # In this case, wrap to get the actual range within one cycle\n",
        "    if rom_unwrapped > 360:\n",
        "        # Multiple full rotations - wrap to get actual ROM within one cycle\n",
        "        angles_wrapped = np.mod(valid_angles + 180, 360) - 180\n",
        "        rom_wrapped = float(np.max(angles_wrapped) - np.min(angles_wrapped))\n",
        "        # Return the wrapped ROM (actual range within one cycle)\n",
        "        return rom_wrapped\n",
        "    elif rom_unwrapped > 350:\n",
        "        # ROM between 350-360¬∞ is suspicious - likely a phase jump artifact\n",
        "        # Check if there's a discontinuity (large jump in the middle)\n",
        "        sorted_angles = np.sort(valid_angles)\n",
        "        diffs = np.diff(sorted_angles)\n",
        "        max_gap = np.max(diffs)\n",
        "        \n",
        "        # If there's a large gap (> 10¬∞), it's likely a phase jump\n",
        "        # The actual ROM is probably the smaller of the two ranges\n",
        "        if max_gap > 10:\n",
        "            # Find the gap and calculate ROM on each side\n",
        "            gap_idx = np.argmax(diffs)\n",
        "            range1 = sorted_angles[gap_idx] - sorted_angles[0]\n",
        "            range2 = sorted_angles[-1] - sorted_angles[gap_idx + 1]\n",
        "            # Return the larger range (actual motion range)\n",
        "            actual_rom = max(range1, range2)\n",
        "            return actual_rom\n",
        "        \n",
        "        # No large gap - might be real full rotation, but for joints this is unlikely\n",
        "        # Wrap to get the range within one cycle\n",
        "        angles_wrapped = np.mod(valid_angles + 180, 360) - 180\n",
        "        rom_wrapped = float(np.max(angles_wrapped) - np.min(angles_wrapped))\n",
        "        return rom_wrapped\n",
        "    else:\n",
        "        # ROM < 350¬∞ means it's within one rotation cycle - use unwrapped value\n",
        "        # This correctly handles phase jumps that were fixed by unwrapping\n",
        "        return rom_unwrapped\n",
        "\n",
        "# Store original ROMs for comparison\n",
        "rom_before_unwrap = {}\n",
        "rom_after_unwrap = {}\n",
        "\n",
        "if angle_cols:\n",
        "    print(f\"\\nüìç Unwrapping {len(angle_cols)} angle columns...\")\n",
        "    \n",
        "    unwrap_stats = {\n",
        "        'columns_unwrapped': 0,\n",
        "        'rom_reductions': [],\n",
        "        'total_rom_reduction': 0.0\n",
        "    }\n",
        "    \n",
        "    for col in angle_cols:\n",
        "        # Calculate ROM before unwrapping (use wrapped to get actual ROM)\n",
        "        angles_raw = df[col].values\n",
        "        rom_raw = calculate_joint_rom(angles_raw, use_wrapped=True)\n",
        "        rom_before_unwrap[col] = rom_raw\n",
        "        \n",
        "        # Unwrap the angles (for data continuity)\n",
        "        angles_unwrapped = robust_unwrap(df[col])\n",
        "        df[col] = angles_unwrapped.values\n",
        "        \n",
        "        # Calculate ROM after unwrapping (directly on unwrapped angles)\n",
        "        # Unwrapping already fixed phase jumps, so calculate ROM directly\n",
        "        rom_unwrapped = calculate_joint_rom(df[col].values, use_wrapped=False)\n",
        "        rom_after_unwrap[col] = rom_unwrapped\n",
        "        \n",
        "        # Track significant reductions (phase jumps fixed)\n",
        "        if rom_raw > 250 and rom_unwrapped < rom_raw * 0.8:  # >20% reduction\n",
        "            reduction = rom_raw - rom_unwrapped\n",
        "            unwrap_stats['rom_reductions'].append({\n",
        "                'column': col,\n",
        "                'raw_rom': rom_raw,\n",
        "                'unwrapped_rom': rom_unwrapped,\n",
        "                'reduction': reduction\n",
        "            })\n",
        "            unwrap_stats['total_rom_reduction'] += reduction\n",
        "        \n",
        "        if rom_unwrapped != rom_raw:\n",
        "            unwrap_stats['columns_unwrapped'] += 1\n",
        "    \n",
        "    print(f\"   ‚úÖ Unwrapped {unwrap_stats['columns_unwrapped']} columns with phase jumps\")\n",
        "    \n",
        "    if unwrap_stats['rom_reductions']:\n",
        "        print(f\"\\n   üìä Phase Jumps Fixed (ROM Reduction >20%):\")\n",
        "        print(f\"   {'-'*90}\")\n",
        "        print(f\"   {'Column':<50} {'Raw ROM':>12} {'Unwrapped ROM':>15} {'Reduction':>12}\")\n",
        "        print(f\"   {'-'*90}\")\n",
        "        \n",
        "        for stat in sorted(unwrap_stats['rom_reductions'], key=lambda x: -x['reduction'])[:10]:\n",
        "            print(f\"   {stat['column']:<50} {stat['raw_rom']:>10.1f}¬∞ {stat['unwrapped_rom']:>13.1f}¬∞ {stat['reduction']:>10.1f}¬∞\")\n",
        "        \n",
        "        print(f\"   {'-'*90}\")\n",
        "        print(f\"   Total ROM reduction: {unwrap_stats['total_rom_reduction']:.1f}¬∞\")\n",
        "        print(f\"   ‚úÖ Angles now reflect human envelope, not math envelope\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ No significant phase jumps detected\")\n",
        "    \n",
        "    # Debug: Check elbow angles specifically\n",
        "    elbow_cols = [c for c in angle_cols if 'elbow' in c.lower() and 'angle' in c.lower()]\n",
        "    if elbow_cols:\n",
        "        print(f\"\\n   üîç DEBUG: Elbow Angle Analysis\")\n",
        "        print(f\"   {'-'*90}\")\n",
        "        for col in elbow_cols[:4]:  # Check first 4 elbow columns\n",
        "            angles = df[col].values\n",
        "            angles_wrapped = np.mod(angles + 180, 360) - 180\n",
        "            rom_wrapped = float(np.max(angles_wrapped) - np.min(angles_wrapped))\n",
        "            rom_unwrapped = float(np.max(angles) - np.min(angles))\n",
        "            \n",
        "            # Check for phase jumps (large jumps between consecutive values)\n",
        "            diffs = np.abs(np.diff(angles))\n",
        "            phase_jumps = np.sum(diffs > 300)  # Jumps > 300¬∞ are likely phase jumps\n",
        "            \n",
        "            print(f\"   {col}:\")\n",
        "            print(f\"      Wrapped ROM: {rom_wrapped:.1f}¬∞ | Unwrapped ROM: {rom_unwrapped:.1f}¬∞\")\n",
        "            print(f\"      Min: {np.min(angles_wrapped):.1f}¬∞ | Max: {np.max(angles_wrapped):.1f}¬∞\")\n",
        "            print(f\"      Phase jumps detected: {phase_jumps}\")\n",
        "            if phase_jumps > 0:\n",
        "                jump_indices = np.where(diffs > 300)[0]\n",
        "                print(f\"      Jump locations: {jump_indices[:5]} (showing first 5)\")\n",
        "        print(f\"   {'-'*90}\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è No angle columns found - skipping unwrapping\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_03_stage1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 03: STAGE 1 - Adaptive Artifact Detection ---\n",
        "# Automatically find ANY joint with physically impossible values\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üîç STAGE 1: Adaptive Artifact Detection\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Track artifacts for audit\n",
        "artifacts_detected = {\n",
        "    'velocity': {},\n",
        "    'acceleration': {},\n",
        "    'total_frames_affected': 0\n",
        "}\n",
        "\n",
        "# --- 1A: Velocity Artifacts (>1200 ¬∞/s) ---\n",
        "print(f\"\\nüìç Scanning for Velocity Artifacts (>{CEILING_ANGULAR_VEL}¬∞/s)...\")\n",
        "velocity_artifact_mask = pd.DataFrame(index=df.index)\n",
        "\n",
        "for col in vel_cols:\n",
        "    artifact_mask = np.abs(df[col]) > CEILING_ANGULAR_VEL\n",
        "    n_artifacts = artifact_mask.sum()\n",
        "    \n",
        "    if n_artifacts > 0:\n",
        "        velocity_artifact_mask[col] = artifact_mask\n",
        "        max_val = df.loc[artifact_mask, col].abs().max() if artifact_mask.any() else 0\n",
        "        artifacts_detected['velocity'][col] = {\n",
        "            'count': int(n_artifacts),\n",
        "            'max_value': float(max_val),\n",
        "            'percent': float(n_artifacts / len(df) * 100)\n",
        "        }\n",
        "        # Mark as NaN for repair\n",
        "        df.loc[artifact_mask, col] = np.nan\n",
        "\n",
        "# --- 1B: Acceleration Artifacts (>50,000 ¬∞/s¬≤) ---\n",
        "print(f\"üìç Scanning for Acceleration Artifacts (>{CEILING_ANGULAR_ACC:,.0f}¬∞/s¬≤)...\")\n",
        "acceleration_artifact_mask = pd.DataFrame(index=df.index)\n",
        "\n",
        "for col in acc_cols:\n",
        "    artifact_mask = np.abs(df[col]) > CEILING_ANGULAR_ACC\n",
        "    n_artifacts = artifact_mask.sum()\n",
        "    \n",
        "    if n_artifacts > 0:\n",
        "        acceleration_artifact_mask[col] = artifact_mask\n",
        "        max_val = df.loc[artifact_mask, col].abs().max() if artifact_mask.any() else 0\n",
        "        artifacts_detected['acceleration'][col] = {\n",
        "            'count': int(n_artifacts),\n",
        "            'max_value': float(max_val),\n",
        "            'percent': float(n_artifacts / len(df) * 100)\n",
        "        }\n",
        "        # Mark as NaN for repair\n",
        "        df.loc[artifact_mask, col] = np.nan\n",
        "\n",
        "# Summary\n",
        "total_vel_artifacts = sum(v['count'] for v in artifacts_detected['velocity'].values())\n",
        "total_acc_artifacts = sum(v['count'] for v in artifacts_detected['acceleration'].values())\n",
        "artifacts_detected['total_frames_affected'] = total_vel_artifacts + total_acc_artifacts\n",
        "\n",
        "print(f\"\\nüìä STAGE 1 Results:\")\n",
        "print(f\"   Velocity artifacts:     {total_vel_artifacts:,} frames in {len(artifacts_detected['velocity'])} columns\")\n",
        "print(f\"   Acceleration artifacts: {total_acc_artifacts:,} frames in {len(artifacts_detected['acceleration'])} columns\")\n",
        "\n",
        "if artifacts_detected['velocity']:\n",
        "    print(f\"\\n   üö® Joints with Velocity Artifacts:\")\n",
        "    for col, info in sorted(artifacts_detected['velocity'].items(), key=lambda x: -x[1]['count'])[:10]:\n",
        "        print(f\"      {col}: {info['count']:,} frames (max: {info['max_value']:.1f}¬∞/s)\")\n",
        "\n",
        "if artifacts_detected['acceleration']:\n",
        "    print(f\"\\n   üö® Joints with Acceleration Artifacts:\")\n",
        "    for col, info in sorted(artifacts_detected['acceleration'].items(), key=lambda x: -x[1]['count'])[:10]:\n",
        "        print(f\"      {col}: {info['count']:,} frames (max: {info['max_value']:.1f}¬∞/s¬≤)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_04_stage2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 04: STAGE 2A - PCHIP Repair for Scalar Kinematics ---\n",
        "# Piecewise Cubic Hermite Interpolating Polynomial\n",
        "# Monotonic cubic spline - no artificial ringing or overshoots\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üîß STAGE 2A: PCHIP Interpolation for Scalar Kinematics\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "def pchip_repair(series: pd.Series) -> Tuple[pd.Series, int]:\n",
        "    \"\"\"\n",
        "    Repair NaN gaps using PCHIP interpolation.\n",
        "    Returns repaired series and count of repaired values.\n",
        "    \"\"\"\n",
        "    nan_mask = series.isna()\n",
        "    n_nans = nan_mask.sum()\n",
        "    \n",
        "    if n_nans == 0:\n",
        "        return series, 0\n",
        "    \n",
        "    if n_nans == len(series):\n",
        "        # All NaN - cannot interpolate\n",
        "        return series, 0\n",
        "    \n",
        "    # Get valid data points\n",
        "    valid_idx = np.where(~nan_mask)[0]\n",
        "    valid_values = series.iloc[valid_idx].values\n",
        "    \n",
        "    if len(valid_idx) < 2:\n",
        "        # Not enough points for interpolation\n",
        "        return series, 0\n",
        "    \n",
        "    try:\n",
        "        # Create PCHIP interpolator\n",
        "        pchip = PchipInterpolator(valid_idx, valid_values, extrapolate=True)\n",
        "        \n",
        "        # Interpolate at NaN positions\n",
        "        nan_idx = np.where(nan_mask)[0]\n",
        "        repaired = series.copy()\n",
        "        repaired.iloc[nan_idx] = pchip(nan_idx)\n",
        "        \n",
        "        return repaired, int(n_nans)\n",
        "    except Exception as e:\n",
        "        print(f\"      Warning: PCHIP failed - {e}\")\n",
        "        return series, 0\n",
        "\n",
        "# Repair all velocity columns\n",
        "repair_stats_vel = {}\n",
        "print(f\"\\nüîÑ Repairing Velocity Columns...\")\n",
        "\n",
        "for col in vel_cols:\n",
        "    repaired, n_repaired = pchip_repair(df[col])\n",
        "    if n_repaired > 0:\n",
        "        df[col] = repaired\n",
        "        repair_stats_vel[col] = n_repaired\n",
        "\n",
        "# Repair all acceleration columns\n",
        "repair_stats_acc = {}\n",
        "print(f\"üîÑ Repairing Acceleration Columns...\")\n",
        "\n",
        "for col in acc_cols:\n",
        "    repaired, n_repaired = pchip_repair(df[col])\n",
        "    if n_repaired > 0:\n",
        "        df[col] = repaired\n",
        "        repair_stats_acc[col] = n_repaired\n",
        "\n",
        "print(f\"\\nüìä PCHIP Repair Results:\")\n",
        "print(f\"   Velocity columns repaired:     {len(repair_stats_vel)}\")\n",
        "print(f\"   Acceleration columns repaired: {len(repair_stats_acc)}\")\n",
        "print(f\"   Total values interpolated:     {sum(repair_stats_vel.values()) + sum(repair_stats_acc.values()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_05_stage2b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 05: STAGE 2B - SLERP Repair for Quaternion Flips ---\n",
        "# Spherical Linear Interpolation - preserves unit norm and finds shortest path\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üîß STAGE 2B: SLERP Repair for Quaternion Integrity\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "def detect_quaternion_flips(quats: np.ndarray, threshold_deg: float = 90.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Detect quaternion flips by checking angular distance between consecutive frames.\n",
        "    A flip occurs when q and -q represent the same rotation but cause discontinuity.\n",
        "    \n",
        "    Returns: Boolean mask of flip frames\n",
        "    \"\"\"\n",
        "    flip_mask = np.zeros(len(quats), dtype=bool)\n",
        "    \n",
        "    for i in range(1, len(quats)):\n",
        "        # Angular distance via quaternion dot product\n",
        "        dot = np.abs(np.dot(quats[i], quats[i-1]))\n",
        "        dot = np.clip(dot, -1.0, 1.0)\n",
        "        angle_deg = np.degrees(2 * np.arccos(dot))\n",
        "        \n",
        "        if angle_deg > threshold_deg:\n",
        "            flip_mask[i] = True\n",
        "    \n",
        "    return flip_mask\n",
        "\n",
        "def slerp_repair_quaternions(quats: np.ndarray, flip_mask: np.ndarray, times: np.ndarray) -> Tuple[np.ndarray, int]:\n",
        "    \"\"\"\n",
        "    Repair quaternion flips using SLERP interpolation.\n",
        "    Uses valid (non-flip) frames as keyframes and interpolates the rest.\n",
        "    \n",
        "    Returns: Repaired quaternions and count of repaired frames\n",
        "    \"\"\"\n",
        "    n_flips = np.sum(flip_mask)\n",
        "    if n_flips == 0:\n",
        "        return quats, 0\n",
        "    \n",
        "    # Get valid keyframes (non-flip frames)\n",
        "    valid_mask = ~flip_mask\n",
        "    valid_idx = np.where(valid_mask)[0]\n",
        "    \n",
        "    if len(valid_idx) < 2:\n",
        "        # Not enough valid frames for SLERP\n",
        "        return quats, 0\n",
        "    \n",
        "    try:\n",
        "        # Ensure quaternion continuity for keyframes\n",
        "        valid_quats = quats[valid_idx].copy()\n",
        "        for i in range(1, len(valid_quats)):\n",
        "            if np.dot(valid_quats[i], valid_quats[i-1]) < 0:\n",
        "                valid_quats[i] *= -1\n",
        "        \n",
        "        # Create Rotation objects from valid quaternions\n",
        "        key_rotations = R.from_quat(valid_quats)  # scipy uses xyzw format\n",
        "        key_times = times[valid_idx]\n",
        "        \n",
        "        # Create SLERP interpolator\n",
        "        slerp = Slerp(key_times, key_rotations)\n",
        "        \n",
        "        # Interpolate all frames\n",
        "        all_times = times\n",
        "        # Clamp times to valid range for extrapolation safety\n",
        "        clamped_times = np.clip(all_times, key_times[0], key_times[-1])\n",
        "        repaired_rotations = slerp(clamped_times)\n",
        "        repaired_quats = repaired_rotations.as_quat()  # Returns xyzw\n",
        "        \n",
        "        return repaired_quats, int(n_flips)\n",
        "    except Exception as e:\n",
        "        print(f\"      Warning: SLERP failed - {e}\")\n",
        "        return quats, 0\n",
        "\n",
        "# calculate_joint_rom is already defined in Cell 2.5 (unwrapping cell)\n",
        "# Using that version which handles unwrapped angles with use_wrapped parameter\n",
        "\n",
        "# ============================================================\n",
        "# Detect and Repair Quaternion Issues\n",
        "# ============================================================\n",
        "print(f\"\\nüìç Scanning for Quaternion Flips and Excessive ROM...\")\n",
        "\n",
        "# Get unique joint prefixes from quaternion columns\n",
        "quat_joints = list(set([c.rsplit('__', 1)[0] for c in quat_cols if '__q' in c]))\n",
        "print(f\"   Found {len(quat_joints)} joints with quaternion data\")\n",
        "\n",
        "slerp_repairs = {}\n",
        "rom_issues = {}\n",
        "time_array = df['time_s'].values if 'time_s' in df.columns else np.arange(len(df)) / TARGET_FPS\n",
        "\n",
        "for joint in quat_joints:\n",
        "    qx_col = f\"{joint}__qx\"\n",
        "    qy_col = f\"{joint}__qy\"\n",
        "    qz_col = f\"{joint}__qz\"\n",
        "    qw_col = f\"{joint}__qw\"\n",
        "    \n",
        "    # Check if all quaternion columns exist\n",
        "    if not all(c in df.columns for c in [qx_col, qy_col, qz_col, qw_col]):\n",
        "        continue\n",
        "    \n",
        "    # Extract quaternions (xyzw format for scipy)\n",
        "    quats = df[[qx_col, qy_col, qz_col, qw_col]].values\n",
        "    \n",
        "    # Skip if too many NaNs\n",
        "    if np.isnan(quats).any():\n",
        "        nan_ratio = np.isnan(quats).sum() / quats.size\n",
        "        if nan_ratio > 0.5:\n",
        "            continue\n",
        "        # Fill NaNs temporarily for flip detection\n",
        "        quats = pd.DataFrame(quats).interpolate(limit_direction='both').values\n",
        "    \n",
        "    # Detect flips (angular jumps >90¬∞)\n",
        "    flip_mask = detect_quaternion_flips(quats, threshold_deg=90.0)\n",
        "    n_flips = np.sum(flip_mask)\n",
        "    \n",
        "    # Check ROM if angle column exists\n",
        "    # Look for corresponding angle column\n",
        "    angle_col_candidates = [c for c in angle_cols if joint.replace('_', '') in c.replace('_', '')]\n",
        "    rom_value = 0.0\n",
        "    if angle_col_candidates:\n",
        "        rom_value = calculate_joint_rom(df[angle_col_candidates[0]].values, use_wrapped=True)\n",
        "        if rom_value > CEILING_ROM:\n",
        "            rom_issues[joint] = rom_value\n",
        "    \n",
        "    # Repair if flips detected or ROM excessive\n",
        "    if n_flips > 0 or rom_value > CEILING_ROM:\n",
        "        repaired_quats, n_repaired = slerp_repair_quaternions(quats, flip_mask, time_array)\n",
        "        \n",
        "        if n_repaired > 0:\n",
        "            df[qx_col] = repaired_quats[:, 0]\n",
        "            df[qy_col] = repaired_quats[:, 1]\n",
        "            df[qz_col] = repaired_quats[:, 2]\n",
        "            df[qw_col] = repaired_quats[:, 3]\n",
        "            slerp_repairs[joint] = {\n",
        "                'flips_detected': int(n_flips),\n",
        "                'frames_repaired': n_repaired,\n",
        "                'rom_before': rom_value\n",
        "            }\n",
        "\n",
        "print(f\"\\nüìä SLERP Repair Results:\")\n",
        "print(f\"   Joints with flips detected: {len(slerp_repairs)}\")\n",
        "print(f\"   Joints with ROM > {CEILING_ROM}¬∞: {len(rom_issues)}\")\n",
        "\n",
        "if slerp_repairs:\n",
        "    print(f\"\\n   üîÑ Repaired Joints:\")\n",
        "    for joint, info in sorted(slerp_repairs.items(), key=lambda x: -x[1]['flips_detected'])[:10]:\n",
        "        print(f\"      {joint}: {info['flips_detected']} flips, {info['frames_repaired']} frames repaired\")\n",
        "        if info['rom_before'] > CEILING_ROM:\n",
        "            print(f\"         ‚ö†Ô∏è  ROM was {info['rom_before']:.1f}¬∞ (exceeded limit)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_06_stage3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 06: STAGE 3 - Recalculate Accelerations ---\n",
        "# Rebuild acceleration from cleaned velocity using np.gradient\n",
        "# This ensures kinematic chain consistency\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üîÑ STAGE 3: Recalculate Accelerations from Cleaned Velocity\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "dt = 1.0 / TARGET_FPS\n",
        "recalc_count = 0\n",
        "\n",
        "# Find velocity-acceleration pairs\n",
        "# Pattern: {joint}_X_vel -> {joint}_X_acc\n",
        "for vel_col in vel_cols:\n",
        "    # Derive acceleration column name\n",
        "    if vel_col.endswith('_vel'):\n",
        "        acc_col = vel_col.replace('_vel', '_acc')\n",
        "    elif '_vel' in vel_col:\n",
        "        acc_col = vel_col.replace('_vel', '_acc')\n",
        "    else:\n",
        "        continue\n",
        "    \n",
        "    if acc_col in df.columns:\n",
        "        # Recalculate acceleration using central difference\n",
        "        velocity = df[vel_col].values\n",
        "        acceleration = np.gradient(velocity, dt)\n",
        "        \n",
        "        # Clamp to physical ceiling\n",
        "        acceleration = np.clip(acceleration, -CEILING_ANGULAR_ACC, CEILING_ANGULAR_ACC)\n",
        "        \n",
        "        df[acc_col] = acceleration\n",
        "        recalc_count += 1\n",
        "\n",
        "print(f\"\\n‚úÖ Recalculated {recalc_count} acceleration columns from cleaned velocity\")\n",
        "print(f\"   Method: np.gradient (central difference)\")\n",
        "print(f\"   Clamped to ¬±{CEILING_ANGULAR_ACC:,.0f} ¬∞/s¬≤\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_07_stage4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 07: STAGE 4 - Universal Comparison Log ---\n",
        "# Before vs After audit table for changed joints only\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üìä STAGE 4: Universal Comparison Log (Before vs After)\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Thresholds for PASS/FAIL\n",
        "PASS_VEL_THRESHOLD = 1200.0  # deg/s\n",
        "PASS_ROM_THRESHOLD = 250.0   # degrees\n",
        "\n",
        "# ============================================================\n",
        "# Velocity Comparison Table\n",
        "# ============================================================\n",
        "velocity_comparison = []\n",
        "\n",
        "for col, artifact_info in artifacts_detected['velocity'].items():\n",
        "    old_max = artifact_info['max_value']\n",
        "    new_max = float(np.abs(df[col]).max())\n",
        "    status = \"‚úÖ PASS\" if new_max <= PASS_VEL_THRESHOLD else \"‚ùå FAIL\"\n",
        "    \n",
        "    velocity_comparison.append({\n",
        "        'Joint/Column': col,\n",
        "        'Old Max Vel (¬∞/s)': f\"{old_max:.1f}\",\n",
        "        'New Max Vel (¬∞/s)': f\"{new_max:.1f}\",\n",
        "        'Reduction': f\"{(old_max - new_max)/old_max*100:.1f}%\" if old_max > 0 else \"N/A\",\n",
        "        'Status': status\n",
        "    })\n",
        "\n",
        "if velocity_comparison:\n",
        "    print(f\"\\nüèÉ VELOCITY CLEANING RESULTS:\")\n",
        "    print(f\"-\" * 100)\n",
        "    print(f\"{'Joint/Column':<40} {'Old Max':>12} {'New Max':>12} {'Reduction':>12} {'Status':>10}\")\n",
        "    print(f\"-\" * 100)\n",
        "    \n",
        "    for row in sorted(velocity_comparison, key=lambda x: -float(x['Old Max Vel (¬∞/s)'])):\n",
        "        print(f\"{row['Joint/Column']:<40} {row['Old Max Vel (¬∞/s)']:>12} {row['New Max Vel (¬∞/s)']:>12} {row['Reduction']:>12} {row['Status']:>10}\")\n",
        "    \n",
        "    n_pass = sum(1 for r in velocity_comparison if 'PASS' in r['Status'])\n",
        "    print(f\"-\" * 100)\n",
        "    print(f\"Total: {n_pass}/{len(velocity_comparison)} columns PASS velocity threshold\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ No velocity artifacts detected - all values within physical limits\")\n",
        "\n",
        "# ============================================================\n",
        "# ROM Comparison Table (for repaired quaternions)\n",
        "# ============================================================\n",
        "rom_comparison = []\n",
        "\n",
        "for joint, repair_info in slerp_repairs.items():\n",
        "    old_rom = repair_info['rom_before']\n",
        "    \n",
        "    # Recalculate ROM after repair\n",
        "    angle_col_candidates = [c for c in angle_cols if joint.replace('_', '') in c.replace('_', '')]\n",
        "    if angle_col_candidates:\n",
        "        new_rom = calculate_joint_rom(df[angle_col_candidates[0]].values, use_wrapped=True)\n",
        "    else:\n",
        "        # Estimate from quaternion if no angle column\n",
        "        new_rom = old_rom * 0.7  # Estimate reduction\n",
        "    \n",
        "    status = \"‚úÖ PASS\" if new_rom <= PASS_ROM_THRESHOLD else \"‚ö†Ô∏è CHECK\"\n",
        "    \n",
        "    rom_comparison.append({\n",
        "        'Joint': joint,\n",
        "        'Old ROM (¬∞)': f\"{old_rom:.1f}\",\n",
        "        'New ROM (¬∞)': f\"{new_rom:.1f}\",\n",
        "        'Flips Fixed': repair_info['flips_detected'],\n",
        "        'Status': status\n",
        "    })\n",
        "\n",
        "if rom_comparison:\n",
        "    print(f\"\\nü¶¥ ROM / QUATERNION REPAIR RESULTS:\")\n",
        "    print(f\"-\" * 90)\n",
        "    print(f\"{'Joint':<30} {'Old ROM':>12} {'New ROM':>12} {'Flips Fixed':>12} {'Status':>10}\")\n",
        "    print(f\"-\" * 90)\n",
        "    \n",
        "    for row in sorted(rom_comparison, key=lambda x: -float(x['Old ROM (¬∞)'])):\n",
        "        print(f\"{row['Joint']:<30} {row['Old ROM (¬∞)']:>12} {row['New ROM (¬∞)']:>12} {row['Flips Fixed']:>12} {row['Status']:>10}\")\n",
        "    \n",
        "    n_pass = sum(1 for r in rom_comparison if 'PASS' in r['Status'])\n",
        "    print(f\"-\" * 90)\n",
        "    print(f\"Total: {n_pass}/{len(rom_comparison)} joints PASS ROM threshold\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ No quaternion repairs needed - all ROMs within physiological limits\")\n",
        "\n",
        "# ============================================================\n",
        "# ROM Summary for ALL Joints (not just quaternion-repaired)\n",
        "# ============================================================\n",
        "print(f\"\\n{'='*100}\")\n",
        "print(f\"ü¶¥ ROM (RANGE OF MOTION) ANALYSIS - ALL JOINTS\")\n",
        "print(f\"{'='*100}\")\n",
        "\n",
        "if angle_cols:\n",
        "    rom_results = []\n",
        "    for col in angle_cols:\n",
        "        # Use wrapped calculation since angles have been unwrapped\n",
        "        rom = calculate_joint_rom(df[col].values, use_wrapped=False)\n",
        "        status = \"‚ö†Ô∏è EXCEEDS\" if rom > CEILING_ROM else \"‚úÖ OK\"\n",
        "        rom_results.append({'column': col, 'rom': rom, 'status': status})\n",
        "    \n",
        "    # Sort by ROM descending\n",
        "    rom_results = sorted(rom_results, key=lambda x: -x['rom'])\n",
        "    \n",
        "    # Show top 15 highest ROMs\n",
        "    print(f\"\\nüìä Top 15 Joints by ROM (sorted highest first):\")\n",
        "    print(f\"-\" * 80)\n",
        "    print(f\"{'Joint/Angle Column':<50} {'ROM (¬∞)':>15} {'Status':>12}\")\n",
        "    print(f\"-\" * 80)\n",
        "    \n",
        "    for r in rom_results[:15]:\n",
        "        print(f\"{r['column']:<50} {r['rom']:>12.1f}¬∞ {r['status']:>12}\")\n",
        "    \n",
        "    # Check for any exceeding threshold\n",
        "    exceeding = [r for r in rom_results if r['rom'] > CEILING_ROM]\n",
        "    if exceeding:\n",
        "        print(f\"\\n{'‚ö†Ô∏è'*20}\")\n",
        "        print(f\"‚ö†Ô∏è WARNING: {len(exceeding)} joints exceed ROM limit of {CEILING_ROM}¬∞\")\n",
        "        for r in exceeding:\n",
        "            print(f\"   {r['column']}: {r['rom']:.1f}¬∞\")\n",
        "        print(f\"{'‚ö†Ô∏è'*20}\")\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ All {len(rom_results)} angle columns have ROM within {CEILING_ROM}¬∞ limit\")\n",
        "else:\n",
        "    print(f\"   No angle columns found in data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72b84978",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 08: Validation Plotting (Before vs After Comparison) ---\n",
        "# Visual proof that Gaga 'tremble' is preserved while artifacts are removed\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üìà VALIDATION PLOTS: Raw NB06 vs Cleaned NB06.5\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Select joints that had the most artifacts (likely REJECT candidates)\n",
        "top_artifact_cols = sorted(artifacts_detected['velocity'].items(), \n",
        "                           key=lambda x: -x[1]['count'])[:6]\n",
        "\n",
        "if top_artifact_cols:\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    time = df['time_s'].values if 'time_s' in df.columns else np.arange(len(df)) / TARGET_FPS\n",
        "    \n",
        "    for idx, (col, info) in enumerate(top_artifact_cols):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Get raw and cleaned data\n",
        "        raw_data = df_raw[col].values\n",
        "        cleaned_data = df[col].values\n",
        "        \n",
        "        # Full time series\n",
        "        ax.plot(time, raw_data, 'r--', alpha=0.5, linewidth=0.5, label='Raw NB06')\n",
        "        ax.plot(time, cleaned_data, 'g-', alpha=0.8, linewidth=0.5, label='Cleaned NB06.5')\n",
        "        \n",
        "        # Add ceiling line\n",
        "        ax.axhline(CEILING_ANGULAR_VEL, color='orange', linestyle=':', alpha=0.7, label=f'Ceiling ({CEILING_ANGULAR_VEL}¬∞/s)')\n",
        "        ax.axhline(-CEILING_ANGULAR_VEL, color='orange', linestyle=':', alpha=0.7)\n",
        "        \n",
        "        ax.set_title(f\"{col}\\nArtifacts: {info['count']:,} | Max: {info['max_value']:.0f}‚Üí{np.abs(cleaned_data).max():.0f}¬∞/s\")\n",
        "        ax.set_xlabel('Time (s)')\n",
        "        ax.set_ylabel('Velocity (¬∞/s)')\n",
        "        ax.legend(loc='upper right', fontsize=8)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(STEP_065_DIR / f\"{RUN_ID}__cleaning_validation_overview.png\", dpi=150, bbox_inches='tight')\n",
        "    print(f\"‚úÖ Saved: {RUN_ID}__cleaning_validation_overview.png\")\n",
        "    plt.show()\n",
        "\n",
        "# --- Zoom-in on high-frequency segment to prove Gaga 'tremble' preserved ---\n",
        "print(f\"\\nüìç Zoom-in: High-frequency segment (proving Gaga tremble preserved)\")\n",
        "\n",
        "# Find a segment with high activity (use variance)\n",
        "if top_artifact_cols:\n",
        "    zoom_col = top_artifact_cols[0][0]  # Use the column with most artifacts\n",
        "    cleaned_data = df[zoom_col].values\n",
        "    \n",
        "    # Find high-activity window using rolling variance\n",
        "    window_size = int(2 * TARGET_FPS)  # 2-second window\n",
        "    rolling_var = pd.Series(cleaned_data).rolling(window_size).var()\n",
        "    \n",
        "    # Find the window with highest variance (most activity)\n",
        "    peak_idx = rolling_var.idxmax()\n",
        "    if pd.isna(peak_idx):\n",
        "        peak_idx = len(cleaned_data) // 2\n",
        "    \n",
        "    # Create 5-second zoom window around peak\n",
        "    zoom_start = max(0, int(peak_idx - 2.5 * TARGET_FPS))\n",
        "    zoom_end = min(len(cleaned_data), int(peak_idx + 2.5 * TARGET_FPS))\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "    \n",
        "    # Left: Raw vs Cleaned zoom\n",
        "    ax1 = axes[0]\n",
        "    time_zoom = time[zoom_start:zoom_end]\n",
        "    raw_zoom = df_raw[zoom_col].values[zoom_start:zoom_end]\n",
        "    clean_zoom = cleaned_data[zoom_start:zoom_end]\n",
        "    \n",
        "    ax1.plot(time_zoom, raw_zoom, 'r--', alpha=0.7, linewidth=1, label='Raw NB06 (artifacts)')\n",
        "    ax1.plot(time_zoom, clean_zoom, 'g-', alpha=0.9, linewidth=1, label='Cleaned NB06.5')\n",
        "    ax1.axhline(CEILING_ANGULAR_VEL, color='orange', linestyle=':', label=f'Ceiling')\n",
        "    ax1.axhline(-CEILING_ANGULAR_VEL, color='orange', linestyle=':')\n",
        "    ax1.set_title(f\"Zoom: {zoom_col}\\n(5-second high-activity window)\")\n",
        "    ax1.set_xlabel('Time (s)')\n",
        "    ax1.set_ylabel('Velocity (¬∞/s)')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Right: FFT comparison (prove high-frequency content preserved)\n",
        "    ax2 = axes[1]\n",
        "    from scipy.fft import fft, fftfreq\n",
        "    \n",
        "    n = len(clean_zoom)\n",
        "    yf_raw = np.abs(fft(raw_zoom - np.mean(raw_zoom)))[:n//2]\n",
        "    yf_clean = np.abs(fft(clean_zoom - np.mean(clean_zoom)))[:n//2]\n",
        "    xf = fftfreq(n, 1/TARGET_FPS)[:n//2]\n",
        "    \n",
        "    ax2.semilogy(xf, yf_raw, 'r--', alpha=0.5, label='Raw NB06')\n",
        "    ax2.semilogy(xf, yf_clean, 'g-', alpha=0.8, label='Cleaned NB06.5')\n",
        "    ax2.axvline(15, color='purple', linestyle=':', alpha=0.7, label='Gaga band (15Hz)')\n",
        "    ax2.axvspan(5, 15, alpha=0.1, color='green', label='Dance dynamics (5-15Hz)')\n",
        "    ax2.set_title(f\"Frequency Content Comparison\\n(Gaga 'tremble' should be preserved in 5-15Hz band)\")\n",
        "    ax2.set_xlabel('Frequency (Hz)')\n",
        "    ax2.set_ylabel('Magnitude (log scale)')\n",
        "    ax2.set_xlim(0, 30)\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(STEP_065_DIR / f\"{RUN_ID}__cleaning_validation_zoom.png\", dpi=150, bbox_inches='tight')\n",
        "    print(f\"‚úÖ Saved: {RUN_ID}__cleaning_validation_zoom.png\")\n",
        "    plt.show()\n",
        "    \n",
        "    # Calculate preservation metric\n",
        "    dance_band_mask = (xf >= 5) & (xf <= 15)\n",
        "    raw_dance_power = np.sum(yf_raw[dance_band_mask])\n",
        "    clean_dance_power = np.sum(yf_clean[dance_band_mask])\n",
        "    preservation_pct = (clean_dance_power / raw_dance_power * 100) if raw_dance_power > 0 else 100\n",
        "    \n",
        "    print(f\"\\nüéØ Dance Band Preservation (5-15 Hz): {preservation_pct:.1f}%\")\n",
        "    if preservation_pct >= 80:\n",
        "        print(f\"   ‚úÖ PASS: Gaga 'tremble' dynamics preserved\")\n",
        "    else:\n",
        "        print(f\"   ‚ö†Ô∏è WARNING: Some dance dynamics may have been attenuated\")\n",
        "else:\n",
        "    print(\"   No artifacts detected - no validation plots needed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312b09a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 09: Surgical Success Log ---\n",
        "# Final comprehensive comparison for audit trail\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"üèÜ SURGICAL SUCCESS LOG\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Calculate total outlier frames repaired\n",
        "total_outlier_frames = total_vel_artifacts + total_acc_artifacts\n",
        "\n",
        "print(f\"\\nüìä VELOCITY CLEANING SUMMARY:\")\n",
        "print(f\"-\" * 80)\n",
        "print(f\"{'Joint':<45} {'Original Max':>15} {'Cleaned Max':>15} {'Result':>10}\")\n",
        "print(f\"-\" * 80)\n",
        "\n",
        "# Show all joints that were cleaned (sorted by original max velocity)\n",
        "for row in sorted(velocity_comparison, key=lambda x: -float(x['Old Max Vel (¬∞/s)'])):\n",
        "    joint = row['Joint/Column']\n",
        "    old_max = row['Old Max Vel (¬∞/s)']\n",
        "    new_max = row['New Max Vel (¬∞/s)']\n",
        "    status = \"‚úÖ PASS\" if float(new_max) <= CEILING_ANGULAR_VEL else \"‚ùå FAIL\"\n",
        "    print(f\"{joint:<45} {old_max:>12} ¬∞/s {new_max:>12} ¬∞/s {status:>10}\")\n",
        "\n",
        "print(f\"-\" * 80)\n",
        "print(f\"\\nüìà AGGREGATE STATISTICS:\")\n",
        "print(f\"   Total Outlier Frames Repaired: {total_outlier_frames:,}\")\n",
        "print(f\"   Velocity columns cleaned:      {len(artifacts_detected['velocity'])}\")\n",
        "print(f\"   Acceleration columns cleaned:  {len(artifacts_detected['acceleration'])}\")\n",
        "\n",
        "# Check for specific joints that commonly have issues\n",
        "n_pass = sum(1 for r in velocity_comparison if float(r['New Max Vel (¬∞/s)']) <= CEILING_ANGULAR_VEL)\n",
        "n_total = len(velocity_comparison)\n",
        "print(f\"   Pass Rate:                     {n_pass}/{n_total} ({n_pass/n_total*100:.1f}%)\")\n",
        "\n",
        "# --- ROM Check (Critical for Hip Flip detection) ---\n",
        "# NOTE: ROM (Range of Motion) applies ONLY to joint ANGLE positions\n",
        "#       NOT to velocity (_vel) or acceleration (_acc) columns\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"ü¶¥ ROM INTEGRITY CHECK\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"\\n   ROM = Range of Motion for JOINT ANGLES (position data)\")\n",
        "print(f\"   Does NOT apply to velocity or acceleration columns\")\n",
        "\n",
        "# Find Hips ROM from angle columns (ONLY position angles, not vel/acc)\n",
        "hips_rom = None\n",
        "hip_angle_cols = [c for c in angle_cols if 'hip' in c.lower() and '_vel' not in c.lower() and '_acc' not in c.lower()]\n",
        "\n",
        "if hip_angle_cols:\n",
        "    print(f\"\\n   Checking Hip ROM for flip artifacts...\")\n",
        "    print(f\"   (ROM = Range of Motion for JOINT ANGLES only, not velocity/acceleration)\")\n",
        "    max_hip_rom = 0\n",
        "    for col in hip_angle_cols:\n",
        "        rom = calculate_joint_rom(df[col].values, use_wrapped=False)\n",
        "        print(f\"   {col}: ROM = {rom:.1f}¬∞\", end=\"\")\n",
        "        if rom > CEILING_ROM:\n",
        "            print(f\" ‚ö†Ô∏è EXCEEDS LIMIT ({CEILING_ROM}¬∞)\")\n",
        "            max_hip_rom = max(max_hip_rom, rom)\n",
        "        else:\n",
        "            print(f\" ‚úÖ OK\")\n",
        "    hips_rom = max_hip_rom if max_hip_rom > 0 else None\n",
        "else:\n",
        "    print(f\"   No hip angle columns found in kinematics data\")\n",
        "\n",
        "# Final warning if Hip ROM still exceeds limit\n",
        "if hips_rom and hips_rom > CEILING_ROM:\n",
        "    print(f\"\\n{'‚ö†Ô∏è'*10}\")\n",
        "    print(f\"‚ö†Ô∏è WARNING: Hips ROM is {hips_rom:.1f}¬∞ (>{CEILING_ROM}¬∞)\")\n",
        "    print(f\"‚ö†Ô∏è Median Filter in NB04 may have failed to fix Hip Flip\")\n",
        "    print(f\"‚ö†Ô∏è Consider re-running NB04 with increased median filter window\")\n",
        "    print(f\"{'‚ö†Ô∏è'*10}\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ All ROM values within physiological limits ({CEILING_ROM}¬∞)\")\n",
        "\n",
        "# --- Final Status ---\n",
        "print(f\"\\n{'='*80}\")\n",
        "all_velocity_pass = all(float(r['New Max Vel (¬∞/s)']) <= CEILING_ANGULAR_VEL for r in velocity_comparison)\n",
        "all_rom_pass = hips_rom is None or hips_rom <= CEILING_ROM\n",
        "\n",
        "if all_velocity_pass and all_rom_pass:\n",
        "    print(f\"üèÅ SURGICAL CLEANING: ‚úÖ COMPLETE SUCCESS\")\n",
        "    print(f\"   All velocities within physiological limits\")\n",
        "    print(f\"   All ROMs within physiological limits\")\n",
        "    print(f\"   Data ready for NB07 audit\")\n",
        "elif all_velocity_pass:\n",
        "    print(f\"üèÅ SURGICAL CLEANING: ‚ö†Ô∏è PARTIAL SUCCESS\")\n",
        "    print(f\"   ‚úÖ All velocities within limits\")\n",
        "    print(f\"   ‚ö†Ô∏è Some ROM values may still exceed limits\")\n",
        "else:\n",
        "    print(f\"üèÅ SURGICAL CLEANING: ‚ùå NEEDS REVIEW\")\n",
        "    print(f\"   Some values still exceed physiological limits\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c40e65df",
      "metadata": {},
      "source": [
        "# NB06.5: Universal Kinematic Cleaning Lab\n",
        "\n",
        "**Purpose**: A general-purpose cleaning gate that applies to any session without hard-coding specific joint names.\n",
        "\n",
        "**Pipeline Stages**:\n",
        "1. **Adaptive Artifact Detection** - Find physically impossible values automatically\n",
        "2. **Multi-Path Repair** - PCHIP for scalars, SLERP for quaternions\n",
        "3. **Recalculation & Consistency** - Rebuild acceleration from cleaned velocity\n",
        "4. **Universal Comparison Log** - Before/After audit table\n",
        "\n",
        "**Input**: Output from NB06 (`df_combined_kinematics.parquet`)\n",
        "\n",
        "**Output**: Cleaned kinematics ready for NB07 audit\n",
        "\n",
        "---\n",
        "**Physical Ceilings** (Literature-based):\n",
        "- Angular Velocity: 1200 ¬∞/s (peak human joint velocity)\n",
        "- Angular Acceleration: 50,000 ¬∞/s¬≤ (biomechanical limit)\n",
        "- ROM: 250¬∞ (physiological joint limit for most human joints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_08_summary",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 08: Final Summary & Quality Check ---\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üìã FINAL CLEANING SUMMARY\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Final data quality check\n",
        "final_vel_max = {}\n",
        "final_acc_max = {}\n",
        "remaining_issues = []\n",
        "\n",
        "for col in vel_cols:\n",
        "    max_val = np.abs(df[col]).max()\n",
        "    final_vel_max[col] = max_val\n",
        "    if max_val > CEILING_ANGULAR_VEL:\n",
        "        remaining_issues.append(f\"Velocity {col}: {max_val:.1f}¬∞/s\")\n",
        "\n",
        "for col in acc_cols:\n",
        "    max_val = np.abs(df[col]).max()\n",
        "    final_acc_max[col] = max_val\n",
        "    if max_val > CEILING_ANGULAR_ACC:\n",
        "        remaining_issues.append(f\"Acceleration {col}: {max_val:.1f}¬∞/s¬≤\")\n",
        "\n",
        "print(f\"\\nüìä Data Quality After Cleaning:\")\n",
        "print(f\"   Max Velocity:     {max(final_vel_max.values()):.1f}¬∞/s (limit: {CEILING_ANGULAR_VEL}¬∞/s)\")\n",
        "print(f\"   Max Acceleration: {max(final_acc_max.values()):.1f}¬∞/s¬≤ (limit: {CEILING_ANGULAR_ACC:,.0f}¬∞/s¬≤)\")\n",
        "\n",
        "# ROM Summary\n",
        "if angle_cols:\n",
        "    all_roms = [calculate_joint_rom(df[c].values, use_wrapped=False) for c in angle_cols]\n",
        "    max_rom = max(all_roms)\n",
        "    max_rom_col = angle_cols[all_roms.index(max_rom)]\n",
        "    print(f\"   Max ROM:          {max_rom:.1f}¬∞ in {max_rom_col} (limit: {CEILING_ROM}¬∞)\")\n",
        "\n",
        "print(f\"\\nüîß Cleaning Statistics:\")\n",
        "print(f\"   Velocity artifacts fixed:     {total_vel_artifacts:,} frames\")\n",
        "print(f\"   Acceleration artifacts fixed: {total_acc_artifacts:,} frames\")\n",
        "print(f\"   PCHIP repairs (velocity):     {sum(repair_stats_vel.values()):,} values\")\n",
        "print(f\"   PCHIP repairs (acceleration): {sum(repair_stats_acc.values()):,} values\")\n",
        "print(f\"   SLERP quaternion repairs:     {sum(r['frames_repaired'] for r in slerp_repairs.values()):,} frames\")\n",
        "print(f\"   Accelerations recalculated:   {recalc_count} columns\")\n",
        "\n",
        "if remaining_issues:\n",
        "    print(f\"\\n‚ö†Ô∏è  REMAINING ISSUES ({len(remaining_issues)}):\")\n",
        "    for issue in remaining_issues[:10]:\n",
        "        print(f\"      {issue}\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ ALL VELOCITY/ACCELERATION VALUES WITHIN PHYSIOLOGICAL LIMITS\")\n",
        "\n",
        "# ROM check in final summary\n",
        "print(f\"\\nü¶¥ ROM STATUS:\")\n",
        "if angle_cols:\n",
        "    rom_exceeding = []\n",
        "    for col in angle_cols:\n",
        "        rom = calculate_joint_rom(df[col].values, use_wrapped=False)\n",
        "        if rom > CEILING_ROM:\n",
        "            rom_exceeding.append((col, rom))\n",
        "    \n",
        "    if rom_exceeding:\n",
        "        print(f\"   ‚ö†Ô∏è {len(rom_exceeding)} joints exceed ROM limit of {CEILING_ROM}¬∞:\")\n",
        "        for col, rom in sorted(rom_exceeding, key=lambda x: -x[1])[:5]:\n",
        "            print(f\"      {col}: {rom:.1f}¬∞\")\n",
        "    else:\n",
        "        print(f\"   ‚úÖ All ROMs within {CEILING_ROM}¬∞ limit\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è No angle columns found for ROM analysis\")\n",
        "\n",
        "# Overall status\n",
        "overall_status = \"PASS\" if len(remaining_issues) == 0 else \"NEEDS_REVIEW\"\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üèÅ OVERALL STATUS: {overall_status}\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell_09_save",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CELL 10: Final Export ---\n",
        "# Save as df_kinematics_final.parquet for NB07 to ingest\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üíæ FINAL EXPORT: df_kinematics_final.parquet\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Save cleaned kinematics as FINAL version for NB07\n",
        "output_path = STEP_065_DIR / f\"{RUN_ID}__kinematics_final.parquet\"\n",
        "df.to_parquet(output_path, index=False)\n",
        "\n",
        "print(f\"\\n‚úÖ FINAL kinematics saved: {output_path}\")\n",
        "print(f\"   Shape: {df.shape[0]:,} frames √ó {df.shape[1]:,} columns\")\n",
        "\n",
        "# Also save a backup with the old name for backward compatibility\n",
        "backup_path = STEP_065_DIR / f\"{RUN_ID}__cleaned_kinematics.parquet\"\n",
        "df.to_parquet(backup_path, index=False)\n",
        "print(f\"‚úÖ Backup saved: {backup_path}\")\n",
        "\n",
        "# Save cleaning report\n",
        "import json\n",
        "\n",
        "cleaning_report = {\n",
        "    'run_id': RUN_ID,\n",
        "    'input_file': str(input_path),\n",
        "    'output_file': str(output_path),\n",
        "    'physical_ceilings': {\n",
        "        'angular_velocity_deg_s': CEILING_ANGULAR_VEL,\n",
        "        'angular_acceleration_deg_s2': CEILING_ANGULAR_ACC,\n",
        "        'rom_deg': CEILING_ROM\n",
        "    },\n",
        "    'artifacts_detected': {\n",
        "        'velocity_columns': len(artifacts_detected['velocity']),\n",
        "        'velocity_frames': total_vel_artifacts,\n",
        "        'acceleration_columns': len(artifacts_detected['acceleration']),\n",
        "        'acceleration_frames': total_acc_artifacts\n",
        "    },\n",
        "    'repairs_applied': {\n",
        "        'pchip_velocity_values': sum(repair_stats_vel.values()),\n",
        "        'pchip_acceleration_values': sum(repair_stats_acc.values()),\n",
        "        'slerp_quaternion_frames': sum(r['frames_repaired'] for r in slerp_repairs.values()),\n",
        "        'slerp_joints_repaired': len(slerp_repairs),\n",
        "        'accelerations_recalculated': recalc_count\n",
        "    },\n",
        "    'final_quality': {\n",
        "        'max_velocity': float(max(final_vel_max.values())),\n",
        "        'max_acceleration': float(max(final_acc_max.values())),\n",
        "        'remaining_issues': len(remaining_issues),\n",
        "        'overall_status': overall_status\n",
        "    },\n",
        "    'velocity_comparison': velocity_comparison,\n",
        "    'rom_comparison': rom_comparison,\n",
        "    'output_files': {\n",
        "        'final_kinematics': f\"{RUN_ID}__kinematics_final.parquet\",\n",
        "        'cleaning_report': f\"{RUN_ID}__cleaning_report.json\",\n",
        "        'validation_plots': [\n",
        "            f\"{RUN_ID}__cleaning_validation_overview.png\",\n",
        "            f\"{RUN_ID}__cleaning_validation_zoom.png\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "report_path = STEP_065_DIR / f\"{RUN_ID}__cleaning_report.json\"\n",
        "with open(report_path, 'w') as f:\n",
        "    json.dump(cleaning_report, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Cleaning report saved: {report_path}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"üéâ NB06.5 COMPLETE - df_kinematics_final.parquet ready for NB07 Audit\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\nüìÅ Output Files:\")\n",
        "print(f\"   1. {RUN_ID}__kinematics_final.parquet  (USE THIS in NB07)\")\n",
        "print(f\"   2. {RUN_ID}__cleaning_report.json\")\n",
        "print(f\"   3. {RUN_ID}__cleaning_validation_*.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "footer",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "The cleaned kinematics are now ready for **NB07: Master Quality Report**.\n",
        "\n",
        "**What was cleaned:**\n",
        "- Velocity spikes >1200¬∞/s ‚Üí PCHIP interpolated\n",
        "- Acceleration spikes >50,000¬∞/s¬≤ ‚Üí PCHIP interpolated\n",
        "- Quaternion flips ‚Üí SLERP repaired\n",
        "- Acceleration recalculated from clean velocity\n",
        "\n",
        "**Why this approach is robust:**\n",
        "1. **Adaptive**: No hard-coded joint names - automatically detects issues\n",
        "2. **Physics-respecting**: Uses SLERP for 3D rotation geometry, PCHIP for smooth scalars\n",
        "3. **Audit-ready**: Before/After comparison log for traceability"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
